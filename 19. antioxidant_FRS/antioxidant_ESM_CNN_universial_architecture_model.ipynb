{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95NTckuFZZzm"
      },
      "source": [
        "### requirements for the following codings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO71IBS6ZgZV",
        "outputId": "dbd95a80-7d37-44a1-8e2d-4b36dac4b482"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fair-esm in /usr/local/lib/python3.8/dist-packages (2.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.30.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1.21)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (15.0.6.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.12.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n"
          ]
        }
      ],
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m91cA0H5w_eY"
      },
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "outputs": [],
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RddxugbsdR1Y"
      },
      "source": [
        "### data loading and embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LNlD8pvizH84"
      },
      "outputs": [],
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('antioxidant_total.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "embeddings_results.to_csv('antioxidant_whole_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "y = dataset['FRS']\n",
        "y = np.array(y) # transformed as np.array for CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zEfIAAQO3bWm"
      },
      "outputs": [],
      "source": [
        "# assign the dataset \n",
        "X_data_name = 'antioxidant_whole_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X = pd.read_csv(X_data_name,header=0, index_col = 0,delimiter=',')\n",
        "X = np.array(X)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, stratify= y, random_state=13)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "92ca4734-7548-482c-eb0a-564e32b0406c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1123, 320)\n",
            "(281, 320)\n",
            "(1123,)\n",
            "(281,)\n",
            "582\n",
            "541\n",
            "146\n",
            "135\n"
          ]
        }
      ],
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(np.count_nonzero(y_train==0))  # notice here 1 means positive and 00 means negative \n",
        "print(np.count_nonzero(y_train==1)) \n",
        "print(np.count_nonzero(y_test==0)) \n",
        "print(np.count_nonzero(y_test==1)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBhJebt_3Y9_",
        "outputId": "3aa0e4d1-8d82-48f0-e8fd-2ec4f1f615ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "71/71 [==============================] - 2s 16ms/step - loss: 1.0924 - accuracy: 0.6037 - val_loss: 0.6937 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5844 - accuracy: 0.6803 - val_loss: 0.6912 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5550 - accuracy: 0.7213 - val_loss: 0.6901 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5136 - accuracy: 0.7257 - val_loss: 0.6835 - val_accuracy: 0.5267 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4887 - accuracy: 0.7391 - val_loss: 0.6606 - val_accuracy: 0.6263 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.4643 - accuracy: 0.7551 - val_loss: 0.6058 - val_accuracy: 0.7260 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4559 - accuracy: 0.7703 - val_loss: 0.5520 - val_accuracy: 0.7367 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4373 - accuracy: 0.7783 - val_loss: 0.5008 - val_accuracy: 0.7544 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4086 - accuracy: 0.7890 - val_loss: 0.5019 - val_accuracy: 0.7473 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4033 - accuracy: 0.7988 - val_loss: 0.5188 - val_accuracy: 0.7367 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3917 - accuracy: 0.7952 - val_loss: 0.5304 - val_accuracy: 0.7580 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3647 - accuracy: 0.8192 - val_loss: 0.5282 - val_accuracy: 0.7544 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3580 - accuracy: 0.8192 - val_loss: 0.5940 - val_accuracy: 0.7616 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3479 - accuracy: 0.8290 - val_loss: 0.5228 - val_accuracy: 0.7367 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3343 - accuracy: 0.8379 - val_loss: 0.5508 - val_accuracy: 0.7580 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3325 - accuracy: 0.8424 - val_loss: 0.5446 - val_accuracy: 0.7544 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3244 - accuracy: 0.8335 - val_loss: 0.5439 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3114 - accuracy: 0.8513 - val_loss: 0.5553 - val_accuracy: 0.7616 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.2994 - accuracy: 0.8593 - val_loss: 0.5635 - val_accuracy: 0.7438 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2945 - accuracy: 0.8593 - val_loss: 0.5659 - val_accuracy: 0.7438 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2908 - accuracy: 0.8638 - val_loss: 0.5728 - val_accuracy: 0.7367 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.8691 - val_loss: 0.5729 - val_accuracy: 0.7722 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2888 - accuracy: 0.8664 - val_loss: 0.5761 - val_accuracy: 0.7580 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2873 - accuracy: 0.8718 - val_loss: 0.5725 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2813 - accuracy: 0.8807 - val_loss: 0.5802 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2854 - accuracy: 0.8700 - val_loss: 0.5749 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2757 - accuracy: 0.8744 - val_loss: 0.5820 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 11ms/step - loss: 0.2728 - accuracy: 0.8700 - val_loss: 0.5862 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2653 - accuracy: 0.8780 - val_loss: 0.5875 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2695 - accuracy: 0.8780 - val_loss: 0.5884 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2734 - accuracy: 0.8682 - val_loss: 0.5895 - val_accuracy: 0.7580 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2714 - accuracy: 0.8771 - val_loss: 0.5918 - val_accuracy: 0.7651 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2879 - accuracy: 0.8646 - val_loss: 0.5875 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2681 - accuracy: 0.8753 - val_loss: 0.5884 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2728 - accuracy: 0.8753 - val_loss: 0.5894 - val_accuracy: 0.7580 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2623 - accuracy: 0.8825 - val_loss: 0.5904 - val_accuracy: 0.7544 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2660 - accuracy: 0.8851 - val_loss: 0.5916 - val_accuracy: 0.7544 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2571 - accuracy: 0.8789 - val_loss: 0.5935 - val_accuracy: 0.7509 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2804 - accuracy: 0.8646 - val_loss: 0.5920 - val_accuracy: 0.7544 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2678 - accuracy: 0.8869 - val_loss: 0.5918 - val_accuracy: 0.7473 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2659 - accuracy: 0.8798 - val_loss: 0.5922 - val_accuracy: 0.7544 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2662 - accuracy: 0.8718 - val_loss: 0.5912 - val_accuracy: 0.7509 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2684 - accuracy: 0.8771 - val_loss: 0.5909 - val_accuracy: 0.7509 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2708 - accuracy: 0.8762 - val_loss: 0.5903 - val_accuracy: 0.7509 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 11ms/step - loss: 0.2789 - accuracy: 0.8646 - val_loss: 0.5905 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2732 - accuracy: 0.8789 - val_loss: 0.5905 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2654 - accuracy: 0.8869 - val_loss: 0.5906 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2705 - accuracy: 0.8736 - val_loss: 0.5910 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2780 - accuracy: 0.8789 - val_loss: 0.5909 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2714 - accuracy: 0.8860 - val_loss: 0.5907 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2692 - accuracy: 0.8807 - val_loss: 0.5908 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2667 - accuracy: 0.8789 - val_loss: 0.5911 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2626 - accuracy: 0.8816 - val_loss: 0.5915 - val_accuracy: 0.7438 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2673 - accuracy: 0.8727 - val_loss: 0.5913 - val_accuracy: 0.7438 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2711 - accuracy: 0.8851 - val_loss: 0.5911 - val_accuracy: 0.7438 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2739 - accuracy: 0.8736 - val_loss: 0.5914 - val_accuracy: 0.7473 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2778 - accuracy: 0.8709 - val_loss: 0.5912 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2646 - accuracy: 0.8744 - val_loss: 0.5914 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2593 - accuracy: 0.8816 - val_loss: 0.5916 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.2526 - accuracy: 0.8887 - val_loss: 0.5914 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2656 - accuracy: 0.8905 - val_loss: 0.5916 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2762 - accuracy: 0.8566 - val_loss: 0.5909 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 1.3738 - accuracy: 0.6020 - val_loss: 0.6574 - val_accuracy: 0.6477 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5578 - accuracy: 0.7097 - val_loss: 0.6395 - val_accuracy: 0.6228 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5043 - accuracy: 0.7480 - val_loss: 0.6495 - val_accuracy: 0.6512 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4751 - accuracy: 0.7765 - val_loss: 0.5985 - val_accuracy: 0.6797 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4587 - accuracy: 0.7872 - val_loss: 0.5686 - val_accuracy: 0.6833 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4312 - accuracy: 0.8094 - val_loss: 0.5749 - val_accuracy: 0.7082 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3983 - accuracy: 0.8255 - val_loss: 0.5849 - val_accuracy: 0.6868 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3925 - accuracy: 0.8246 - val_loss: 0.5622 - val_accuracy: 0.7260 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3573 - accuracy: 0.8370 - val_loss: 0.6319 - val_accuracy: 0.6904 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3433 - accuracy: 0.8593 - val_loss: 0.6346 - val_accuracy: 0.7260 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3414 - accuracy: 0.8486 - val_loss: 0.6326 - val_accuracy: 0.7117 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3052 - accuracy: 0.8664 - val_loss: 0.6505 - val_accuracy: 0.7260 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2945 - accuracy: 0.8780 - val_loss: 0.6902 - val_accuracy: 0.6975 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2997 - accuracy: 0.8709 - val_loss: 0.6482 - val_accuracy: 0.6940 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2644 - accuracy: 0.8976 - val_loss: 0.6756 - val_accuracy: 0.6940 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2623 - accuracy: 0.8887 - val_loss: 0.6843 - val_accuracy: 0.7011 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 11ms/step - loss: 0.2569 - accuracy: 0.8940 - val_loss: 0.7252 - val_accuracy: 0.6868 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2557 - accuracy: 0.8914 - val_loss: 0.6776 - val_accuracy: 0.7046 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2376 - accuracy: 0.9029 - val_loss: 0.6847 - val_accuracy: 0.7046 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2421 - accuracy: 0.9074 - val_loss: 0.6819 - val_accuracy: 0.6975 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2324 - accuracy: 0.9101 - val_loss: 0.6918 - val_accuracy: 0.6940 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2271 - accuracy: 0.9101 - val_loss: 0.7001 - val_accuracy: 0.6940 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2272 - accuracy: 0.9136 - val_loss: 0.7174 - val_accuracy: 0.6904 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2393 - accuracy: 0.9003 - val_loss: 0.6984 - val_accuracy: 0.6940 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2223 - accuracy: 0.9216 - val_loss: 0.7004 - val_accuracy: 0.6940 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2316 - accuracy: 0.9065 - val_loss: 0.6972 - val_accuracy: 0.7117 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2266 - accuracy: 0.9127 - val_loss: 0.7019 - val_accuracy: 0.6904 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2254 - accuracy: 0.9110 - val_loss: 0.7092 - val_accuracy: 0.6904 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2255 - accuracy: 0.9145 - val_loss: 0.7068 - val_accuracy: 0.6940 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2160 - accuracy: 0.9190 - val_loss: 0.7038 - val_accuracy: 0.6904 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2208 - accuracy: 0.9101 - val_loss: 0.7071 - val_accuracy: 0.6904 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2263 - accuracy: 0.9083 - val_loss: 0.7063 - val_accuracy: 0.6904 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2205 - accuracy: 0.9136 - val_loss: 0.7069 - val_accuracy: 0.6940 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2198 - accuracy: 0.9101 - val_loss: 0.7077 - val_accuracy: 0.6940 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2272 - accuracy: 0.9056 - val_loss: 0.7071 - val_accuracy: 0.6975 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2118 - accuracy: 0.9172 - val_loss: 0.7075 - val_accuracy: 0.6940 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2217 - accuracy: 0.9136 - val_loss: 0.7064 - val_accuracy: 0.6940 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2126 - accuracy: 0.9261 - val_loss: 0.7069 - val_accuracy: 0.6940 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2256 - accuracy: 0.9092 - val_loss: 0.7071 - val_accuracy: 0.6940 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2154 - accuracy: 0.9136 - val_loss: 0.7083 - val_accuracy: 0.6940 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2287 - accuracy: 0.9136 - val_loss: 0.7076 - val_accuracy: 0.6940 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2112 - accuracy: 0.9127 - val_loss: 0.7084 - val_accuracy: 0.6940 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2135 - accuracy: 0.9154 - val_loss: 0.7089 - val_accuracy: 0.6940 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2181 - accuracy: 0.9145 - val_loss: 0.7098 - val_accuracy: 0.6940 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2153 - accuracy: 0.9101 - val_loss: 0.7089 - val_accuracy: 0.6940 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2119 - accuracy: 0.9181 - val_loss: 0.7092 - val_accuracy: 0.6904 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2140 - accuracy: 0.9252 - val_loss: 0.7090 - val_accuracy: 0.6904 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2168 - accuracy: 0.9127 - val_loss: 0.7099 - val_accuracy: 0.6904 - lr: 2.8211e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 14ms/step - loss: 1.2257 - accuracy: 0.6732 - val_loss: 0.7080 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5539 - accuracy: 0.7195 - val_loss: 0.7003 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4908 - accuracy: 0.7560 - val_loss: 0.7033 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4648 - accuracy: 0.7756 - val_loss: 0.7113 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4414 - accuracy: 0.7827 - val_loss: 0.6623 - val_accuracy: 0.5587 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4137 - accuracy: 0.8059 - val_loss: 0.6072 - val_accuracy: 0.6477 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3846 - accuracy: 0.8272 - val_loss: 0.5764 - val_accuracy: 0.6797 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3822 - accuracy: 0.8290 - val_loss: 0.6052 - val_accuracy: 0.6975 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3479 - accuracy: 0.8370 - val_loss: 0.6218 - val_accuracy: 0.7153 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3355 - accuracy: 0.8522 - val_loss: 0.7226 - val_accuracy: 0.7011 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3261 - accuracy: 0.8504 - val_loss: 0.6336 - val_accuracy: 0.7153 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3075 - accuracy: 0.8682 - val_loss: 0.6681 - val_accuracy: 0.7189 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2896 - accuracy: 0.8727 - val_loss: 0.6556 - val_accuracy: 0.6975 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2871 - accuracy: 0.8780 - val_loss: 0.7094 - val_accuracy: 0.7224 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2741 - accuracy: 0.8833 - val_loss: 0.7076 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2518 - accuracy: 0.8887 - val_loss: 0.7097 - val_accuracy: 0.7295 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2690 - accuracy: 0.8851 - val_loss: 0.7046 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2446 - accuracy: 0.8967 - val_loss: 0.7251 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2505 - accuracy: 0.8914 - val_loss: 0.7381 - val_accuracy: 0.7473 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2363 - accuracy: 0.9065 - val_loss: 0.7532 - val_accuracy: 0.7616 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2276 - accuracy: 0.9074 - val_loss: 0.7416 - val_accuracy: 0.7473 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2220 - accuracy: 0.9056 - val_loss: 0.7546 - val_accuracy: 0.7509 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2293 - accuracy: 0.9047 - val_loss: 0.7602 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2332 - accuracy: 0.9056 - val_loss: 0.7560 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2203 - accuracy: 0.9083 - val_loss: 0.7564 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2266 - accuracy: 0.9145 - val_loss: 0.7592 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2129 - accuracy: 0.9190 - val_loss: 0.7632 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2097 - accuracy: 0.9181 - val_loss: 0.7754 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2079 - accuracy: 0.9288 - val_loss: 0.7763 - val_accuracy: 0.7473 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2091 - accuracy: 0.9172 - val_loss: 0.7739 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2195 - accuracy: 0.9092 - val_loss: 0.7752 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2134 - accuracy: 0.9279 - val_loss: 0.7784 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2079 - accuracy: 0.9163 - val_loss: 0.7823 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2190 - accuracy: 0.9092 - val_loss: 0.7780 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2014 - accuracy: 0.9190 - val_loss: 0.7765 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2151 - accuracy: 0.9190 - val_loss: 0.7759 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2077 - accuracy: 0.9190 - val_loss: 0.7769 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2145 - accuracy: 0.9145 - val_loss: 0.7765 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2142 - accuracy: 0.9136 - val_loss: 0.7762 - val_accuracy: 0.7367 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2154 - accuracy: 0.9181 - val_loss: 0.7759 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2139 - accuracy: 0.9234 - val_loss: 0.7760 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2155 - accuracy: 0.9190 - val_loss: 0.7762 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2265 - accuracy: 0.9056 - val_loss: 0.7759 - val_accuracy: 0.7367 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2201 - accuracy: 0.9136 - val_loss: 0.7760 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2118 - accuracy: 0.9154 - val_loss: 0.7753 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2140 - accuracy: 0.9243 - val_loss: 0.7742 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2040 - accuracy: 0.9252 - val_loss: 0.7748 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2091 - accuracy: 0.9190 - val_loss: 0.7754 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.2098 - accuracy: 0.9190 - val_loss: 0.7756 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.2042 - accuracy: 0.9323 - val_loss: 0.7764 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2135 - accuracy: 0.9145 - val_loss: 0.7762 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2159 - accuracy: 0.9154 - val_loss: 0.7758 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2257 - accuracy: 0.9003 - val_loss: 0.7762 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2082 - accuracy: 0.9190 - val_loss: 0.7766 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2116 - accuracy: 0.9252 - val_loss: 0.7763 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2116 - accuracy: 0.9145 - val_loss: 0.7756 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2165 - accuracy: 0.9065 - val_loss: 0.7765 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2145 - accuracy: 0.9110 - val_loss: 0.7761 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2128 - accuracy: 0.9172 - val_loss: 0.7759 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2194 - accuracy: 0.9163 - val_loss: 0.7761 - val_accuracy: 0.7402 - lr: 3.6562e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 3s 24ms/step - loss: 0.9575 - accuracy: 0.6100 - val_loss: 0.6937 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5676 - accuracy: 0.6874 - val_loss: 0.6924 - val_accuracy: 0.5836 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5284 - accuracy: 0.7115 - val_loss: 0.6923 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5047 - accuracy: 0.7418 - val_loss: 0.6897 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4771 - accuracy: 0.7667 - val_loss: 0.6660 - val_accuracy: 0.6050 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4569 - accuracy: 0.7480 - val_loss: 0.6212 - val_accuracy: 0.6904 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4382 - accuracy: 0.7640 - val_loss: 0.5560 - val_accuracy: 0.6904 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4151 - accuracy: 0.7729 - val_loss: 0.6100 - val_accuracy: 0.7367 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4032 - accuracy: 0.7988 - val_loss: 0.5924 - val_accuracy: 0.6975 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3774 - accuracy: 0.8175 - val_loss: 0.6291 - val_accuracy: 0.7509 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3809 - accuracy: 0.8192 - val_loss: 0.6021 - val_accuracy: 0.7082 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3518 - accuracy: 0.8317 - val_loss: 0.6472 - val_accuracy: 0.7153 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3358 - accuracy: 0.8415 - val_loss: 0.7347 - val_accuracy: 0.7438 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3234 - accuracy: 0.8638 - val_loss: 0.6845 - val_accuracy: 0.7189 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3122 - accuracy: 0.8459 - val_loss: 0.6722 - val_accuracy: 0.7189 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3094 - accuracy: 0.8540 - val_loss: 0.7201 - val_accuracy: 0.7473 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2934 - accuracy: 0.8531 - val_loss: 0.6864 - val_accuracy: 0.7153 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2807 - accuracy: 0.8646 - val_loss: 0.7314 - val_accuracy: 0.7260 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2850 - accuracy: 0.8655 - val_loss: 0.7249 - val_accuracy: 0.7295 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2839 - accuracy: 0.8860 - val_loss: 0.7396 - val_accuracy: 0.7224 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2719 - accuracy: 0.8771 - val_loss: 0.7445 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2717 - accuracy: 0.8780 - val_loss: 0.7518 - val_accuracy: 0.7402 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2664 - accuracy: 0.8807 - val_loss: 0.7770 - val_accuracy: 0.7544 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2634 - accuracy: 0.8744 - val_loss: 0.7384 - val_accuracy: 0.7509 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2688 - accuracy: 0.8762 - val_loss: 0.7335 - val_accuracy: 0.7367 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2626 - accuracy: 0.8896 - val_loss: 0.7412 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2448 - accuracy: 0.8967 - val_loss: 0.7544 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.2523 - accuracy: 0.8940 - val_loss: 0.7382 - val_accuracy: 0.7331 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2592 - accuracy: 0.8807 - val_loss: 0.7494 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2441 - accuracy: 0.8994 - val_loss: 0.7553 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2627 - accuracy: 0.8816 - val_loss: 0.7549 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2455 - accuracy: 0.8923 - val_loss: 0.7511 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2478 - accuracy: 0.8940 - val_loss: 0.7513 - val_accuracy: 0.7367 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2423 - accuracy: 0.8949 - val_loss: 0.7536 - val_accuracy: 0.7473 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2512 - accuracy: 0.8860 - val_loss: 0.7530 - val_accuracy: 0.7331 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2497 - accuracy: 0.8851 - val_loss: 0.7519 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2477 - accuracy: 0.8914 - val_loss: 0.7519 - val_accuracy: 0.7367 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2502 - accuracy: 0.8931 - val_loss: 0.7535 - val_accuracy: 0.7367 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2497 - accuracy: 0.8994 - val_loss: 0.7530 - val_accuracy: 0.7367 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2484 - accuracy: 0.8940 - val_loss: 0.7513 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2453 - accuracy: 0.8914 - val_loss: 0.7536 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2450 - accuracy: 0.8931 - val_loss: 0.7529 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2450 - accuracy: 0.8940 - val_loss: 0.7530 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2464 - accuracy: 0.8887 - val_loss: 0.7533 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2448 - accuracy: 0.8958 - val_loss: 0.7532 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2418 - accuracy: 0.8896 - val_loss: 0.7530 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2387 - accuracy: 0.9012 - val_loss: 0.7531 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2461 - accuracy: 0.8914 - val_loss: 0.7532 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2443 - accuracy: 0.8905 - val_loss: 0.7529 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2455 - accuracy: 0.8905 - val_loss: 0.7536 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2414 - accuracy: 0.8914 - val_loss: 0.7531 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2393 - accuracy: 0.8931 - val_loss: 0.7537 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2479 - accuracy: 0.8940 - val_loss: 0.7540 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2566 - accuracy: 0.8833 - val_loss: 0.7539 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2393 - accuracy: 0.9029 - val_loss: 0.7539 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2524 - accuracy: 0.8851 - val_loss: 0.7534 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2500 - accuracy: 0.9047 - val_loss: 0.7540 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2456 - accuracy: 0.8940 - val_loss: 0.7532 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2448 - accuracy: 0.8949 - val_loss: 0.7539 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2404 - accuracy: 0.8914 - val_loss: 0.7543 - val_accuracy: 0.7402 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2503 - accuracy: 0.8949 - val_loss: 0.7535 - val_accuracy: 0.7402 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2603 - accuracy: 0.8789 - val_loss: 0.7537 - val_accuracy: 0.7402 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2463 - accuracy: 0.8914 - val_loss: 0.7536 - val_accuracy: 0.7402 - lr: 2.1937e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 3s 23ms/step - loss: 0.9402 - accuracy: 0.5459 - val_loss: 0.7039 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6328 - accuracy: 0.6429 - val_loss: 0.7157 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5608 - accuracy: 0.7044 - val_loss: 0.7061 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5377 - accuracy: 0.7195 - val_loss: 0.7162 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5403 - accuracy: 0.7115 - val_loss: 0.6619 - val_accuracy: 0.6477 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4989 - accuracy: 0.7578 - val_loss: 0.6701 - val_accuracy: 0.5445 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4872 - accuracy: 0.7480 - val_loss: 0.6065 - val_accuracy: 0.6833 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4849 - accuracy: 0.7462 - val_loss: 0.5750 - val_accuracy: 0.6975 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4482 - accuracy: 0.7765 - val_loss: 0.5523 - val_accuracy: 0.7402 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4301 - accuracy: 0.7845 - val_loss: 0.5682 - val_accuracy: 0.7295 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4298 - accuracy: 0.7934 - val_loss: 0.6071 - val_accuracy: 0.7438 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4145 - accuracy: 0.7916 - val_loss: 0.5736 - val_accuracy: 0.7580 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.4033 - accuracy: 0.8103 - val_loss: 0.5909 - val_accuracy: 0.7331 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.4047 - accuracy: 0.8112 - val_loss: 0.6005 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3843 - accuracy: 0.8264 - val_loss: 0.6078 - val_accuracy: 0.7544 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3843 - accuracy: 0.8148 - val_loss: 0.6230 - val_accuracy: 0.7367 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3656 - accuracy: 0.8272 - val_loss: 0.6478 - val_accuracy: 0.7224 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3626 - accuracy: 0.8335 - val_loss: 0.6405 - val_accuracy: 0.7367 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3576 - accuracy: 0.8388 - val_loss: 0.6431 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3589 - accuracy: 0.8290 - val_loss: 0.6352 - val_accuracy: 0.7295 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3368 - accuracy: 0.8424 - val_loss: 0.6511 - val_accuracy: 0.7260 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3315 - accuracy: 0.8504 - val_loss: 0.6611 - val_accuracy: 0.7367 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3327 - accuracy: 0.8459 - val_loss: 0.6373 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3334 - accuracy: 0.8566 - val_loss: 0.6523 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3218 - accuracy: 0.8566 - val_loss: 0.6515 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3424 - accuracy: 0.8468 - val_loss: 0.6604 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3315 - accuracy: 0.8575 - val_loss: 0.6526 - val_accuracy: 0.7402 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3255 - accuracy: 0.8593 - val_loss: 0.6591 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3159 - accuracy: 0.8584 - val_loss: 0.6579 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3249 - accuracy: 0.8611 - val_loss: 0.6600 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3211 - accuracy: 0.8620 - val_loss: 0.6553 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3208 - accuracy: 0.8620 - val_loss: 0.6541 - val_accuracy: 0.7509 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3106 - accuracy: 0.8673 - val_loss: 0.6601 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3137 - accuracy: 0.8584 - val_loss: 0.6584 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3253 - accuracy: 0.8611 - val_loss: 0.6572 - val_accuracy: 0.7473 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3173 - accuracy: 0.8593 - val_loss: 0.6572 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3174 - accuracy: 0.8602 - val_loss: 0.6575 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3307 - accuracy: 0.8566 - val_loss: 0.6574 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3202 - accuracy: 0.8549 - val_loss: 0.6573 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3156 - accuracy: 0.8691 - val_loss: 0.6575 - val_accuracy: 0.7438 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3206 - accuracy: 0.8638 - val_loss: 0.6568 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3072 - accuracy: 0.8655 - val_loss: 0.6578 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3143 - accuracy: 0.8736 - val_loss: 0.6572 - val_accuracy: 0.7438 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3100 - accuracy: 0.8727 - val_loss: 0.6576 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3181 - accuracy: 0.8646 - val_loss: 0.6575 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3135 - accuracy: 0.8655 - val_loss: 0.6581 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3273 - accuracy: 0.8451 - val_loss: 0.6579 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3153 - accuracy: 0.8682 - val_loss: 0.6575 - val_accuracy: 0.7438 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3157 - accuracy: 0.8620 - val_loss: 0.6574 - val_accuracy: 0.7438 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3199 - accuracy: 0.8620 - val_loss: 0.6573 - val_accuracy: 0.7438 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3094 - accuracy: 0.8575 - val_loss: 0.6576 - val_accuracy: 0.7438 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3159 - accuracy: 0.8629 - val_loss: 0.6579 - val_accuracy: 0.7438 - lr: 1.6927e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 17ms/step - loss: 0.9609 - accuracy: 0.6331 - val_loss: 0.6953 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.6408 - accuracy: 0.6572 - val_loss: 0.6951 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.5597 - accuracy: 0.6981 - val_loss: 0.6953 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5425 - accuracy: 0.7115 - val_loss: 0.6861 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5304 - accuracy: 0.7168 - val_loss: 0.6255 - val_accuracy: 0.6762 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4977 - accuracy: 0.7507 - val_loss: 0.6080 - val_accuracy: 0.6975 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4630 - accuracy: 0.7720 - val_loss: 0.5763 - val_accuracy: 0.6868 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4532 - accuracy: 0.7756 - val_loss: 0.5564 - val_accuracy: 0.7189 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4343 - accuracy: 0.7765 - val_loss: 0.5588 - val_accuracy: 0.7117 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4169 - accuracy: 0.7988 - val_loss: 0.5969 - val_accuracy: 0.7438 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4023 - accuracy: 0.7916 - val_loss: 0.6109 - val_accuracy: 0.7367 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3778 - accuracy: 0.8183 - val_loss: 0.5906 - val_accuracy: 0.7580 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3803 - accuracy: 0.8112 - val_loss: 0.6299 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3774 - accuracy: 0.8121 - val_loss: 0.6170 - val_accuracy: 0.7189 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3396 - accuracy: 0.8255 - val_loss: 0.6376 - val_accuracy: 0.7224 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3435 - accuracy: 0.8388 - val_loss: 0.6172 - val_accuracy: 0.7331 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3362 - accuracy: 0.8299 - val_loss: 0.6622 - val_accuracy: 0.7473 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3165 - accuracy: 0.8513 - val_loss: 0.6759 - val_accuracy: 0.7367 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3160 - accuracy: 0.8433 - val_loss: 0.6475 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3203 - accuracy: 0.8468 - val_loss: 0.6826 - val_accuracy: 0.7189 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3077 - accuracy: 0.8486 - val_loss: 0.6540 - val_accuracy: 0.7402 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2982 - accuracy: 0.8566 - val_loss: 0.6787 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3063 - accuracy: 0.8513 - val_loss: 0.6648 - val_accuracy: 0.7509 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2953 - accuracy: 0.8549 - val_loss: 0.6800 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2971 - accuracy: 0.8593 - val_loss: 0.6737 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2991 - accuracy: 0.8459 - val_loss: 0.6914 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2977 - accuracy: 0.8495 - val_loss: 0.6837 - val_accuracy: 0.7473 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2973 - accuracy: 0.8504 - val_loss: 0.6806 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2917 - accuracy: 0.8513 - val_loss: 0.6849 - val_accuracy: 0.7473 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.2892 - accuracy: 0.8602 - val_loss: 0.6846 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2982 - accuracy: 0.8468 - val_loss: 0.6874 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2956 - accuracy: 0.8540 - val_loss: 0.6824 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2845 - accuracy: 0.8655 - val_loss: 0.6872 - val_accuracy: 0.7473 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2760 - accuracy: 0.8638 - val_loss: 0.6912 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.8549 - val_loss: 0.6931 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3014 - accuracy: 0.8557 - val_loss: 0.6900 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2857 - accuracy: 0.8620 - val_loss: 0.6907 - val_accuracy: 0.7473 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2900 - accuracy: 0.8575 - val_loss: 0.6881 - val_accuracy: 0.7473 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2899 - accuracy: 0.8602 - val_loss: 0.6896 - val_accuracy: 0.7473 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2872 - accuracy: 0.8638 - val_loss: 0.6898 - val_accuracy: 0.7473 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 2s 25ms/step - loss: 0.2916 - accuracy: 0.8531 - val_loss: 0.6897 - val_accuracy: 0.7473 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2920 - accuracy: 0.8549 - val_loss: 0.6898 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2951 - accuracy: 0.8566 - val_loss: 0.6890 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2991 - accuracy: 0.8611 - val_loss: 0.6897 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2850 - accuracy: 0.8682 - val_loss: 0.6898 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2811 - accuracy: 0.8566 - val_loss: 0.6895 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2976 - accuracy: 0.8531 - val_loss: 0.6897 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2913 - accuracy: 0.8531 - val_loss: 0.6894 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2966 - accuracy: 0.8504 - val_loss: 0.6892 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2788 - accuracy: 0.8575 - val_loss: 0.6895 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2979 - accuracy: 0.8549 - val_loss: 0.6895 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2824 - accuracy: 0.8646 - val_loss: 0.6898 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 0.9928 - accuracy: 0.5628 - val_loss: 0.6978 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6434 - accuracy: 0.6527 - val_loss: 0.7374 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5670 - accuracy: 0.6963 - val_loss: 0.7242 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5409 - accuracy: 0.7337 - val_loss: 0.7273 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5189 - accuracy: 0.7435 - val_loss: 0.6871 - val_accuracy: 0.5018 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4779 - accuracy: 0.7658 - val_loss: 0.6155 - val_accuracy: 0.7011 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4582 - accuracy: 0.7711 - val_loss: 0.5640 - val_accuracy: 0.6975 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4591 - accuracy: 0.7765 - val_loss: 0.6254 - val_accuracy: 0.6548 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4663 - accuracy: 0.7747 - val_loss: 0.5581 - val_accuracy: 0.7046 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4306 - accuracy: 0.7952 - val_loss: 0.5811 - val_accuracy: 0.7117 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.4186 - accuracy: 0.8050 - val_loss: 0.5990 - val_accuracy: 0.7046 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4147 - accuracy: 0.7961 - val_loss: 0.6051 - val_accuracy: 0.7153 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3801 - accuracy: 0.8192 - val_loss: 0.6487 - val_accuracy: 0.6762 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3863 - accuracy: 0.8139 - val_loss: 0.6501 - val_accuracy: 0.6975 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3626 - accuracy: 0.8237 - val_loss: 0.6230 - val_accuracy: 0.7224 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3785 - accuracy: 0.8290 - val_loss: 0.6113 - val_accuracy: 0.7260 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3668 - accuracy: 0.8379 - val_loss: 0.6678 - val_accuracy: 0.7153 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3554 - accuracy: 0.8424 - val_loss: 0.6324 - val_accuracy: 0.7189 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3511 - accuracy: 0.8370 - val_loss: 0.6435 - val_accuracy: 0.7153 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3471 - accuracy: 0.8362 - val_loss: 0.6492 - val_accuracy: 0.7189 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3366 - accuracy: 0.8566 - val_loss: 0.6607 - val_accuracy: 0.7153 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3394 - accuracy: 0.8540 - val_loss: 0.6627 - val_accuracy: 0.7189 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3423 - accuracy: 0.8549 - val_loss: 0.6678 - val_accuracy: 0.7189 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3283 - accuracy: 0.8522 - val_loss: 0.6758 - val_accuracy: 0.7260 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3292 - accuracy: 0.8540 - val_loss: 0.6823 - val_accuracy: 0.7189 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3242 - accuracy: 0.8655 - val_loss: 0.6669 - val_accuracy: 0.7189 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3300 - accuracy: 0.8549 - val_loss: 0.6603 - val_accuracy: 0.7189 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3416 - accuracy: 0.8477 - val_loss: 0.6665 - val_accuracy: 0.7117 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3318 - accuracy: 0.8575 - val_loss: 0.6688 - val_accuracy: 0.7189 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3330 - accuracy: 0.8504 - val_loss: 0.6626 - val_accuracy: 0.7189 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3193 - accuracy: 0.8575 - val_loss: 0.6770 - val_accuracy: 0.7082 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3324 - accuracy: 0.8433 - val_loss: 0.6724 - val_accuracy: 0.7117 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3186 - accuracy: 0.8584 - val_loss: 0.6738 - val_accuracy: 0.7117 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3270 - accuracy: 0.8557 - val_loss: 0.6729 - val_accuracy: 0.7189 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3209 - accuracy: 0.8593 - val_loss: 0.6737 - val_accuracy: 0.7117 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3251 - accuracy: 0.8638 - val_loss: 0.6705 - val_accuracy: 0.7189 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.3189 - accuracy: 0.8646 - val_loss: 0.6700 - val_accuracy: 0.7189 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3245 - accuracy: 0.8451 - val_loss: 0.6703 - val_accuracy: 0.7189 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3207 - accuracy: 0.8620 - val_loss: 0.6712 - val_accuracy: 0.7189 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3227 - accuracy: 0.8620 - val_loss: 0.6713 - val_accuracy: 0.7153 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3155 - accuracy: 0.8602 - val_loss: 0.6731 - val_accuracy: 0.7153 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3149 - accuracy: 0.8575 - val_loss: 0.6728 - val_accuracy: 0.7153 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3170 - accuracy: 0.8531 - val_loss: 0.6731 - val_accuracy: 0.7153 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3229 - accuracy: 0.8655 - val_loss: 0.6730 - val_accuracy: 0.7189 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3152 - accuracy: 0.8655 - val_loss: 0.6730 - val_accuracy: 0.7189 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3109 - accuracy: 0.8602 - val_loss: 0.6741 - val_accuracy: 0.7189 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3184 - accuracy: 0.8611 - val_loss: 0.6737 - val_accuracy: 0.7189 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3295 - accuracy: 0.8504 - val_loss: 0.6733 - val_accuracy: 0.7189 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3286 - accuracy: 0.8646 - val_loss: 0.6734 - val_accuracy: 0.7189 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3213 - accuracy: 0.8540 - val_loss: 0.6735 - val_accuracy: 0.7189 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3223 - accuracy: 0.8620 - val_loss: 0.6735 - val_accuracy: 0.7189 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3287 - accuracy: 0.8522 - val_loss: 0.6733 - val_accuracy: 0.7189 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3087 - accuracy: 0.8700 - val_loss: 0.6734 - val_accuracy: 0.7189 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3292 - accuracy: 0.8513 - val_loss: 0.6736 - val_accuracy: 0.7189 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3179 - accuracy: 0.8673 - val_loss: 0.6739 - val_accuracy: 0.7189 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3211 - accuracy: 0.8584 - val_loss: 0.6744 - val_accuracy: 0.7189 - lr: 1.0156e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 3s 22ms/step - loss: 1.1767 - accuracy: 0.5280 - val_loss: 0.6980 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6079 - accuracy: 0.6679 - val_loss: 0.7001 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5488 - accuracy: 0.7231 - val_loss: 0.7071 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5058 - accuracy: 0.7364 - val_loss: 0.6951 - val_accuracy: 0.4875 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5044 - accuracy: 0.7427 - val_loss: 0.6348 - val_accuracy: 0.6548 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4556 - accuracy: 0.7649 - val_loss: 0.6066 - val_accuracy: 0.6512 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4592 - accuracy: 0.7792 - val_loss: 0.5541 - val_accuracy: 0.6975 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4325 - accuracy: 0.7934 - val_loss: 0.5199 - val_accuracy: 0.7260 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4111 - accuracy: 0.8094 - val_loss: 0.5050 - val_accuracy: 0.7367 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3941 - accuracy: 0.8059 - val_loss: 0.5321 - val_accuracy: 0.7153 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3903 - accuracy: 0.8121 - val_loss: 0.5546 - val_accuracy: 0.7722 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3621 - accuracy: 0.8255 - val_loss: 0.5389 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3504 - accuracy: 0.8362 - val_loss: 0.5386 - val_accuracy: 0.7473 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3517 - accuracy: 0.8344 - val_loss: 0.5403 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3272 - accuracy: 0.8540 - val_loss: 0.5769 - val_accuracy: 0.7509 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3230 - accuracy: 0.8638 - val_loss: 0.5654 - val_accuracy: 0.7544 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3213 - accuracy: 0.8540 - val_loss: 0.5991 - val_accuracy: 0.7687 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3175 - accuracy: 0.8442 - val_loss: 0.5816 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2967 - accuracy: 0.8646 - val_loss: 0.5937 - val_accuracy: 0.7473 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2939 - accuracy: 0.8798 - val_loss: 0.5956 - val_accuracy: 0.7758 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2928 - accuracy: 0.8709 - val_loss: 0.5940 - val_accuracy: 0.7473 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2822 - accuracy: 0.8833 - val_loss: 0.5983 - val_accuracy: 0.7544 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2903 - accuracy: 0.8682 - val_loss: 0.5855 - val_accuracy: 0.7544 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2846 - accuracy: 0.8727 - val_loss: 0.5936 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2938 - accuracy: 0.8798 - val_loss: 0.5934 - val_accuracy: 0.7544 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2802 - accuracy: 0.8842 - val_loss: 0.6036 - val_accuracy: 0.7580 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 2s 21ms/step - loss: 0.2834 - accuracy: 0.8709 - val_loss: 0.5991 - val_accuracy: 0.7616 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2736 - accuracy: 0.8851 - val_loss: 0.6001 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2778 - accuracy: 0.8878 - val_loss: 0.5994 - val_accuracy: 0.7651 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2718 - accuracy: 0.8869 - val_loss: 0.6033 - val_accuracy: 0.7722 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2674 - accuracy: 0.8878 - val_loss: 0.6028 - val_accuracy: 0.7651 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2737 - accuracy: 0.8860 - val_loss: 0.6096 - val_accuracy: 0.7687 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2679 - accuracy: 0.8923 - val_loss: 0.6078 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2687 - accuracy: 0.8878 - val_loss: 0.6077 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2638 - accuracy: 0.8851 - val_loss: 0.6088 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2764 - accuracy: 0.8807 - val_loss: 0.6086 - val_accuracy: 0.7616 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2680 - accuracy: 0.8798 - val_loss: 0.6094 - val_accuracy: 0.7758 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2578 - accuracy: 0.8940 - val_loss: 0.6092 - val_accuracy: 0.7722 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2762 - accuracy: 0.8887 - val_loss: 0.6081 - val_accuracy: 0.7687 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2533 - accuracy: 0.8967 - val_loss: 0.6101 - val_accuracy: 0.7722 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2681 - accuracy: 0.8860 - val_loss: 0.6092 - val_accuracy: 0.7651 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2680 - accuracy: 0.8923 - val_loss: 0.6089 - val_accuracy: 0.7687 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2626 - accuracy: 0.8940 - val_loss: 0.6088 - val_accuracy: 0.7687 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2659 - accuracy: 0.8914 - val_loss: 0.6089 - val_accuracy: 0.7687 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2657 - accuracy: 0.8869 - val_loss: 0.6089 - val_accuracy: 0.7687 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2748 - accuracy: 0.8878 - val_loss: 0.6091 - val_accuracy: 0.7687 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2679 - accuracy: 0.8887 - val_loss: 0.6091 - val_accuracy: 0.7651 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2721 - accuracy: 0.8816 - val_loss: 0.6094 - val_accuracy: 0.7687 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2581 - accuracy: 0.8967 - val_loss: 0.6097 - val_accuracy: 0.7687 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2637 - accuracy: 0.8976 - val_loss: 0.6097 - val_accuracy: 0.7687 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2839 - accuracy: 0.8825 - val_loss: 0.6101 - val_accuracy: 0.7687 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2617 - accuracy: 0.8949 - val_loss: 0.6100 - val_accuracy: 0.7687 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2680 - accuracy: 0.8896 - val_loss: 0.6103 - val_accuracy: 0.7687 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2663 - accuracy: 0.8887 - val_loss: 0.6101 - val_accuracy: 0.7687 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2618 - accuracy: 0.8896 - val_loss: 0.6102 - val_accuracy: 0.7687 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2690 - accuracy: 0.8914 - val_loss: 0.6101 - val_accuracy: 0.7687 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2822 - accuracy: 0.8860 - val_loss: 0.6103 - val_accuracy: 0.7687 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2686 - accuracy: 0.8842 - val_loss: 0.6103 - val_accuracy: 0.7687 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2725 - accuracy: 0.8860 - val_loss: 0.6101 - val_accuracy: 0.7687 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2599 - accuracy: 0.8976 - val_loss: 0.6098 - val_accuracy: 0.7687 - lr: 3.6562e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 0.9534 - accuracy: 0.5770 - val_loss: 0.7110 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.6386 - accuracy: 0.6224 - val_loss: 0.7066 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.6074 - accuracy: 0.6687 - val_loss: 0.7043 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.6001 - accuracy: 0.6919 - val_loss: 0.6551 - val_accuracy: 0.5979 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5622 - accuracy: 0.6732 - val_loss: 0.5703 - val_accuracy: 0.7544 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5395 - accuracy: 0.7177 - val_loss: 0.5889 - val_accuracy: 0.7295 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5221 - accuracy: 0.7231 - val_loss: 0.5381 - val_accuracy: 0.7367 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5028 - accuracy: 0.7435 - val_loss: 0.5223 - val_accuracy: 0.7473 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4803 - accuracy: 0.7444 - val_loss: 0.4961 - val_accuracy: 0.7544 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4590 - accuracy: 0.7676 - val_loss: 0.5121 - val_accuracy: 0.7224 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4572 - accuracy: 0.7703 - val_loss: 0.5098 - val_accuracy: 0.7438 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4483 - accuracy: 0.7907 - val_loss: 0.5035 - val_accuracy: 0.7473 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4264 - accuracy: 0.8041 - val_loss: 0.5202 - val_accuracy: 0.7331 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4168 - accuracy: 0.7881 - val_loss: 0.5319 - val_accuracy: 0.7295 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4056 - accuracy: 0.8103 - val_loss: 0.5270 - val_accuracy: 0.7544 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3995 - accuracy: 0.8094 - val_loss: 0.5517 - val_accuracy: 0.7580 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3975 - accuracy: 0.8050 - val_loss: 0.5327 - val_accuracy: 0.7473 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3826 - accuracy: 0.8237 - val_loss: 0.5512 - val_accuracy: 0.7260 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3906 - accuracy: 0.8077 - val_loss: 0.5626 - val_accuracy: 0.7438 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3798 - accuracy: 0.8157 - val_loss: 0.5462 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3543 - accuracy: 0.8459 - val_loss: 0.5630 - val_accuracy: 0.7473 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3606 - accuracy: 0.8406 - val_loss: 0.5569 - val_accuracy: 0.7509 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3515 - accuracy: 0.8308 - val_loss: 0.5562 - val_accuracy: 0.7367 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3621 - accuracy: 0.8362 - val_loss: 0.5549 - val_accuracy: 0.7331 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3607 - accuracy: 0.8290 - val_loss: 0.5551 - val_accuracy: 0.7367 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3495 - accuracy: 0.8424 - val_loss: 0.5536 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3525 - accuracy: 0.8459 - val_loss: 0.5581 - val_accuracy: 0.7473 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3486 - accuracy: 0.8326 - val_loss: 0.5604 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3495 - accuracy: 0.8353 - val_loss: 0.5612 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3423 - accuracy: 0.8406 - val_loss: 0.5640 - val_accuracy: 0.7544 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3449 - accuracy: 0.8415 - val_loss: 0.5682 - val_accuracy: 0.7544 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3364 - accuracy: 0.8442 - val_loss: 0.5701 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3518 - accuracy: 0.8451 - val_loss: 0.5668 - val_accuracy: 0.7367 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3457 - accuracy: 0.8522 - val_loss: 0.5661 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3380 - accuracy: 0.8442 - val_loss: 0.5666 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3439 - accuracy: 0.8397 - val_loss: 0.5669 - val_accuracy: 0.7509 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3411 - accuracy: 0.8451 - val_loss: 0.5668 - val_accuracy: 0.7544 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3368 - accuracy: 0.8326 - val_loss: 0.5676 - val_accuracy: 0.7473 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3373 - accuracy: 0.8424 - val_loss: 0.5674 - val_accuracy: 0.7544 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3462 - accuracy: 0.8424 - val_loss: 0.5689 - val_accuracy: 0.7544 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3362 - accuracy: 0.8451 - val_loss: 0.5700 - val_accuracy: 0.7544 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3411 - accuracy: 0.8477 - val_loss: 0.5693 - val_accuracy: 0.7544 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3429 - accuracy: 0.8433 - val_loss: 0.5685 - val_accuracy: 0.7544 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3467 - accuracy: 0.8522 - val_loss: 0.5694 - val_accuracy: 0.7509 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3383 - accuracy: 0.8397 - val_loss: 0.5694 - val_accuracy: 0.7509 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3373 - accuracy: 0.8504 - val_loss: 0.5696 - val_accuracy: 0.7509 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3328 - accuracy: 0.8442 - val_loss: 0.5696 - val_accuracy: 0.7509 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3380 - accuracy: 0.8451 - val_loss: 0.5696 - val_accuracy: 0.7509 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3327 - accuracy: 0.8549 - val_loss: 0.5697 - val_accuracy: 0.7509 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3404 - accuracy: 0.8468 - val_loss: 0.5697 - val_accuracy: 0.7509 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3400 - accuracy: 0.8468 - val_loss: 0.5699 - val_accuracy: 0.7509 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3427 - accuracy: 0.8451 - val_loss: 0.5700 - val_accuracy: 0.7509 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3406 - accuracy: 0.8433 - val_loss: 0.5699 - val_accuracy: 0.7509 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3383 - accuracy: 0.8362 - val_loss: 0.5697 - val_accuracy: 0.7509 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3329 - accuracy: 0.8486 - val_loss: 0.5699 - val_accuracy: 0.7509 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3402 - accuracy: 0.8388 - val_loss: 0.5699 - val_accuracy: 0.7509 - lr: 1.0156e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 0.9209 - accuracy: 0.6020 - val_loss: 0.6949 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6008 - accuracy: 0.6759 - val_loss: 0.7087 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5648 - accuracy: 0.7142 - val_loss: 0.7247 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5248 - accuracy: 0.7498 - val_loss: 0.7271 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4955 - accuracy: 0.7498 - val_loss: 0.7240 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4716 - accuracy: 0.7542 - val_loss: 0.6758 - val_accuracy: 0.5587 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4577 - accuracy: 0.7916 - val_loss: 0.6290 - val_accuracy: 0.6406 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4459 - accuracy: 0.7854 - val_loss: 0.6336 - val_accuracy: 0.6370 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4219 - accuracy: 0.8014 - val_loss: 0.6373 - val_accuracy: 0.6655 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.4112 - accuracy: 0.8005 - val_loss: 0.6872 - val_accuracy: 0.6655 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3979 - accuracy: 0.8219 - val_loss: 0.7266 - val_accuracy: 0.6797 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3722 - accuracy: 0.8201 - val_loss: 0.7450 - val_accuracy: 0.6797 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3668 - accuracy: 0.8362 - val_loss: 0.7811 - val_accuracy: 0.6797 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3590 - accuracy: 0.8362 - val_loss: 0.7863 - val_accuracy: 0.6797 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3398 - accuracy: 0.8451 - val_loss: 0.8103 - val_accuracy: 0.6762 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3405 - accuracy: 0.8362 - val_loss: 0.7988 - val_accuracy: 0.6690 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3435 - accuracy: 0.8415 - val_loss: 0.8034 - val_accuracy: 0.6726 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3252 - accuracy: 0.8522 - val_loss: 0.7876 - val_accuracy: 0.6690 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3173 - accuracy: 0.8655 - val_loss: 0.8389 - val_accuracy: 0.6762 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3193 - accuracy: 0.8602 - val_loss: 0.8157 - val_accuracy: 0.6797 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3106 - accuracy: 0.8664 - val_loss: 0.8111 - val_accuracy: 0.6726 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3095 - accuracy: 0.8762 - val_loss: 0.8155 - val_accuracy: 0.6726 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3122 - accuracy: 0.8655 - val_loss: 0.8140 - val_accuracy: 0.6797 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3019 - accuracy: 0.8709 - val_loss: 0.8305 - val_accuracy: 0.6726 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3061 - accuracy: 0.8727 - val_loss: 0.8214 - val_accuracy: 0.6762 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3128 - accuracy: 0.8620 - val_loss: 0.8350 - val_accuracy: 0.6833 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3039 - accuracy: 0.8646 - val_loss: 0.8209 - val_accuracy: 0.6868 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2831 - accuracy: 0.8771 - val_loss: 0.8262 - val_accuracy: 0.6726 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2874 - accuracy: 0.8816 - val_loss: 0.8363 - val_accuracy: 0.6690 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2997 - accuracy: 0.8700 - val_loss: 0.8307 - val_accuracy: 0.6797 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3015 - accuracy: 0.8700 - val_loss: 0.8327 - val_accuracy: 0.6833 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2885 - accuracy: 0.8753 - val_loss: 0.8328 - val_accuracy: 0.6797 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2950 - accuracy: 0.8771 - val_loss: 0.8353 - val_accuracy: 0.6797 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2962 - accuracy: 0.8816 - val_loss: 0.8334 - val_accuracy: 0.6797 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2965 - accuracy: 0.8816 - val_loss: 0.8343 - val_accuracy: 0.6797 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2909 - accuracy: 0.8807 - val_loss: 0.8376 - val_accuracy: 0.6726 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2935 - accuracy: 0.8753 - val_loss: 0.8347 - val_accuracy: 0.6762 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2875 - accuracy: 0.8780 - val_loss: 0.8351 - val_accuracy: 0.6797 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2908 - accuracy: 0.8709 - val_loss: 0.8356 - val_accuracy: 0.6797 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3014 - accuracy: 0.8727 - val_loss: 0.8345 - val_accuracy: 0.6797 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2857 - accuracy: 0.8771 - val_loss: 0.8371 - val_accuracy: 0.6797 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2946 - accuracy: 0.8718 - val_loss: 0.8370 - val_accuracy: 0.6797 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2936 - accuracy: 0.8762 - val_loss: 0.8364 - val_accuracy: 0.6797 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2903 - accuracy: 0.8860 - val_loss: 0.8349 - val_accuracy: 0.6833 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2914 - accuracy: 0.8718 - val_loss: 0.8355 - val_accuracy: 0.6833 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2941 - accuracy: 0.8655 - val_loss: 0.8359 - val_accuracy: 0.6762 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2905 - accuracy: 0.8744 - val_loss: 0.8364 - val_accuracy: 0.6762 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 2s 21ms/step - loss: 0.2879 - accuracy: 0.8851 - val_loss: 0.8366 - val_accuracy: 0.6762 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2894 - accuracy: 0.8736 - val_loss: 0.8374 - val_accuracy: 0.6762 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2862 - accuracy: 0.8771 - val_loss: 0.8381 - val_accuracy: 0.6762 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2843 - accuracy: 0.8869 - val_loss: 0.8382 - val_accuracy: 0.6762 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2883 - accuracy: 0.8682 - val_loss: 0.8388 - val_accuracy: 0.6762 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2898 - accuracy: 0.8753 - val_loss: 0.8383 - val_accuracy: 0.6762 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2955 - accuracy: 0.8744 - val_loss: 0.8388 - val_accuracy: 0.6762 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3010 - accuracy: 0.8798 - val_loss: 0.8384 - val_accuracy: 0.6762 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2942 - accuracy: 0.8851 - val_loss: 0.8384 - val_accuracy: 0.6762 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3077 - accuracy: 0.8638 - val_loss: 0.8380 - val_accuracy: 0.6762 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2905 - accuracy: 0.8736 - val_loss: 0.8385 - val_accuracy: 0.6762 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2924 - accuracy: 0.8700 - val_loss: 0.8388 - val_accuracy: 0.6762 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3020 - accuracy: 0.8753 - val_loss: 0.8386 - val_accuracy: 0.6762 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.2699 - accuracy: 0.8833 - val_loss: 0.8382 - val_accuracy: 0.6762 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2858 - accuracy: 0.8771 - val_loss: 0.8384 - val_accuracy: 0.6762 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2988 - accuracy: 0.8691 - val_loss: 0.8383 - val_accuracy: 0.6762 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2896 - accuracy: 0.8825 - val_loss: 0.8382 - val_accuracy: 0.6762 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2934 - accuracy: 0.8718 - val_loss: 0.8384 - val_accuracy: 0.6762 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2886 - accuracy: 0.8825 - val_loss: 0.8386 - val_accuracy: 0.6762 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2922 - accuracy: 0.8744 - val_loss: 0.8392 - val_accuracy: 0.6762 - lr: 1.3162e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 1.3717 - accuracy: 0.6358 - val_loss: 0.6918 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.5565 - accuracy: 0.6981 - val_loss: 0.6899 - val_accuracy: 0.5658 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.5084 - accuracy: 0.7435 - val_loss: 0.6898 - val_accuracy: 0.5730 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.4780 - accuracy: 0.7596 - val_loss: 0.6689 - val_accuracy: 0.5730 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4565 - accuracy: 0.7827 - val_loss: 0.6409 - val_accuracy: 0.6477 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4222 - accuracy: 0.8005 - val_loss: 0.6019 - val_accuracy: 0.6940 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4058 - accuracy: 0.8201 - val_loss: 0.5644 - val_accuracy: 0.7295 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3802 - accuracy: 0.8246 - val_loss: 0.5372 - val_accuracy: 0.7331 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3468 - accuracy: 0.8335 - val_loss: 0.5631 - val_accuracy: 0.6975 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3214 - accuracy: 0.8655 - val_loss: 0.6451 - val_accuracy: 0.6868 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3237 - accuracy: 0.8513 - val_loss: 0.5984 - val_accuracy: 0.7046 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2932 - accuracy: 0.8673 - val_loss: 0.6094 - val_accuracy: 0.7046 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2826 - accuracy: 0.8762 - val_loss: 0.6175 - val_accuracy: 0.7224 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2658 - accuracy: 0.8860 - val_loss: 0.6957 - val_accuracy: 0.6975 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2616 - accuracy: 0.8940 - val_loss: 0.6443 - val_accuracy: 0.7189 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2543 - accuracy: 0.9020 - val_loss: 0.6474 - val_accuracy: 0.6975 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2520 - accuracy: 0.8931 - val_loss: 0.6603 - val_accuracy: 0.6975 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2376 - accuracy: 0.9038 - val_loss: 0.6634 - val_accuracy: 0.7117 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2443 - accuracy: 0.8958 - val_loss: 0.6608 - val_accuracy: 0.7011 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2325 - accuracy: 0.9065 - val_loss: 0.6590 - val_accuracy: 0.7189 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2222 - accuracy: 0.9216 - val_loss: 0.6628 - val_accuracy: 0.7046 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2217 - accuracy: 0.9020 - val_loss: 0.6679 - val_accuracy: 0.7082 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2246 - accuracy: 0.9065 - val_loss: 0.6578 - val_accuracy: 0.7117 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2160 - accuracy: 0.9154 - val_loss: 0.6640 - val_accuracy: 0.7011 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2306 - accuracy: 0.9038 - val_loss: 0.6643 - val_accuracy: 0.7046 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2204 - accuracy: 0.9163 - val_loss: 0.6656 - val_accuracy: 0.7082 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2131 - accuracy: 0.9065 - val_loss: 0.6672 - val_accuracy: 0.7082 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 0.6737 - val_accuracy: 0.7011 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2009 - accuracy: 0.9243 - val_loss: 0.6749 - val_accuracy: 0.7082 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2079 - accuracy: 0.9199 - val_loss: 0.6741 - val_accuracy: 0.7117 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2108 - accuracy: 0.9127 - val_loss: 0.6783 - val_accuracy: 0.7011 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.1970 - accuracy: 0.9332 - val_loss: 0.6823 - val_accuracy: 0.7046 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2039 - accuracy: 0.9101 - val_loss: 0.6810 - val_accuracy: 0.7046 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2125 - accuracy: 0.9136 - val_loss: 0.6819 - val_accuracy: 0.7046 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2013 - accuracy: 0.9261 - val_loss: 0.6830 - val_accuracy: 0.7082 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.1994 - accuracy: 0.9225 - val_loss: 0.6828 - val_accuracy: 0.7082 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2003 - accuracy: 0.9252 - val_loss: 0.6832 - val_accuracy: 0.7046 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.1956 - accuracy: 0.9279 - val_loss: 0.6832 - val_accuracy: 0.7046 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2109 - accuracy: 0.9199 - val_loss: 0.6840 - val_accuracy: 0.7046 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2071 - accuracy: 0.9181 - val_loss: 0.6858 - val_accuracy: 0.7082 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2065 - accuracy: 0.9172 - val_loss: 0.6842 - val_accuracy: 0.7082 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2080 - accuracy: 0.9145 - val_loss: 0.6841 - val_accuracy: 0.7082 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.1989 - accuracy: 0.9190 - val_loss: 0.6847 - val_accuracy: 0.7046 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2183 - accuracy: 0.9092 - val_loss: 0.6846 - val_accuracy: 0.7046 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2108 - accuracy: 0.9181 - val_loss: 0.6845 - val_accuracy: 0.7046 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2154 - accuracy: 0.9127 - val_loss: 0.6841 - val_accuracy: 0.7046 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 0.6835 - val_accuracy: 0.7082 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2050 - accuracy: 0.9127 - val_loss: 0.6834 - val_accuracy: 0.7046 - lr: 2.8211e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 0.9618 - accuracy: 0.5779 - val_loss: 0.7123 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.6278 - accuracy: 0.6572 - val_loss: 0.7818 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.6192 - accuracy: 0.6554 - val_loss: 0.7823 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.5645 - accuracy: 0.7088 - val_loss: 0.7519 - val_accuracy: 0.4804 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5229 - accuracy: 0.7444 - val_loss: 0.7209 - val_accuracy: 0.4875 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4889 - accuracy: 0.7694 - val_loss: 0.6917 - val_accuracy: 0.5338 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4821 - accuracy: 0.7614 - val_loss: 0.6064 - val_accuracy: 0.6548 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4586 - accuracy: 0.7667 - val_loss: 0.5796 - val_accuracy: 0.6868 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4323 - accuracy: 0.7934 - val_loss: 0.5816 - val_accuracy: 0.6975 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4206 - accuracy: 0.7890 - val_loss: 0.5852 - val_accuracy: 0.7260 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4203 - accuracy: 0.7979 - val_loss: 0.5641 - val_accuracy: 0.7331 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3917 - accuracy: 0.8192 - val_loss: 0.5971 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3895 - accuracy: 0.8139 - val_loss: 0.6341 - val_accuracy: 0.7331 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3794 - accuracy: 0.8183 - val_loss: 0.5841 - val_accuracy: 0.6797 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3842 - accuracy: 0.8130 - val_loss: 0.6203 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3578 - accuracy: 0.8335 - val_loss: 0.6053 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3551 - accuracy: 0.8353 - val_loss: 0.6640 - val_accuracy: 0.7509 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3377 - accuracy: 0.8486 - val_loss: 0.6446 - val_accuracy: 0.7473 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3356 - accuracy: 0.8540 - val_loss: 0.6458 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3353 - accuracy: 0.8459 - val_loss: 0.6625 - val_accuracy: 0.7367 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3197 - accuracy: 0.8459 - val_loss: 0.6570 - val_accuracy: 0.7402 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3074 - accuracy: 0.8709 - val_loss: 0.6692 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3194 - accuracy: 0.8593 - val_loss: 0.6632 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3233 - accuracy: 0.8575 - val_loss: 0.6400 - val_accuracy: 0.7367 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3161 - accuracy: 0.8593 - val_loss: 0.6545 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3212 - accuracy: 0.8549 - val_loss: 0.6493 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3144 - accuracy: 0.8575 - val_loss: 0.6483 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3156 - accuracy: 0.8584 - val_loss: 0.6587 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3081 - accuracy: 0.8673 - val_loss: 0.6627 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3058 - accuracy: 0.8700 - val_loss: 0.6658 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3207 - accuracy: 0.8495 - val_loss: 0.6547 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2924 - accuracy: 0.8798 - val_loss: 0.6634 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.8646 - val_loss: 0.6622 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3054 - accuracy: 0.8700 - val_loss: 0.6637 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2963 - accuracy: 0.8700 - val_loss: 0.6671 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3054 - accuracy: 0.8664 - val_loss: 0.6672 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3058 - accuracy: 0.8682 - val_loss: 0.6656 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3010 - accuracy: 0.8798 - val_loss: 0.6647 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3025 - accuracy: 0.8646 - val_loss: 0.6631 - val_accuracy: 0.7438 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3013 - accuracy: 0.8646 - val_loss: 0.6630 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3019 - accuracy: 0.8655 - val_loss: 0.6637 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3013 - accuracy: 0.8753 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3024 - accuracy: 0.8718 - val_loss: 0.6648 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3038 - accuracy: 0.8611 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3065 - accuracy: 0.8638 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3062 - accuracy: 0.8629 - val_loss: 0.6649 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3052 - accuracy: 0.8718 - val_loss: 0.6643 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3045 - accuracy: 0.8655 - val_loss: 0.6644 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2920 - accuracy: 0.8673 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2948 - accuracy: 0.8718 - val_loss: 0.6648 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.2964 - accuracy: 0.8825 - val_loss: 0.6646 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2932 - accuracy: 0.8780 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3023 - accuracy: 0.8566 - val_loss: 0.6642 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2921 - accuracy: 0.8736 - val_loss: 0.6648 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2977 - accuracy: 0.8753 - val_loss: 0.6641 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2874 - accuracy: 0.8753 - val_loss: 0.6645 - val_accuracy: 0.7402 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3006 - accuracy: 0.8646 - val_loss: 0.6647 - val_accuracy: 0.7402 - lr: 6.0936e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 1.6049 - accuracy: 0.5735 - val_loss: 0.6756 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6567 - accuracy: 0.6171 - val_loss: 0.6838 - val_accuracy: 0.5302 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5772 - accuracy: 0.6785 - val_loss: 0.6149 - val_accuracy: 0.6441 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5437 - accuracy: 0.7168 - val_loss: 0.5976 - val_accuracy: 0.6726 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.5312 - accuracy: 0.7373 - val_loss: 0.5508 - val_accuracy: 0.7153 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.4795 - accuracy: 0.7676 - val_loss: 0.5395 - val_accuracy: 0.7011 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.4784 - accuracy: 0.7569 - val_loss: 0.5141 - val_accuracy: 0.7260 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4551 - accuracy: 0.7747 - val_loss: 0.4882 - val_accuracy: 0.7616 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4345 - accuracy: 0.7934 - val_loss: 0.4887 - val_accuracy: 0.7758 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4092 - accuracy: 0.8094 - val_loss: 0.4912 - val_accuracy: 0.7829 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4060 - accuracy: 0.8166 - val_loss: 0.5168 - val_accuracy: 0.7402 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3839 - accuracy: 0.8210 - val_loss: 0.5072 - val_accuracy: 0.7473 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3799 - accuracy: 0.8281 - val_loss: 0.4975 - val_accuracy: 0.7580 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3638 - accuracy: 0.8353 - val_loss: 0.5163 - val_accuracy: 0.7509 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3467 - accuracy: 0.8522 - val_loss: 0.5045 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3477 - accuracy: 0.8424 - val_loss: 0.4924 - val_accuracy: 0.7687 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3381 - accuracy: 0.8540 - val_loss: 0.4969 - val_accuracy: 0.7651 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3227 - accuracy: 0.8664 - val_loss: 0.4971 - val_accuracy: 0.7722 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 2s 21ms/step - loss: 0.3195 - accuracy: 0.8584 - val_loss: 0.4858 - val_accuracy: 0.7616 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3072 - accuracy: 0.8789 - val_loss: 0.5107 - val_accuracy: 0.7580 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3197 - accuracy: 0.8575 - val_loss: 0.5179 - val_accuracy: 0.7473 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3024 - accuracy: 0.8744 - val_loss: 0.5148 - val_accuracy: 0.7616 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3123 - accuracy: 0.8655 - val_loss: 0.4993 - val_accuracy: 0.7687 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3038 - accuracy: 0.8736 - val_loss: 0.5066 - val_accuracy: 0.7580 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3004 - accuracy: 0.8718 - val_loss: 0.5080 - val_accuracy: 0.7544 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3104 - accuracy: 0.8646 - val_loss: 0.5149 - val_accuracy: 0.7580 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2971 - accuracy: 0.8709 - val_loss: 0.5133 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2858 - accuracy: 0.8780 - val_loss: 0.5201 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3063 - accuracy: 0.8736 - val_loss: 0.5248 - val_accuracy: 0.7580 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2884 - accuracy: 0.8851 - val_loss: 0.5216 - val_accuracy: 0.7616 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2948 - accuracy: 0.8753 - val_loss: 0.5202 - val_accuracy: 0.7616 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 2s 21ms/step - loss: 0.2863 - accuracy: 0.8825 - val_loss: 0.5205 - val_accuracy: 0.7616 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2785 - accuracy: 0.8807 - val_loss: 0.5231 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2973 - accuracy: 0.8753 - val_loss: 0.5232 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2877 - accuracy: 0.8851 - val_loss: 0.5207 - val_accuracy: 0.7616 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2901 - accuracy: 0.8744 - val_loss: 0.5221 - val_accuracy: 0.7616 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2780 - accuracy: 0.8878 - val_loss: 0.5223 - val_accuracy: 0.7616 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2870 - accuracy: 0.8762 - val_loss: 0.5230 - val_accuracy: 0.7616 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2810 - accuracy: 0.8780 - val_loss: 0.5237 - val_accuracy: 0.7616 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2927 - accuracy: 0.8718 - val_loss: 0.5239 - val_accuracy: 0.7616 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2836 - accuracy: 0.8771 - val_loss: 0.5236 - val_accuracy: 0.7616 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2853 - accuracy: 0.8807 - val_loss: 0.5239 - val_accuracy: 0.7616 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.2890 - accuracy: 0.8780 - val_loss: 0.5234 - val_accuracy: 0.7616 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.2887 - accuracy: 0.8780 - val_loss: 0.5226 - val_accuracy: 0.7616 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2717 - accuracy: 0.8887 - val_loss: 0.5229 - val_accuracy: 0.7616 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2861 - accuracy: 0.8807 - val_loss: 0.5225 - val_accuracy: 0.7616 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2890 - accuracy: 0.8700 - val_loss: 0.5223 - val_accuracy: 0.7616 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2909 - accuracy: 0.8780 - val_loss: 0.5227 - val_accuracy: 0.7616 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2795 - accuracy: 0.8860 - val_loss: 0.5228 - val_accuracy: 0.7616 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2907 - accuracy: 0.8709 - val_loss: 0.5229 - val_accuracy: 0.7616 - lr: 2.8211e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 16ms/step - loss: 1.0772 - accuracy: 0.5263 - val_loss: 0.6908 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6767 - accuracy: 0.5521 - val_loss: 0.6911 - val_accuracy: 0.6085 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6165 - accuracy: 0.6242 - val_loss: 0.6798 - val_accuracy: 0.5587 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5623 - accuracy: 0.6545 - val_loss: 0.6592 - val_accuracy: 0.6548 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5486 - accuracy: 0.6803 - val_loss: 0.6488 - val_accuracy: 0.7295 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5055 - accuracy: 0.7079 - val_loss: 0.6238 - val_accuracy: 0.7189 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.5156 - accuracy: 0.6999 - val_loss: 0.5777 - val_accuracy: 0.7189 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4976 - accuracy: 0.7159 - val_loss: 0.5013 - val_accuracy: 0.7473 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4885 - accuracy: 0.7346 - val_loss: 0.4763 - val_accuracy: 0.7651 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4780 - accuracy: 0.7346 - val_loss: 0.4763 - val_accuracy: 0.7544 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4565 - accuracy: 0.7685 - val_loss: 0.4735 - val_accuracy: 0.7438 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4612 - accuracy: 0.7533 - val_loss: 0.4938 - val_accuracy: 0.7936 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4427 - accuracy: 0.7649 - val_loss: 0.4760 - val_accuracy: 0.7794 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4237 - accuracy: 0.7676 - val_loss: 0.4751 - val_accuracy: 0.7758 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4290 - accuracy: 0.7738 - val_loss: 0.5078 - val_accuracy: 0.7829 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4101 - accuracy: 0.7872 - val_loss: 0.4857 - val_accuracy: 0.7829 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4298 - accuracy: 0.7845 - val_loss: 0.4801 - val_accuracy: 0.7794 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3904 - accuracy: 0.7961 - val_loss: 0.4750 - val_accuracy: 0.7687 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3919 - accuracy: 0.8050 - val_loss: 0.4689 - val_accuracy: 0.7687 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3866 - accuracy: 0.7970 - val_loss: 0.4737 - val_accuracy: 0.7687 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3837 - accuracy: 0.7934 - val_loss: 0.4734 - val_accuracy: 0.7651 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3767 - accuracy: 0.8050 - val_loss: 0.4752 - val_accuracy: 0.7794 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3778 - accuracy: 0.8023 - val_loss: 0.4852 - val_accuracy: 0.7900 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3720 - accuracy: 0.8059 - val_loss: 0.4806 - val_accuracy: 0.7687 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3822 - accuracy: 0.8059 - val_loss: 0.4804 - val_accuracy: 0.7865 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3662 - accuracy: 0.8121 - val_loss: 0.4818 - val_accuracy: 0.7722 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3609 - accuracy: 0.8157 - val_loss: 0.4770 - val_accuracy: 0.7687 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3657 - accuracy: 0.8183 - val_loss: 0.4775 - val_accuracy: 0.7722 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3727 - accuracy: 0.8032 - val_loss: 0.4795 - val_accuracy: 0.7722 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3704 - accuracy: 0.8023 - val_loss: 0.4781 - val_accuracy: 0.7722 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3631 - accuracy: 0.8094 - val_loss: 0.4795 - val_accuracy: 0.7722 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3662 - accuracy: 0.8077 - val_loss: 0.4797 - val_accuracy: 0.7794 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3696 - accuracy: 0.8166 - val_loss: 0.4795 - val_accuracy: 0.7722 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3631 - accuracy: 0.8068 - val_loss: 0.4818 - val_accuracy: 0.7758 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3569 - accuracy: 0.8103 - val_loss: 0.4816 - val_accuracy: 0.7722 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3634 - accuracy: 0.8237 - val_loss: 0.4815 - val_accuracy: 0.7758 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3614 - accuracy: 0.8148 - val_loss: 0.4819 - val_accuracy: 0.7758 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3636 - accuracy: 0.8112 - val_loss: 0.4806 - val_accuracy: 0.7758 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3646 - accuracy: 0.8121 - val_loss: 0.4808 - val_accuracy: 0.7722 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3571 - accuracy: 0.8192 - val_loss: 0.4807 - val_accuracy: 0.7722 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3585 - accuracy: 0.8094 - val_loss: 0.4808 - val_accuracy: 0.7722 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3558 - accuracy: 0.8290 - val_loss: 0.4808 - val_accuracy: 0.7722 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3718 - accuracy: 0.8130 - val_loss: 0.4812 - val_accuracy: 0.7687 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3531 - accuracy: 0.8219 - val_loss: 0.4816 - val_accuracy: 0.7687 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3609 - accuracy: 0.8094 - val_loss: 0.4815 - val_accuracy: 0.7687 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3708 - accuracy: 0.8094 - val_loss: 0.4815 - val_accuracy: 0.7722 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.3641 - accuracy: 0.8183 - val_loss: 0.4814 - val_accuracy: 0.7722 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3659 - accuracy: 0.8068 - val_loss: 0.4814 - val_accuracy: 0.7722 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3641 - accuracy: 0.8175 - val_loss: 0.4814 - val_accuracy: 0.7722 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3649 - accuracy: 0.8094 - val_loss: 0.4813 - val_accuracy: 0.7722 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3565 - accuracy: 0.8210 - val_loss: 0.4814 - val_accuracy: 0.7722 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3614 - accuracy: 0.8094 - val_loss: 0.4814 - val_accuracy: 0.7722 - lr: 1.6927e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 0.8782 - accuracy: 0.6020 - val_loss: 0.6942 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5971 - accuracy: 0.6883 - val_loss: 0.7013 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.5441 - accuracy: 0.7008 - val_loss: 0.6980 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.5626 - accuracy: 0.7070 - val_loss: 0.6886 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5213 - accuracy: 0.7248 - val_loss: 0.6613 - val_accuracy: 0.5979 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4896 - accuracy: 0.7320 - val_loss: 0.6214 - val_accuracy: 0.7011 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4731 - accuracy: 0.7605 - val_loss: 0.6033 - val_accuracy: 0.6619 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4596 - accuracy: 0.7818 - val_loss: 0.5650 - val_accuracy: 0.6940 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4465 - accuracy: 0.7836 - val_loss: 0.5986 - val_accuracy: 0.6904 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4493 - accuracy: 0.7720 - val_loss: 0.5530 - val_accuracy: 0.7011 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4293 - accuracy: 0.7881 - val_loss: 0.6207 - val_accuracy: 0.7153 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4061 - accuracy: 0.7979 - val_loss: 0.5637 - val_accuracy: 0.7011 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4032 - accuracy: 0.8139 - val_loss: 0.5456 - val_accuracy: 0.7082 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3966 - accuracy: 0.8023 - val_loss: 0.5786 - val_accuracy: 0.7260 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3911 - accuracy: 0.8068 - val_loss: 0.5742 - val_accuracy: 0.7295 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3642 - accuracy: 0.8299 - val_loss: 0.5824 - val_accuracy: 0.7082 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.3745 - accuracy: 0.8255 - val_loss: 0.5763 - val_accuracy: 0.7117 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 0.3597 - accuracy: 0.8353 - val_loss: 0.6055 - val_accuracy: 0.7331 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3544 - accuracy: 0.8370 - val_loss: 0.6054 - val_accuracy: 0.7011 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3582 - accuracy: 0.8335 - val_loss: 0.5935 - val_accuracy: 0.7117 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3460 - accuracy: 0.8424 - val_loss: 0.5898 - val_accuracy: 0.7117 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3509 - accuracy: 0.8353 - val_loss: 0.5715 - val_accuracy: 0.7189 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3599 - accuracy: 0.8370 - val_loss: 0.5899 - val_accuracy: 0.7046 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3449 - accuracy: 0.8468 - val_loss: 0.5994 - val_accuracy: 0.7046 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3443 - accuracy: 0.8486 - val_loss: 0.5994 - val_accuracy: 0.7082 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3297 - accuracy: 0.8593 - val_loss: 0.6066 - val_accuracy: 0.7082 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3356 - accuracy: 0.8513 - val_loss: 0.5930 - val_accuracy: 0.7153 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3366 - accuracy: 0.8451 - val_loss: 0.5965 - val_accuracy: 0.7189 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3279 - accuracy: 0.8566 - val_loss: 0.6011 - val_accuracy: 0.7046 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3449 - accuracy: 0.8335 - val_loss: 0.5978 - val_accuracy: 0.7046 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3351 - accuracy: 0.8477 - val_loss: 0.5947 - val_accuracy: 0.7117 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3264 - accuracy: 0.8540 - val_loss: 0.5974 - val_accuracy: 0.7153 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3218 - accuracy: 0.8566 - val_loss: 0.6018 - val_accuracy: 0.7082 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3251 - accuracy: 0.8477 - val_loss: 0.6025 - val_accuracy: 0.7153 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3322 - accuracy: 0.8593 - val_loss: 0.5998 - val_accuracy: 0.7153 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3395 - accuracy: 0.8397 - val_loss: 0.6006 - val_accuracy: 0.7117 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3343 - accuracy: 0.8531 - val_loss: 0.5998 - val_accuracy: 0.7117 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3314 - accuracy: 0.8522 - val_loss: 0.5994 - val_accuracy: 0.7117 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3412 - accuracy: 0.8477 - val_loss: 0.5995 - val_accuracy: 0.7117 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3336 - accuracy: 0.8495 - val_loss: 0.6002 - val_accuracy: 0.7117 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3348 - accuracy: 0.8531 - val_loss: 0.6011 - val_accuracy: 0.7082 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3312 - accuracy: 0.8468 - val_loss: 0.6009 - val_accuracy: 0.7082 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3306 - accuracy: 0.8451 - val_loss: 0.6009 - val_accuracy: 0.7082 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.3313 - accuracy: 0.8477 - val_loss: 0.6010 - val_accuracy: 0.7082 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3298 - accuracy: 0.8549 - val_loss: 0.6014 - val_accuracy: 0.7082 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3332 - accuracy: 0.8557 - val_loss: 0.6010 - val_accuracy: 0.7082 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3224 - accuracy: 0.8566 - val_loss: 0.6010 - val_accuracy: 0.7082 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3299 - accuracy: 0.8602 - val_loss: 0.6010 - val_accuracy: 0.7082 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3321 - accuracy: 0.8442 - val_loss: 0.6008 - val_accuracy: 0.7082 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3458 - accuracy: 0.8433 - val_loss: 0.6009 - val_accuracy: 0.7082 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3345 - accuracy: 0.8459 - val_loss: 0.6010 - val_accuracy: 0.7082 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3279 - accuracy: 0.8495 - val_loss: 0.6009 - val_accuracy: 0.7082 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3317 - accuracy: 0.8513 - val_loss: 0.6002 - val_accuracy: 0.7082 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3359 - accuracy: 0.8370 - val_loss: 0.6003 - val_accuracy: 0.7082 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3157 - accuracy: 0.8620 - val_loss: 0.6006 - val_accuracy: 0.7082 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3305 - accuracy: 0.8442 - val_loss: 0.6009 - val_accuracy: 0.7117 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3327 - accuracy: 0.8477 - val_loss: 0.6010 - val_accuracy: 0.7117 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3261 - accuracy: 0.8522 - val_loss: 0.6007 - val_accuracy: 0.7117 - lr: 6.0936e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 1.5620 - accuracy: 0.6367 - val_loss: 0.6691 - val_accuracy: 0.5765 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5496 - accuracy: 0.7195 - val_loss: 0.6564 - val_accuracy: 0.6548 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5424 - accuracy: 0.7079 - val_loss: 0.5952 - val_accuracy: 0.6904 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5013 - accuracy: 0.7293 - val_loss: 0.5927 - val_accuracy: 0.6868 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4863 - accuracy: 0.7631 - val_loss: 0.5809 - val_accuracy: 0.6868 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4549 - accuracy: 0.7827 - val_loss: 0.5257 - val_accuracy: 0.7438 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.4276 - accuracy: 0.8041 - val_loss: 0.5213 - val_accuracy: 0.7402 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4100 - accuracy: 0.8014 - val_loss: 0.5396 - val_accuracy: 0.7153 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3877 - accuracy: 0.8255 - val_loss: 0.5402 - val_accuracy: 0.7260 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3711 - accuracy: 0.8272 - val_loss: 0.5407 - val_accuracy: 0.7438 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3614 - accuracy: 0.8397 - val_loss: 0.5834 - val_accuracy: 0.6868 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3541 - accuracy: 0.8451 - val_loss: 0.5625 - val_accuracy: 0.7367 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3391 - accuracy: 0.8531 - val_loss: 0.5712 - val_accuracy: 0.7331 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3203 - accuracy: 0.8584 - val_loss: 0.5737 - val_accuracy: 0.7295 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3040 - accuracy: 0.8700 - val_loss: 0.5844 - val_accuracy: 0.7260 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3017 - accuracy: 0.8744 - val_loss: 0.5780 - val_accuracy: 0.7331 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3007 - accuracy: 0.8646 - val_loss: 0.6111 - val_accuracy: 0.7224 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2865 - accuracy: 0.8789 - val_loss: 0.6013 - val_accuracy: 0.7153 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.2854 - accuracy: 0.8762 - val_loss: 0.5974 - val_accuracy: 0.7260 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.2715 - accuracy: 0.8887 - val_loss: 0.6067 - val_accuracy: 0.7117 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2697 - accuracy: 0.8860 - val_loss: 0.5999 - val_accuracy: 0.7331 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2666 - accuracy: 0.8940 - val_loss: 0.6025 - val_accuracy: 0.7153 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2640 - accuracy: 0.8949 - val_loss: 0.5993 - val_accuracy: 0.7367 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2574 - accuracy: 0.8976 - val_loss: 0.6104 - val_accuracy: 0.7153 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2666 - accuracy: 0.8949 - val_loss: 0.6122 - val_accuracy: 0.7153 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2683 - accuracy: 0.9038 - val_loss: 0.6061 - val_accuracy: 0.7224 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2605 - accuracy: 0.8985 - val_loss: 0.6046 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2598 - accuracy: 0.8958 - val_loss: 0.6073 - val_accuracy: 0.7189 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2425 - accuracy: 0.9118 - val_loss: 0.6088 - val_accuracy: 0.7260 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2359 - accuracy: 0.9101 - val_loss: 0.6110 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2546 - accuracy: 0.8976 - val_loss: 0.6129 - val_accuracy: 0.7295 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2534 - accuracy: 0.9056 - val_loss: 0.6133 - val_accuracy: 0.7295 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.2631 - accuracy: 0.8931 - val_loss: 0.6113 - val_accuracy: 0.7224 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.2409 - accuracy: 0.9110 - val_loss: 0.6131 - val_accuracy: 0.7260 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2524 - accuracy: 0.9029 - val_loss: 0.6138 - val_accuracy: 0.7260 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2520 - accuracy: 0.8976 - val_loss: 0.6141 - val_accuracy: 0.7260 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2609 - accuracy: 0.8869 - val_loss: 0.6131 - val_accuracy: 0.7260 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2519 - accuracy: 0.9012 - val_loss: 0.6141 - val_accuracy: 0.7189 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2412 - accuracy: 0.9154 - val_loss: 0.6138 - val_accuracy: 0.7224 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2514 - accuracy: 0.8958 - val_loss: 0.6143 - val_accuracy: 0.7224 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2375 - accuracy: 0.9110 - val_loss: 0.6151 - val_accuracy: 0.7224 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2437 - accuracy: 0.9038 - val_loss: 0.6149 - val_accuracy: 0.7224 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.2413 - accuracy: 0.9065 - val_loss: 0.6149 - val_accuracy: 0.7224 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.2528 - accuracy: 0.8931 - val_loss: 0.6147 - val_accuracy: 0.7224 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.2442 - accuracy: 0.9038 - val_loss: 0.6145 - val_accuracy: 0.7224 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.2539 - accuracy: 0.9065 - val_loss: 0.6142 - val_accuracy: 0.7224 - lr: 4.7018e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 15ms/step - loss: 1.9195 - accuracy: 0.5138 - val_loss: 0.6948 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6960 - accuracy: 0.5334 - val_loss: 1.5551 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.7136 - accuracy: 0.5102 - val_loss: 0.6937 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6785 - accuracy: 0.5601 - val_loss: 0.5850 - val_accuracy: 0.7224 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6304 - accuracy: 0.6492 - val_loss: 0.6025 - val_accuracy: 0.6904 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5942 - accuracy: 0.6910 - val_loss: 0.5651 - val_accuracy: 0.7153 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5773 - accuracy: 0.7079 - val_loss: 0.5595 - val_accuracy: 0.7224 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.5859 - accuracy: 0.6999 - val_loss: 0.5357 - val_accuracy: 0.7473 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.5712 - accuracy: 0.6990 - val_loss: 0.5452 - val_accuracy: 0.7331 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.5596 - accuracy: 0.7088 - val_loss: 0.5486 - val_accuracy: 0.7473 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5530 - accuracy: 0.7329 - val_loss: 0.5413 - val_accuracy: 0.7367 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5493 - accuracy: 0.7257 - val_loss: 0.5445 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5399 - accuracy: 0.7302 - val_loss: 0.5328 - val_accuracy: 0.7260 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5424 - accuracy: 0.7329 - val_loss: 0.5316 - val_accuracy: 0.7473 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5245 - accuracy: 0.7427 - val_loss: 0.5351 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5268 - accuracy: 0.7453 - val_loss: 0.5303 - val_accuracy: 0.7544 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5197 - accuracy: 0.7489 - val_loss: 0.5314 - val_accuracy: 0.7509 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5110 - accuracy: 0.7489 - val_loss: 0.5291 - val_accuracy: 0.7260 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4963 - accuracy: 0.7533 - val_loss: 0.5303 - val_accuracy: 0.7473 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5002 - accuracy: 0.7720 - val_loss: 0.5272 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5123 - accuracy: 0.7453 - val_loss: 0.5258 - val_accuracy: 0.7367 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.5075 - accuracy: 0.7596 - val_loss: 0.5252 - val_accuracy: 0.7616 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.5047 - accuracy: 0.7578 - val_loss: 0.5289 - val_accuracy: 0.7509 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5123 - accuracy: 0.7587 - val_loss: 0.5255 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4873 - accuracy: 0.7756 - val_loss: 0.5243 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5297 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4974 - accuracy: 0.7551 - val_loss: 0.5249 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4893 - accuracy: 0.7676 - val_loss: 0.5243 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4940 - accuracy: 0.7587 - val_loss: 0.5229 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5072 - accuracy: 0.7507 - val_loss: 0.5224 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4932 - accuracy: 0.7711 - val_loss: 0.5229 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4909 - accuracy: 0.7676 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4933 - accuracy: 0.7747 - val_loss: 0.5231 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.5083 - accuracy: 0.7444 - val_loss: 0.5232 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.5007 - accuracy: 0.7560 - val_loss: 0.5233 - val_accuracy: 0.7509 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.4964 - accuracy: 0.7703 - val_loss: 0.5232 - val_accuracy: 0.7473 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4949 - accuracy: 0.7747 - val_loss: 0.5232 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5045 - accuracy: 0.7516 - val_loss: 0.5233 - val_accuracy: 0.7509 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5027 - accuracy: 0.7667 - val_loss: 0.5235 - val_accuracy: 0.7509 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4841 - accuracy: 0.7711 - val_loss: 0.5237 - val_accuracy: 0.7509 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4945 - accuracy: 0.7640 - val_loss: 0.5236 - val_accuracy: 0.7509 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4918 - accuracy: 0.7694 - val_loss: 0.5234 - val_accuracy: 0.7509 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4976 - accuracy: 0.7587 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4941 - accuracy: 0.7560 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4900 - accuracy: 0.7649 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4932 - accuracy: 0.7720 - val_loss: 0.5234 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.5146 - accuracy: 0.7507 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.4982 - accuracy: 0.7605 - val_loss: 0.5234 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.4915 - accuracy: 0.7640 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5141 - accuracy: 0.7427 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4970 - accuracy: 0.7622 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5057 - accuracy: 0.7533 - val_loss: 0.5232 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4899 - accuracy: 0.7738 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4855 - accuracy: 0.7809 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4944 - accuracy: 0.7631 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4948 - accuracy: 0.7498 - val_loss: 0.5232 - val_accuracy: 0.7473 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4868 - accuracy: 0.7747 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4955 - accuracy: 0.7667 - val_loss: 0.5232 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4912 - accuracy: 0.7676 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.4771 - accuracy: 0.7765 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.4981 - accuracy: 0.7614 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.4964 - accuracy: 0.7738 - val_loss: 0.5233 - val_accuracy: 0.7473 - lr: 3.6562e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 3s 25ms/step - loss: 0.9722 - accuracy: 0.5859 - val_loss: 0.7140 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6202 - accuracy: 0.6607 - val_loss: 0.7230 - val_accuracy: 0.4804 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6389 - accuracy: 0.6385 - val_loss: 0.7160 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5687 - accuracy: 0.7133 - val_loss: 0.7589 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5553 - accuracy: 0.7284 - val_loss: 0.7530 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.5140 - accuracy: 0.7551 - val_loss: 0.6719 - val_accuracy: 0.5801 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4968 - accuracy: 0.7551 - val_loss: 0.6283 - val_accuracy: 0.6370 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5052 - accuracy: 0.7551 - val_loss: 0.5451 - val_accuracy: 0.7260 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4619 - accuracy: 0.7854 - val_loss: 0.5563 - val_accuracy: 0.7260 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4721 - accuracy: 0.7783 - val_loss: 0.5495 - val_accuracy: 0.7224 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4526 - accuracy: 0.8005 - val_loss: 0.5867 - val_accuracy: 0.7295 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4485 - accuracy: 0.7934 - val_loss: 0.6005 - val_accuracy: 0.7260 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4253 - accuracy: 0.7996 - val_loss: 0.5748 - val_accuracy: 0.7367 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4296 - accuracy: 0.8103 - val_loss: 0.6331 - val_accuracy: 0.7189 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4211 - accuracy: 0.8068 - val_loss: 0.6023 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4106 - accuracy: 0.8121 - val_loss: 0.6091 - val_accuracy: 0.7189 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3989 - accuracy: 0.8308 - val_loss: 0.6084 - val_accuracy: 0.7402 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3725 - accuracy: 0.8388 - val_loss: 0.6212 - val_accuracy: 0.7331 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3734 - accuracy: 0.8379 - val_loss: 0.6158 - val_accuracy: 0.7295 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3827 - accuracy: 0.8406 - val_loss: 0.6096 - val_accuracy: 0.7367 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3681 - accuracy: 0.8433 - val_loss: 0.6251 - val_accuracy: 0.7438 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3658 - accuracy: 0.8504 - val_loss: 0.6127 - val_accuracy: 0.7331 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3662 - accuracy: 0.8495 - val_loss: 0.6078 - val_accuracy: 0.7331 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3632 - accuracy: 0.8468 - val_loss: 0.6140 - val_accuracy: 0.7367 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3611 - accuracy: 0.8593 - val_loss: 0.6122 - val_accuracy: 0.7295 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3574 - accuracy: 0.8477 - val_loss: 0.6231 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3695 - accuracy: 0.8495 - val_loss: 0.6189 - val_accuracy: 0.7295 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3541 - accuracy: 0.8468 - val_loss: 0.6250 - val_accuracy: 0.7331 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3520 - accuracy: 0.8620 - val_loss: 0.6220 - val_accuracy: 0.7331 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3478 - accuracy: 0.8638 - val_loss: 0.6225 - val_accuracy: 0.7331 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3493 - accuracy: 0.8620 - val_loss: 0.6247 - val_accuracy: 0.7331 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3483 - accuracy: 0.8629 - val_loss: 0.6240 - val_accuracy: 0.7331 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3360 - accuracy: 0.8709 - val_loss: 0.6224 - val_accuracy: 0.7295 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3543 - accuracy: 0.8540 - val_loss: 0.6243 - val_accuracy: 0.7295 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3548 - accuracy: 0.8540 - val_loss: 0.6233 - val_accuracy: 0.7295 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3532 - accuracy: 0.8611 - val_loss: 0.6222 - val_accuracy: 0.7295 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3481 - accuracy: 0.8655 - val_loss: 0.6208 - val_accuracy: 0.7295 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3453 - accuracy: 0.8575 - val_loss: 0.6227 - val_accuracy: 0.7295 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 2s 22ms/step - loss: 0.3479 - accuracy: 0.8504 - val_loss: 0.6228 - val_accuracy: 0.7295 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 2s 23ms/step - loss: 0.3509 - accuracy: 0.8566 - val_loss: 0.6229 - val_accuracy: 0.7295 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3435 - accuracy: 0.8593 - val_loss: 0.6240 - val_accuracy: 0.7295 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3475 - accuracy: 0.8540 - val_loss: 0.6248 - val_accuracy: 0.7331 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3449 - accuracy: 0.8629 - val_loss: 0.6246 - val_accuracy: 0.7331 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3348 - accuracy: 0.8718 - val_loss: 0.6250 - val_accuracy: 0.7331 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3506 - accuracy: 0.8602 - val_loss: 0.6250 - val_accuracy: 0.7331 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3446 - accuracy: 0.8584 - val_loss: 0.6250 - val_accuracy: 0.7331 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3454 - accuracy: 0.8513 - val_loss: 0.6245 - val_accuracy: 0.7331 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3467 - accuracy: 0.8638 - val_loss: 0.6247 - val_accuracy: 0.7331 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3499 - accuracy: 0.8513 - val_loss: 0.6250 - val_accuracy: 0.7331 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3379 - accuracy: 0.8682 - val_loss: 0.6248 - val_accuracy: 0.7331 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3477 - accuracy: 0.8718 - val_loss: 0.6249 - val_accuracy: 0.7331 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3477 - accuracy: 0.8664 - val_loss: 0.6247 - val_accuracy: 0.7331 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3489 - accuracy: 0.8557 - val_loss: 0.6245 - val_accuracy: 0.7331 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3524 - accuracy: 0.8549 - val_loss: 0.6246 - val_accuracy: 0.7331 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3432 - accuracy: 0.8540 - val_loss: 0.6244 - val_accuracy: 0.7331 - lr: 1.0156e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 17ms/step - loss: 1.0275 - accuracy: 0.6207 - val_loss: 0.7300 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6052 - accuracy: 0.6643 - val_loss: 0.6978 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5677 - accuracy: 0.7240 - val_loss: 0.7299 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.5440 - accuracy: 0.7168 - val_loss: 0.7049 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.5251 - accuracy: 0.7177 - val_loss: 0.6806 - val_accuracy: 0.5231 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.5040 - accuracy: 0.7293 - val_loss: 0.5934 - val_accuracy: 0.7153 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4705 - accuracy: 0.7649 - val_loss: 0.5507 - val_accuracy: 0.7117 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4647 - accuracy: 0.7809 - val_loss: 0.5442 - val_accuracy: 0.6833 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4562 - accuracy: 0.7738 - val_loss: 0.5227 - val_accuracy: 0.7117 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4296 - accuracy: 0.7943 - val_loss: 0.5117 - val_accuracy: 0.7260 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4380 - accuracy: 0.8014 - val_loss: 0.5257 - val_accuracy: 0.7153 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.4067 - accuracy: 0.8068 - val_loss: 0.5336 - val_accuracy: 0.6868 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4036 - accuracy: 0.8050 - val_loss: 0.5231 - val_accuracy: 0.7153 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4084 - accuracy: 0.8112 - val_loss: 0.5402 - val_accuracy: 0.7367 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3815 - accuracy: 0.8210 - val_loss: 0.5096 - val_accuracy: 0.7189 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3754 - accuracy: 0.8183 - val_loss: 0.5086 - val_accuracy: 0.7295 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3585 - accuracy: 0.8326 - val_loss: 0.5240 - val_accuracy: 0.7331 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3545 - accuracy: 0.8335 - val_loss: 0.5419 - val_accuracy: 0.7438 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3531 - accuracy: 0.8344 - val_loss: 0.5351 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3412 - accuracy: 0.8370 - val_loss: 0.5391 - val_accuracy: 0.7260 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3382 - accuracy: 0.8451 - val_loss: 0.5434 - val_accuracy: 0.7331 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3457 - accuracy: 0.8424 - val_loss: 0.5405 - val_accuracy: 0.7260 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3346 - accuracy: 0.8468 - val_loss: 0.5371 - val_accuracy: 0.7331 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3422 - accuracy: 0.8531 - val_loss: 0.5376 - val_accuracy: 0.7331 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3451 - accuracy: 0.8424 - val_loss: 0.5355 - val_accuracy: 0.7438 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3202 - accuracy: 0.8664 - val_loss: 0.5480 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3187 - accuracy: 0.8531 - val_loss: 0.5418 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3346 - accuracy: 0.8522 - val_loss: 0.5427 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.3212 - accuracy: 0.8477 - val_loss: 0.5438 - val_accuracy: 0.7402 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3378 - accuracy: 0.8522 - val_loss: 0.5403 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3327 - accuracy: 0.8629 - val_loss: 0.5431 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3261 - accuracy: 0.8522 - val_loss: 0.5437 - val_accuracy: 0.7438 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3142 - accuracy: 0.8611 - val_loss: 0.5449 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3164 - accuracy: 0.8709 - val_loss: 0.5448 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3286 - accuracy: 0.8575 - val_loss: 0.5444 - val_accuracy: 0.7402 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3296 - accuracy: 0.8557 - val_loss: 0.5450 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3206 - accuracy: 0.8664 - val_loss: 0.5447 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3212 - accuracy: 0.8646 - val_loss: 0.5433 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3159 - accuracy: 0.8709 - val_loss: 0.5435 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3120 - accuracy: 0.8638 - val_loss: 0.5444 - val_accuracy: 0.7438 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3263 - accuracy: 0.8584 - val_loss: 0.5446 - val_accuracy: 0.7438 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3144 - accuracy: 0.8664 - val_loss: 0.5449 - val_accuracy: 0.7438 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3283 - accuracy: 0.8504 - val_loss: 0.5449 - val_accuracy: 0.7402 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3213 - accuracy: 0.8522 - val_loss: 0.5449 - val_accuracy: 0.7438 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3224 - accuracy: 0.8486 - val_loss: 0.5450 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3208 - accuracy: 0.8593 - val_loss: 0.5451 - val_accuracy: 0.7438 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3196 - accuracy: 0.8549 - val_loss: 0.5450 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3212 - accuracy: 0.8531 - val_loss: 0.5450 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3129 - accuracy: 0.8655 - val_loss: 0.5453 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3279 - accuracy: 0.8522 - val_loss: 0.5451 - val_accuracy: 0.7402 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3249 - accuracy: 0.8549 - val_loss: 0.5449 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3233 - accuracy: 0.8549 - val_loss: 0.5448 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3201 - accuracy: 0.8638 - val_loss: 0.5445 - val_accuracy: 0.7402 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3237 - accuracy: 0.8540 - val_loss: 0.5446 - val_accuracy: 0.7438 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3226 - accuracy: 0.8504 - val_loss: 0.5446 - val_accuracy: 0.7438 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3147 - accuracy: 0.8584 - val_loss: 0.5447 - val_accuracy: 0.7438 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.3276 - accuracy: 0.8513 - val_loss: 0.5450 - val_accuracy: 0.7438 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3126 - accuracy: 0.8575 - val_loss: 0.5450 - val_accuracy: 0.7438 - lr: 6.0936e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 16ms/step - loss: 0.9107 - accuracy: 0.5824 - val_loss: 0.7034 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6704 - accuracy: 0.5850 - val_loss: 0.6799 - val_accuracy: 0.6726 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6623 - accuracy: 0.6456 - val_loss: 0.7136 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.6135 - accuracy: 0.6687 - val_loss: 0.7163 - val_accuracy: 0.5196 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.5877 - accuracy: 0.6919 - val_loss: 0.6603 - val_accuracy: 0.5801 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 1s 15ms/step - loss: 0.5633 - accuracy: 0.7177 - val_loss: 0.6622 - val_accuracy: 0.5943 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.5431 - accuracy: 0.7266 - val_loss: 0.5789 - val_accuracy: 0.6833 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.5313 - accuracy: 0.7302 - val_loss: 0.5503 - val_accuracy: 0.7331 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5189 - accuracy: 0.7159 - val_loss: 0.5327 - val_accuracy: 0.7117 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.5012 - accuracy: 0.7284 - val_loss: 0.5348 - val_accuracy: 0.7331 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4890 - accuracy: 0.7311 - val_loss: 0.5341 - val_accuracy: 0.7295 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4678 - accuracy: 0.7444 - val_loss: 0.5305 - val_accuracy: 0.7153 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4593 - accuracy: 0.7587 - val_loss: 0.5237 - val_accuracy: 0.7260 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4550 - accuracy: 0.7640 - val_loss: 0.5252 - val_accuracy: 0.7473 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4349 - accuracy: 0.7685 - val_loss: 0.5348 - val_accuracy: 0.7082 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4285 - accuracy: 0.7898 - val_loss: 0.5476 - val_accuracy: 0.7402 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4318 - accuracy: 0.7854 - val_loss: 0.5316 - val_accuracy: 0.7438 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4083 - accuracy: 0.7988 - val_loss: 0.5350 - val_accuracy: 0.7473 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.4042 - accuracy: 0.7881 - val_loss: 0.5664 - val_accuracy: 0.7402 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.4188 - accuracy: 0.7863 - val_loss: 0.5468 - val_accuracy: 0.7438 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3996 - accuracy: 0.7881 - val_loss: 0.5456 - val_accuracy: 0.7544 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3887 - accuracy: 0.8077 - val_loss: 0.5307 - val_accuracy: 0.7402 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4072 - accuracy: 0.7934 - val_loss: 0.5360 - val_accuracy: 0.7402 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3945 - accuracy: 0.7979 - val_loss: 0.5367 - val_accuracy: 0.7402 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3841 - accuracy: 0.7952 - val_loss: 0.5375 - val_accuracy: 0.7367 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3852 - accuracy: 0.8148 - val_loss: 0.5375 - val_accuracy: 0.7473 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3723 - accuracy: 0.8139 - val_loss: 0.5435 - val_accuracy: 0.7402 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3768 - accuracy: 0.8130 - val_loss: 0.5449 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3831 - accuracy: 0.8166 - val_loss: 0.5430 - val_accuracy: 0.7367 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3747 - accuracy: 0.8077 - val_loss: 0.5428 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3714 - accuracy: 0.8041 - val_loss: 0.5445 - val_accuracy: 0.7402 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3765 - accuracy: 0.8130 - val_loss: 0.5449 - val_accuracy: 0.7367 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 2s 21ms/step - loss: 0.3639 - accuracy: 0.8264 - val_loss: 0.5435 - val_accuracy: 0.7331 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3727 - accuracy: 0.8112 - val_loss: 0.5424 - val_accuracy: 0.7367 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3652 - accuracy: 0.8183 - val_loss: 0.5444 - val_accuracy: 0.7438 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3766 - accuracy: 0.8157 - val_loss: 0.5453 - val_accuracy: 0.7402 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3727 - accuracy: 0.8068 - val_loss: 0.5444 - val_accuracy: 0.7438 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3685 - accuracy: 0.8183 - val_loss: 0.5445 - val_accuracy: 0.7367 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3767 - accuracy: 0.8157 - val_loss: 0.5450 - val_accuracy: 0.7367 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3613 - accuracy: 0.8059 - val_loss: 0.5450 - val_accuracy: 0.7402 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3773 - accuracy: 0.8121 - val_loss: 0.5453 - val_accuracy: 0.7367 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3689 - accuracy: 0.8166 - val_loss: 0.5448 - val_accuracy: 0.7367 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3658 - accuracy: 0.8121 - val_loss: 0.5451 - val_accuracy: 0.7438 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3695 - accuracy: 0.8246 - val_loss: 0.5458 - val_accuracy: 0.7367 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3700 - accuracy: 0.8157 - val_loss: 0.5456 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3803 - accuracy: 0.8103 - val_loss: 0.5452 - val_accuracy: 0.7367 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3706 - accuracy: 0.8166 - val_loss: 0.5451 - val_accuracy: 0.7402 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3660 - accuracy: 0.8228 - val_loss: 0.5453 - val_accuracy: 0.7367 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3531 - accuracy: 0.8326 - val_loss: 0.5456 - val_accuracy: 0.7367 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3811 - accuracy: 0.8121 - val_loss: 0.5456 - val_accuracy: 0.7367 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3684 - accuracy: 0.8157 - val_loss: 0.5457 - val_accuracy: 0.7367 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3655 - accuracy: 0.8210 - val_loss: 0.5460 - val_accuracy: 0.7367 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3773 - accuracy: 0.8103 - val_loss: 0.5463 - val_accuracy: 0.7331 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3769 - accuracy: 0.8237 - val_loss: 0.5460 - val_accuracy: 0.7331 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3716 - accuracy: 0.8121 - val_loss: 0.5461 - val_accuracy: 0.7331 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3769 - accuracy: 0.8281 - val_loss: 0.5463 - val_accuracy: 0.7331 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3706 - accuracy: 0.8192 - val_loss: 0.5462 - val_accuracy: 0.7331 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3649 - accuracy: 0.8166 - val_loss: 0.5461 - val_accuracy: 0.7331 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.8050 - val_loss: 0.5461 - val_accuracy: 0.7331 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3693 - accuracy: 0.8148 - val_loss: 0.5464 - val_accuracy: 0.7331 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3629 - accuracy: 0.8175 - val_loss: 0.5462 - val_accuracy: 0.7331 - lr: 3.6562e-06\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "for i in range(20):\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2,stratify= y, random_state=i)\n",
        "    # normalize the X data range\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "    model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_test,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_test    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n",
        "    name = \"neuro_tensorflow_model\" + str(i)\n",
        "    model.save(name,save_format = 'tf') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-okvR7u3jxh",
        "outputId": "241f6cd7-4ba5-4587-a349-79e8eb65e990"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.7722419928825622, 0.7259786476868327, 0.7615658362989324, 0.7544483985765125, 0.7580071174377224, 0.7580071174377224, 0.7259786476868327, 0.7758007117437722, 0.7580071174377224, 0.6868327402135231, 0.7330960854092526, 0.7508896797153025, 0.7829181494661922, 0.7935943060498221, 0.7330960854092526, 0.7437722419928826, 0.7615658362989324, 0.7437722419928826, 0.7437722419928826, 0.7544483985765125]\n",
            "[0.7731490872210953, 0.7287095767910992, 0.7612068965517241, 0.7556062912227296, 0.7576357179096904, 0.7686110215920077, 0.7266068532035685, 0.7757345491388045, 0.7603047520661157, 0.688841984573692, 0.735248447204969, 0.7507092917215523, 0.7895262107364218, 0.7958612975391499, 0.7327079107505071, 0.762914612281488, 0.7615639327559858, 0.7457902892561983, 0.7435623409669212, 0.7546863917316851]\n",
            "[0.8014705882352942, 0.7116564417177914, 0.7724137931034483, 0.7851851851851852, 0.7671232876712328, 0.7241379310344828, 0.7518248175182481, 0.7943262411347518, 0.74375, 0.676829268292683, 0.7204968944099379, 0.7676056338028169, 0.7544910179640718, 0.8333333333333334, 0.7448275862068966, 0.7010869565217391, 0.7615894039735099, 0.73125, 0.7466666666666667, 0.7769784172661871]\n",
            "[0.7448275862068966, 0.7457627118644068, 0.75, 0.726027397260274, 0.7481481481481481, 0.8130841121495327, 0.7013888888888888, 0.7571428571428571, 0.7768595041322314, 0.7008547008547008, 0.75, 0.7338129496402878, 0.8245614035087719, 0.7583892617449665, 0.7205882352941176, 0.8247422680412371, 0.7615384615384615, 0.7603305785123967, 0.7404580152671756, 0.7323943661971831]\n",
            "[0.546436740880549, 0.4518620201982288, 0.5225463013600126, 0.5112125824454592, 0.5152714358193811, 0.5221280498621895, 0.4534206060784519, 0.5518886259900743, 0.5159664421885165, 0.37264911509866744, 0.4658187976203358, 0.5017746143328284, 0.5690956043725125, 0.5910918086101773, 0.465533872440516, 0.5003756717841318, 0.5220651363991392, 0.48719641138090203, 0.48638267894113923, 0.509734462210999]\n",
            "[0.8403348554033485, 0.7907153729071537, 0.7938609842719431, 0.8030441400304413, 0.8126839167935058, 0.8156012176560121, 0.7888381532217148, 0.8339167935058348, 0.8248097412480974, 0.7336377473363775, 0.8063926940639269, 0.8060882800608827, 0.8504312531709793, 0.8668188736681887, 0.8010654490106545, 0.8233384069000508, 0.8257229832572299, 0.8008371385083713, 0.8293505834601724, 0.8203957382039573]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(ACC_collecton)\n",
        "print(BACC_collecton)\n",
        "print(Sn_collecton)\n",
        "print(Sp_collecton)\n",
        "print(MCC_collecton)\n",
        "print(AUC_collecton)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qODBPw9C7y6I",
        "outputId": "195612c0-cf39-44ef-b46c-565ebe0bbe70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['antioxidant.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import joblib\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "joblib.dump(scaler, 'antioxidant.joblib')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3Fagh9Iw83q"
      },
      "source": [
        "### Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "outputs": [],
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 16, verbose=1)\n",
        "  return model, model_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sws_G8h08tuq"
      },
      "source": [
        "### 10-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "76d7a691-64e2-4191-c2a0-c2400d4f952c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/64 [..............................] - ETA: 1:00 - loss: 1.0158 - accuracy: 0.3125"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-25cdea4c3f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mX_train_CV\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mX_valid_CV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0my_train_CV\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_valid_CV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mESM_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid_CV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_CV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpredicted_class\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4f18214be816>\u001b[0m in \u001b[0;36mESM_CNN\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mlrate\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n\u001b[0m\u001b[1;32m     49\u001b[0m                             epochs=200,callbacks=callbacks_list,batch_size = 16, verbose=1)\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTi2x37MzsIY"
      },
      "outputs": [],
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397sLYBohyh7",
        "outputId": "7cca9c4f-0da1-4f80-9bf3-b7da2713807b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.9815950920245399]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ACC_collecton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JBlTA9shnQE"
      },
      "source": [
        "### model evaluation in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPwEv_WsnH6Q",
        "outputId": "94f03d85-07f3-4669-dcb6-2d49be89b4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 2s 16ms/step - loss: 1.0464 - accuracy: 0.5824 - val_loss: 0.6963 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.6303 - accuracy: 0.6260 - val_loss: 0.6918 - val_accuracy: 0.5196 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.5567 - accuracy: 0.7053 - val_loss: 0.6875 - val_accuracy: 0.6014 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.5475 - accuracy: 0.7044 - val_loss: 0.6788 - val_accuracy: 0.6690 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "71/71 [==============================] - 2s 31ms/step - loss: 0.5279 - accuracy: 0.7186 - val_loss: 0.6601 - val_accuracy: 0.6584 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "71/71 [==============================] - 2s 35ms/step - loss: 0.4966 - accuracy: 0.7578 - val_loss: 0.5993 - val_accuracy: 0.7473 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4809 - accuracy: 0.7507 - val_loss: 0.5836 - val_accuracy: 0.7509 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4707 - accuracy: 0.7462 - val_loss: 0.4891 - val_accuracy: 0.7651 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4409 - accuracy: 0.7720 - val_loss: 0.5507 - val_accuracy: 0.7473 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4403 - accuracy: 0.7854 - val_loss: 0.4682 - val_accuracy: 0.7687 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.4153 - accuracy: 0.7801 - val_loss: 0.4802 - val_accuracy: 0.7651 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.4011 - accuracy: 0.7809 - val_loss: 0.4827 - val_accuracy: 0.7829 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3933 - accuracy: 0.8014 - val_loss: 0.5501 - val_accuracy: 0.7402 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3894 - accuracy: 0.8023 - val_loss: 0.4737 - val_accuracy: 0.7829 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3710 - accuracy: 0.7907 - val_loss: 0.4817 - val_accuracy: 0.8043 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3601 - accuracy: 0.8130 - val_loss: 0.4744 - val_accuracy: 0.7758 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "71/71 [==============================] - 1s 18ms/step - loss: 0.3692 - accuracy: 0.8032 - val_loss: 0.4691 - val_accuracy: 0.7758 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "71/71 [==============================] - 1s 21ms/step - loss: 0.3560 - accuracy: 0.8121 - val_loss: 0.4766 - val_accuracy: 0.7794 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "71/71 [==============================] - 1s 14ms/step - loss: 0.3377 - accuracy: 0.8201 - val_loss: 0.4791 - val_accuracy: 0.7829 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3355 - accuracy: 0.8148 - val_loss: 0.4834 - val_accuracy: 0.7544 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3344 - accuracy: 0.8246 - val_loss: 0.4867 - val_accuracy: 0.7829 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "71/71 [==============================] - 1s 13ms/step - loss: 0.3319 - accuracy: 0.8228 - val_loss: 0.4906 - val_accuracy: 0.7972 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3212 - accuracy: 0.8281 - val_loss: 0.4883 - val_accuracy: 0.7865 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3176 - accuracy: 0.8370 - val_loss: 0.4901 - val_accuracy: 0.7829 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3231 - accuracy: 0.8290 - val_loss: 0.4889 - val_accuracy: 0.7829 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3190 - accuracy: 0.8370 - val_loss: 0.4899 - val_accuracy: 0.7758 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3173 - accuracy: 0.8335 - val_loss: 0.4917 - val_accuracy: 0.7936 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3214 - accuracy: 0.8228 - val_loss: 0.4929 - val_accuracy: 0.7972 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3142 - accuracy: 0.8317 - val_loss: 0.4919 - val_accuracy: 0.7758 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3137 - accuracy: 0.8246 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "71/71 [==============================] - 1s 20ms/step - loss: 0.3185 - accuracy: 0.8370 - val_loss: 0.4914 - val_accuracy: 0.7972 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3070 - accuracy: 0.8353 - val_loss: 0.4910 - val_accuracy: 0.7936 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3089 - accuracy: 0.8433 - val_loss: 0.4905 - val_accuracy: 0.7936 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3097 - accuracy: 0.8299 - val_loss: 0.4900 - val_accuracy: 0.7972 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3114 - accuracy: 0.8344 - val_loss: 0.4901 - val_accuracy: 0.8007 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3172 - accuracy: 0.8290 - val_loss: 0.4908 - val_accuracy: 0.7936 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3124 - accuracy: 0.8388 - val_loss: 0.4905 - val_accuracy: 0.8007 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3087 - accuracy: 0.8388 - val_loss: 0.4912 - val_accuracy: 0.8007 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "71/71 [==============================] - 2s 26ms/step - loss: 0.2991 - accuracy: 0.8379 - val_loss: 0.4910 - val_accuracy: 0.8007 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "71/71 [==============================] - 2s 27ms/step - loss: 0.3183 - accuracy: 0.8255 - val_loss: 0.4908 - val_accuracy: 0.7972 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "71/71 [==============================] - 2s 27ms/step - loss: 0.3197 - accuracy: 0.8317 - val_loss: 0.4912 - val_accuracy: 0.7972 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "71/71 [==============================] - 2s 31ms/step - loss: 0.3032 - accuracy: 0.8397 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "71/71 [==============================] - 2s 24ms/step - loss: 0.3093 - accuracy: 0.8379 - val_loss: 0.4912 - val_accuracy: 0.7972 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "71/71 [==============================] - 2s 27ms/step - loss: 0.2962 - accuracy: 0.8362 - val_loss: 0.4913 - val_accuracy: 0.7972 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3121 - accuracy: 0.8272 - val_loss: 0.4913 - val_accuracy: 0.7972 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3023 - accuracy: 0.8370 - val_loss: 0.4913 - val_accuracy: 0.7972 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3032 - accuracy: 0.8504 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3062 - accuracy: 0.8290 - val_loss: 0.4916 - val_accuracy: 0.7972 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3092 - accuracy: 0.8379 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3130 - accuracy: 0.8326 - val_loss: 0.4914 - val_accuracy: 0.7972 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "71/71 [==============================] - 1s 16ms/step - loss: 0.3044 - accuracy: 0.8379 - val_loss: 0.4913 - val_accuracy: 0.7972 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "71/71 [==============================] - 1s 19ms/step - loss: 0.3069 - accuracy: 0.8415 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "71/71 [==============================] - 1s 17ms/step - loss: 0.3099 - accuracy: 0.8335 - val_loss: 0.4915 - val_accuracy: 0.7972 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3030 - accuracy: 0.8344 - val_loss: 0.4916 - val_accuracy: 0.7972 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "71/71 [==============================] - 1s 12ms/step - loss: 0.3077 - accuracy: 0.8433 - val_loss: 0.4917 - val_accuracy: 0.7972 - lr: 1.0156e-05\n",
            "281/281 [==============================] - 1s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPaaT9fhE4Y-",
        "outputId": "d3472b03-8ec9-42eb-8d5c-644460bf626d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8042704626334519\n",
            "0.8040156361051883\n",
            "0.8095238095238095\n",
            "0.7985074626865671\n",
            "0.6078461507957617\n",
            "0.871740233384069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "92af7c6c-213e-461d-d1b9-ee8d1523f8ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/antioxidant_tensorflow_model/ (stored 0%)\n",
            "  adding: content/antioxidant_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/antioxidant_tensorflow_model/fingerprint.pb (stored 0%)\n",
            "  adding: content/antioxidant_tensorflow_model/keras_metadata.pb (deflated 90%)\n",
            "  adding: content/antioxidant_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/antioxidant_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 41%)\n",
            "  adding: content/antioxidant_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/antioxidant_tensorflow_model/saved_model.pb (deflated 88%)\n"
          ]
        }
      ],
      "source": [
        "model.save('antioxidant_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/antioxidant_tensorflow_model.zip /content/antioxidant_tensorflow_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G1yUX0bCZyG"
      },
      "source": [
        "### t-SNE graph making"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abadUCq3CeO3"
      },
      "outputs": [],
      "source": [
        "# concatenate the dataset\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from keras.datasets import mnist\n",
        "from sklearn.datasets import load_iris\n",
        "from numpy import reshape\n",
        "import seaborn as sns\n",
        "import pandas as pd  \n",
        "tsne = TSNE(n_components=2, verbose=0, perplexity= 25, learning_rate='auto',n_iter = 5000,random_state=123)\n",
        "z = tsne.fit_transform(X) \n",
        "df = pd.DataFrame()\n",
        "df[\"comp-1\"] = z[:,0]\n",
        "df[\"comp-2\"] = z[:,1]\n",
        "y_new_label=[]\n",
        "for i in y:\n",
        "    if i == 0:\n",
        "        y_new_label.append('Active')\n",
        "    if i == 1:\n",
        "        y_new_label.append('Inactive')\n",
        "df[\"y\"] = y_new_label\n",
        "graph = sns.scatterplot(data=df, x=\"comp-1\", y=\"comp-2\", hue=y_new_label,\n",
        "                palette='BrBG_r', legend='full')\n",
        "graph_for_output = graph.get_figure()\n",
        "graph_for_output.savefig('18.antioxidant_t-SNE.png', dpi=300)\n",
        "df.to_excel('18.antioxidant_t-SNE.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQIWSlOUCwqb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boJihng4cdj0"
      },
      "source": [
        "### Umap\n",
        "Uniform Manifold Approximation and Projection (UMAP) is a dimension reduction technique that can be used for visualisation similarly to t-SNE, but also for general non-linear dimension reduction. The algorithm is founded on three assumptions about the data:\n",
        "1. The data is uniformly distributed on a Riemannian manifold;\n",
        "2. The Riemannian metric is locally constant (or can be approximated as such);\n",
        "3. The manifold is locally connected.\n",
        "https://pypi.org/project/umap-learn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8I9ypH1FceFi",
        "outputId": "7ee8e932-ab1f-4a4d-9ad6-0ae4a5c1e0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (1.7.3)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.8/dist-packages (from umap-learn) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from umap-learn) (4.64.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (0.39.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (6.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.49->umap-learn) (57.4.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.22->umap-learn) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.49->umap-learn) (3.12.1)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82829 sha256=cc348053e816fd6b1bb853e168279e5901e01d9893a73722b98bb96159c41888\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/3a/67/06a8950e053725912e6a8c42c4a3a241410f6487b8402542ea\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55513 sha256=18753a43aceadd92f1325481e692ade07639f26d317241431b623363856a73f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/63/3a/29954bca1a27ba100ed8c27973a78cb71b43dc67aed62e80c3\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.8 umap-learn-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sHoxYsXYcnhy",
        "outputId": "b5b794c4-0906-4b65-8635-58607f039ae5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import umap\n",
        "import seaborn as sns\n",
        "# concatenate the dataset\n",
        "X = np.concatenate((X_train, X_test), axis=0)\n",
        "y = np.concatenate((y_train, y_test), axis=0)\n",
        "embedding = umap.UMAP(n_neighbors=20).fit_transform(X, y=y) # two dimension\n",
        "df = pd.DataFrame()\n",
        "df[\"comp-1\"] = embedding[:,0]\n",
        "df[\"comp-2\"] = embedding[:,1]\n",
        "y_new_label=[]\n",
        "for i in y:\n",
        "    if i == 0:\n",
        "        y_new_label.append('Active')\n",
        "    if i == 1:\n",
        "        y_new_label.append('Inactive')\n",
        "df[\"y\"] = y_new_label\n",
        "graph = sns.scatterplot(data=df, x=\"comp-1\", y=\"comp-2\", hue=y_new_label,\n",
        "                palette='YlOrRd_r', legend='full')\n",
        "graph_for_output = graph.get_figure()\n",
        "graph_for_output.savefig('18.antioxidant_UMAP_UMAP.png', dpi=300)\n",
        "df.to_excel('18.antioxidant_UMAP.xlsx')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-wQLt2odAr4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}