{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (main dataset)"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('AMP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMP_train_main_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('AMP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMP_test_main_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ4hr_qAl9kf",
        "outputId": "7d2591d2-a840-4a85-a438-e59a38958edd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'AMP_train_main_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'AMP_test_main_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "afed6297-0f5d-427d-9056-cef968548e99"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13428, 320)\n",
            "(8953, 320)\n",
            "(13428,)\n",
            "(8953,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 64, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa4d524-0b05-4d70-c11f-806ce2886351"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "189/189 [==============================] - 7s 34ms/step - loss: 0.3141 - accuracy: 0.9036 - val_loss: 0.6856 - val_accuracy: 0.5465 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 8s 43ms/step - loss: 0.1491 - accuracy: 0.9451 - val_loss: 0.4972 - val_accuracy: 0.9360 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1266 - accuracy: 0.9532 - val_loss: 0.1946 - val_accuracy: 0.9442 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 8s 40ms/step - loss: 0.1186 - accuracy: 0.9554 - val_loss: 0.1196 - val_accuracy: 0.9523 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 11s 60ms/step - loss: 0.1147 - accuracy: 0.9554 - val_loss: 0.1273 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1046 - accuracy: 0.9590 - val_loss: 0.1206 - val_accuracy: 0.9509 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1037 - accuracy: 0.9613 - val_loss: 0.1175 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1002 - accuracy: 0.9611 - val_loss: 0.1191 - val_accuracy: 0.9568 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0931 - accuracy: 0.9641 - val_loss: 0.1184 - val_accuracy: 0.9561 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 9s 45ms/step - loss: 0.0908 - accuracy: 0.9638 - val_loss: 0.1139 - val_accuracy: 0.9583 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0913 - accuracy: 0.9648 - val_loss: 0.1146 - val_accuracy: 0.9553 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0873 - accuracy: 0.9655 - val_loss: 0.1112 - val_accuracy: 0.9568 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0865 - accuracy: 0.9665 - val_loss: 0.1103 - val_accuracy: 0.9576 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0844 - accuracy: 0.9665 - val_loss: 0.1157 - val_accuracy: 0.9590 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0820 - accuracy: 0.9686 - val_loss: 0.1129 - val_accuracy: 0.9553 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0822 - accuracy: 0.9681 - val_loss: 0.1126 - val_accuracy: 0.9590 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0819 - accuracy: 0.9680 - val_loss: 0.1103 - val_accuracy: 0.9583 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0804 - accuracy: 0.9681 - val_loss: 0.1118 - val_accuracy: 0.9605 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0821 - accuracy: 0.9683 - val_loss: 0.1097 - val_accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0800 - accuracy: 0.9685 - val_loss: 0.1138 - val_accuracy: 0.9568 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0801 - accuracy: 0.9672 - val_loss: 0.1109 - val_accuracy: 0.9576 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0797 - accuracy: 0.9676 - val_loss: 0.1087 - val_accuracy: 0.9590 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0805 - accuracy: 0.9683 - val_loss: 0.1099 - val_accuracy: 0.9568 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0779 - accuracy: 0.9705 - val_loss: 0.1107 - val_accuracy: 0.9561 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0779 - accuracy: 0.9695 - val_loss: 0.1106 - val_accuracy: 0.9568 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0796 - accuracy: 0.9680 - val_loss: 0.1102 - val_accuracy: 0.9576 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0788 - accuracy: 0.9679 - val_loss: 0.1089 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 0.0778 - accuracy: 0.9692 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0772 - accuracy: 0.9708 - val_loss: 0.1099 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0752 - accuracy: 0.9695 - val_loss: 0.1099 - val_accuracy: 0.9576 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0773 - accuracy: 0.9686 - val_loss: 0.1095 - val_accuracy: 0.9583 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0754 - accuracy: 0.9689 - val_loss: 0.1096 - val_accuracy: 0.9590 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 0.0781 - accuracy: 0.9700 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 8s 42ms/step - loss: 0.0790 - accuracy: 0.9690 - val_loss: 0.1091 - val_accuracy: 0.9583 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0778 - accuracy: 0.9683 - val_loss: 0.1092 - val_accuracy: 0.9583 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0773 - accuracy: 0.9688 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0788 - accuracy: 0.9683 - val_loss: 0.1092 - val_accuracy: 0.9583 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0772 - accuracy: 0.9719 - val_loss: 0.1092 - val_accuracy: 0.9583 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0773 - accuracy: 0.9699 - val_loss: 0.1092 - val_accuracy: 0.9583 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0760 - accuracy: 0.9696 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0778 - accuracy: 0.9683 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0768 - accuracy: 0.9705 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0780 - accuracy: 0.9693 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0758 - accuracy: 0.9708 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0770 - accuracy: 0.9686 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0779 - accuracy: 0.9700 - val_loss: 0.1093 - val_accuracy: 0.9583 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0760 - accuracy: 0.9706 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0770 - accuracy: 0.9704 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0779 - accuracy: 0.9698 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0766 - accuracy: 0.9707 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0778 - accuracy: 0.9700 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0763 - accuracy: 0.9700 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0772 - accuracy: 0.9700 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0757 - accuracy: 0.9710 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0754 - accuracy: 0.9705 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0770 - accuracy: 0.9694 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0764 - accuracy: 0.9712 - val_loss: 0.1094 - val_accuracy: 0.9583 - lr: 6.0936e-06\n",
            "1343/1343 [==============================] - 3s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 34ms/step - loss: 0.2968 - accuracy: 0.9078 - val_loss: 0.8969 - val_accuracy: 0.3083 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1544 - accuracy: 0.9450 - val_loss: 0.6776 - val_accuracy: 0.4483 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1295 - accuracy: 0.9509 - val_loss: 0.1614 - val_accuracy: 0.9546 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1201 - accuracy: 0.9553 - val_loss: 0.1082 - val_accuracy: 0.9598 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1156 - accuracy: 0.9571 - val_loss: 0.1005 - val_accuracy: 0.9605 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1059 - accuracy: 0.9609 - val_loss: 0.1018 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1039 - accuracy: 0.9611 - val_loss: 0.0962 - val_accuracy: 0.9650 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1006 - accuracy: 0.9620 - val_loss: 0.1008 - val_accuracy: 0.9628 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0941 - accuracy: 0.9655 - val_loss: 0.0989 - val_accuracy: 0.9650 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0910 - accuracy: 0.9660 - val_loss: 0.0944 - val_accuracy: 0.9680 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0888 - accuracy: 0.9671 - val_loss: 0.1116 - val_accuracy: 0.9538 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0854 - accuracy: 0.9667 - val_loss: 0.0968 - val_accuracy: 0.9643 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0857 - accuracy: 0.9669 - val_loss: 0.0933 - val_accuracy: 0.9650 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0835 - accuracy: 0.9688 - val_loss: 0.0963 - val_accuracy: 0.9672 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0805 - accuracy: 0.9687 - val_loss: 0.0927 - val_accuracy: 0.9650 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0842 - accuracy: 0.9693 - val_loss: 0.0976 - val_accuracy: 0.9628 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0815 - accuracy: 0.9686 - val_loss: 0.0909 - val_accuracy: 0.9680 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0779 - accuracy: 0.9710 - val_loss: 0.0921 - val_accuracy: 0.9665 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0782 - accuracy: 0.9701 - val_loss: 0.0961 - val_accuracy: 0.9635 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0792 - accuracy: 0.9713 - val_loss: 0.0909 - val_accuracy: 0.9695 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0734 - accuracy: 0.9720 - val_loss: 0.0904 - val_accuracy: 0.9672 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.0917 - val_accuracy: 0.9695 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 0.0755 - accuracy: 0.9723 - val_loss: 0.0921 - val_accuracy: 0.9650 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 7s 34ms/step - loss: 0.0752 - accuracy: 0.9710 - val_loss: 0.0900 - val_accuracy: 0.9680 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0739 - accuracy: 0.9737 - val_loss: 0.0896 - val_accuracy: 0.9702 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0755 - accuracy: 0.9729 - val_loss: 0.0909 - val_accuracy: 0.9702 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0750 - accuracy: 0.9740 - val_loss: 0.0910 - val_accuracy: 0.9687 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0738 - accuracy: 0.9728 - val_loss: 0.0906 - val_accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0743 - accuracy: 0.9723 - val_loss: 0.0902 - val_accuracy: 0.9695 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0746 - accuracy: 0.9731 - val_loss: 0.0896 - val_accuracy: 0.9687 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 0.0747 - accuracy: 0.9737 - val_loss: 0.0895 - val_accuracy: 0.9687 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 8s 42ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 0.0894 - val_accuracy: 0.9695 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0747 - accuracy: 0.9719 - val_loss: 0.0894 - val_accuracy: 0.9687 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0738 - accuracy: 0.9719 - val_loss: 0.0899 - val_accuracy: 0.9687 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0724 - accuracy: 0.9732 - val_loss: 0.0900 - val_accuracy: 0.9687 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0738 - accuracy: 0.9735 - val_loss: 0.0896 - val_accuracy: 0.9680 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0736 - accuracy: 0.9714 - val_loss: 0.0901 - val_accuracy: 0.9695 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0729 - accuracy: 0.9721 - val_loss: 0.0898 - val_accuracy: 0.9702 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0746 - accuracy: 0.9731 - val_loss: 0.0898 - val_accuracy: 0.9702 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0732 - accuracy: 0.9733 - val_loss: 0.0898 - val_accuracy: 0.9687 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0736 - accuracy: 0.9730 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0750 - accuracy: 0.9716 - val_loss: 0.0898 - val_accuracy: 0.9687 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0729 - accuracy: 0.9735 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0744 - accuracy: 0.9716 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0717 - accuracy: 0.9747 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0729 - accuracy: 0.9731 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0709 - accuracy: 0.9733 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0734 - accuracy: 0.9734 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0731 - accuracy: 0.9729 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0707 - accuracy: 0.9739 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0732 - accuracy: 0.9715 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0714 - accuracy: 0.9743 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0736 - accuracy: 0.9732 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0720 - accuracy: 0.9734 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0725 - accuracy: 0.9735 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0727 - accuracy: 0.9734 - val_loss: 0.0900 - val_accuracy: 0.9695 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0728 - accuracy: 0.9739 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0756 - accuracy: 0.9709 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0723 - accuracy: 0.9731 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0739 - accuracy: 0.9721 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0737 - accuracy: 0.9724 - val_loss: 0.0899 - val_accuracy: 0.9695 - lr: 2.1937e-06\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 33ms/step - loss: 0.3526 - accuracy: 0.8909 - val_loss: 0.7471 - val_accuracy: 0.2800 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1477 - accuracy: 0.9457 - val_loss: 0.6786 - val_accuracy: 0.4430 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1268 - accuracy: 0.9516 - val_loss: 0.1627 - val_accuracy: 0.9501 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1215 - accuracy: 0.9551 - val_loss: 0.1244 - val_accuracy: 0.9501 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1140 - accuracy: 0.9582 - val_loss: 0.1091 - val_accuracy: 0.9568 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1058 - accuracy: 0.9605 - val_loss: 0.1155 - val_accuracy: 0.9568 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1022 - accuracy: 0.9621 - val_loss: 0.1023 - val_accuracy: 0.9576 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 0.1009 - accuracy: 0.9648 - val_loss: 0.1148 - val_accuracy: 0.9590 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0934 - accuracy: 0.9662 - val_loss: 0.1071 - val_accuracy: 0.9590 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0926 - accuracy: 0.9664 - val_loss: 0.1065 - val_accuracy: 0.9590 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0882 - accuracy: 0.9674 - val_loss: 0.1024 - val_accuracy: 0.9561 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0859 - accuracy: 0.9686 - val_loss: 0.1027 - val_accuracy: 0.9561 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0880 - accuracy: 0.9681 - val_loss: 0.1052 - val_accuracy: 0.9590 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 0.1042 - val_accuracy: 0.9605 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0832 - accuracy: 0.9698 - val_loss: 0.1021 - val_accuracy: 0.9583 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0818 - accuracy: 0.9700 - val_loss: 0.1028 - val_accuracy: 0.9613 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0795 - accuracy: 0.9710 - val_loss: 0.1019 - val_accuracy: 0.9605 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0803 - accuracy: 0.9707 - val_loss: 0.0998 - val_accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 0.1021 - val_accuracy: 0.9598 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0803 - accuracy: 0.9715 - val_loss: 0.0995 - val_accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0789 - accuracy: 0.9720 - val_loss: 0.1015 - val_accuracy: 0.9598 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0765 - accuracy: 0.9728 - val_loss: 0.1043 - val_accuracy: 0.9605 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0776 - accuracy: 0.9729 - val_loss: 0.1008 - val_accuracy: 0.9583 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 8s 40ms/step - loss: 0.0770 - accuracy: 0.9732 - val_loss: 0.1012 - val_accuracy: 0.9583 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 0.0769 - accuracy: 0.9726 - val_loss: 0.1020 - val_accuracy: 0.9568 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0783 - accuracy: 0.9720 - val_loss: 0.1009 - val_accuracy: 0.9598 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0762 - accuracy: 0.9724 - val_loss: 0.1022 - val_accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0767 - accuracy: 0.9720 - val_loss: 0.1007 - val_accuracy: 0.9598 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0775 - accuracy: 0.9723 - val_loss: 0.1008 - val_accuracy: 0.9598 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0769 - accuracy: 0.9738 - val_loss: 0.1006 - val_accuracy: 0.9590 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0759 - accuracy: 0.9729 - val_loss: 0.1008 - val_accuracy: 0.9590 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0775 - accuracy: 0.9710 - val_loss: 0.1005 - val_accuracy: 0.9598 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0754 - accuracy: 0.9728 - val_loss: 0.1005 - val_accuracy: 0.9598 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0750 - accuracy: 0.9745 - val_loss: 0.1007 - val_accuracy: 0.9590 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0763 - accuracy: 0.9713 - val_loss: 0.1008 - val_accuracy: 0.9590 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0760 - accuracy: 0.9731 - val_loss: 0.1010 - val_accuracy: 0.9590 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.1012 - val_accuracy: 0.9590 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0740 - accuracy: 0.9743 - val_loss: 0.1014 - val_accuracy: 0.9598 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0745 - accuracy: 0.9729 - val_loss: 0.1014 - val_accuracy: 0.9598 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0778 - accuracy: 0.9713 - val_loss: 0.1013 - val_accuracy: 0.9598 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0754 - accuracy: 0.9721 - val_loss: 0.1011 - val_accuracy: 0.9598 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0744 - accuracy: 0.9734 - val_loss: 0.1011 - val_accuracy: 0.9598 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0750 - accuracy: 0.9727 - val_loss: 0.1011 - val_accuracy: 0.9598 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0758 - accuracy: 0.9741 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 0.1009 - val_accuracy: 0.9590 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0754 - accuracy: 0.9731 - val_loss: 0.1010 - val_accuracy: 0.9590 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0765 - accuracy: 0.9719 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0772 - accuracy: 0.9723 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0750 - accuracy: 0.9721 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0758 - accuracy: 0.9723 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0745 - accuracy: 0.9738 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0765 - accuracy: 0.9724 - val_loss: 0.1010 - val_accuracy: 0.9590 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0750 - accuracy: 0.9718 - val_loss: 0.1010 - val_accuracy: 0.9590 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0755 - accuracy: 0.9747 - val_loss: 0.1010 - val_accuracy: 0.9598 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0754 - accuracy: 0.9721 - val_loss: 0.1009 - val_accuracy: 0.9590 - lr: 1.0156e-05\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 34ms/step - loss: 0.3073 - accuracy: 0.8916 - val_loss: 0.6073 - val_accuracy: 0.7103 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1525 - accuracy: 0.9441 - val_loss: 0.3558 - val_accuracy: 0.9375 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 0.1256 - accuracy: 0.9518 - val_loss: 0.1201 - val_accuracy: 0.9605 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1229 - accuracy: 0.9536 - val_loss: 0.1046 - val_accuracy: 0.9583 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1148 - accuracy: 0.9571 - val_loss: 0.1027 - val_accuracy: 0.9635 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1070 - accuracy: 0.9590 - val_loss: 0.1021 - val_accuracy: 0.9650 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1050 - accuracy: 0.9595 - val_loss: 0.1013 - val_accuracy: 0.9643 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1011 - accuracy: 0.9614 - val_loss: 0.0915 - val_accuracy: 0.9628 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0980 - accuracy: 0.9628 - val_loss: 0.0923 - val_accuracy: 0.9635 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0935 - accuracy: 0.9660 - val_loss: 0.0954 - val_accuracy: 0.9657 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0905 - accuracy: 0.9667 - val_loss: 0.0901 - val_accuracy: 0.9643 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0901 - accuracy: 0.9675 - val_loss: 0.0918 - val_accuracy: 0.9657 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0885 - accuracy: 0.9667 - val_loss: 0.0924 - val_accuracy: 0.9635 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0866 - accuracy: 0.9691 - val_loss: 0.0930 - val_accuracy: 0.9628 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0854 - accuracy: 0.9686 - val_loss: 0.0971 - val_accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0834 - accuracy: 0.9697 - val_loss: 0.0956 - val_accuracy: 0.9635 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0833 - accuracy: 0.9676 - val_loss: 0.0933 - val_accuracy: 0.9680 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0810 - accuracy: 0.9691 - val_loss: 0.0917 - val_accuracy: 0.9665 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0813 - accuracy: 0.9692 - val_loss: 0.0919 - val_accuracy: 0.9635 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0811 - accuracy: 0.9693 - val_loss: 0.0948 - val_accuracy: 0.9680 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0817 - accuracy: 0.9689 - val_loss: 0.0939 - val_accuracy: 0.9672 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0768 - accuracy: 0.9719 - val_loss: 0.0923 - val_accuracy: 0.9672 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0798 - accuracy: 0.9716 - val_loss: 0.0922 - val_accuracy: 0.9680 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0792 - accuracy: 0.9710 - val_loss: 0.0927 - val_accuracy: 0.9672 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0771 - accuracy: 0.9729 - val_loss: 0.0922 - val_accuracy: 0.9657 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0768 - accuracy: 0.9717 - val_loss: 0.0933 - val_accuracy: 0.9665 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0771 - accuracy: 0.9719 - val_loss: 0.0933 - val_accuracy: 0.9657 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0786 - accuracy: 0.9713 - val_loss: 0.0926 - val_accuracy: 0.9657 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0789 - accuracy: 0.9694 - val_loss: 0.0921 - val_accuracy: 0.9657 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0771 - accuracy: 0.9722 - val_loss: 0.0927 - val_accuracy: 0.9657 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0776 - accuracy: 0.9719 - val_loss: 0.0927 - val_accuracy: 0.9657 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0761 - accuracy: 0.9724 - val_loss: 0.0927 - val_accuracy: 0.9665 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0772 - accuracy: 0.9708 - val_loss: 0.0925 - val_accuracy: 0.9657 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0772 - accuracy: 0.9695 - val_loss: 0.0924 - val_accuracy: 0.9657 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0785 - accuracy: 0.9712 - val_loss: 0.0920 - val_accuracy: 0.9657 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0767 - accuracy: 0.9703 - val_loss: 0.0921 - val_accuracy: 0.9665 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 8s 40ms/step - loss: 0.0759 - accuracy: 0.9713 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0777 - accuracy: 0.9713 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0783 - accuracy: 0.9709 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0771 - accuracy: 0.9698 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0774 - accuracy: 0.9715 - val_loss: 0.0927 - val_accuracy: 0.9665 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0770 - accuracy: 0.9710 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0765 - accuracy: 0.9693 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0773 - accuracy: 0.9718 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0766 - accuracy: 0.9712 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0780 - accuracy: 0.9705 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0771 - accuracy: 0.9722 - val_loss: 0.0925 - val_accuracy: 0.9665 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0796 - accuracy: 0.9710 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0756 - accuracy: 0.9728 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 8s 40ms/step - loss: 0.0782 - accuracy: 0.9704 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0785 - accuracy: 0.9721 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0770 - accuracy: 0.9720 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0763 - accuracy: 0.9719 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0781 - accuracy: 0.9701 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0765 - accuracy: 0.9724 - val_loss: 0.0926 - val_accuracy: 0.9665 - lr: 6.0936e-06\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 34ms/step - loss: 0.3033 - accuracy: 0.8966 - val_loss: 0.6824 - val_accuracy: 0.7074 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1462 - accuracy: 0.9458 - val_loss: 0.4577 - val_accuracy: 0.9404 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1236 - accuracy: 0.9537 - val_loss: 0.1494 - val_accuracy: 0.9576 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1193 - accuracy: 0.9550 - val_loss: 0.1109 - val_accuracy: 0.9576 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1109 - accuracy: 0.9571 - val_loss: 0.1072 - val_accuracy: 0.9576 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1018 - accuracy: 0.9612 - val_loss: 0.1041 - val_accuracy: 0.9598 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0978 - accuracy: 0.9626 - val_loss: 0.1039 - val_accuracy: 0.9598 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0971 - accuracy: 0.9607 - val_loss: 0.1059 - val_accuracy: 0.9598 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0908 - accuracy: 0.9650 - val_loss: 0.1080 - val_accuracy: 0.9598 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0898 - accuracy: 0.9640 - val_loss: 0.1017 - val_accuracy: 0.9635 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0896 - accuracy: 0.9655 - val_loss: 0.0994 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0849 - accuracy: 0.9658 - val_loss: 0.0994 - val_accuracy: 0.9635 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0815 - accuracy: 0.9666 - val_loss: 0.0965 - val_accuracy: 0.9665 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0829 - accuracy: 0.9676 - val_loss: 0.0982 - val_accuracy: 0.9650 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0791 - accuracy: 0.9689 - val_loss: 0.0988 - val_accuracy: 0.9650 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0798 - accuracy: 0.9689 - val_loss: 0.0986 - val_accuracy: 0.9628 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0784 - accuracy: 0.9695 - val_loss: 0.0971 - val_accuracy: 0.9650 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0777 - accuracy: 0.9690 - val_loss: 0.0974 - val_accuracy: 0.9643 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0754 - accuracy: 0.9712 - val_loss: 0.0972 - val_accuracy: 0.9643 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0753 - accuracy: 0.9703 - val_loss: 0.0973 - val_accuracy: 0.9665 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0752 - accuracy: 0.9695 - val_loss: 0.0987 - val_accuracy: 0.9665 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0738 - accuracy: 0.9699 - val_loss: 0.0983 - val_accuracy: 0.9665 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0742 - accuracy: 0.9707 - val_loss: 0.0976 - val_accuracy: 0.9643 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 8s 40ms/step - loss: 0.0721 - accuracy: 0.9717 - val_loss: 0.0991 - val_accuracy: 0.9650 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 9s 49ms/step - loss: 0.0718 - accuracy: 0.9707 - val_loss: 0.0983 - val_accuracy: 0.9643 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 11s 57ms/step - loss: 0.0744 - accuracy: 0.9705 - val_loss: 0.0988 - val_accuracy: 0.9650 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0760 - accuracy: 0.9703 - val_loss: 0.0979 - val_accuracy: 0.9650 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0736 - accuracy: 0.9705 - val_loss: 0.0987 - val_accuracy: 0.9665 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0728 - accuracy: 0.9715 - val_loss: 0.0994 - val_accuracy: 0.9657 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0728 - accuracy: 0.9719 - val_loss: 0.0984 - val_accuracy: 0.9650 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0727 - accuracy: 0.9700 - val_loss: 0.0987 - val_accuracy: 0.9657 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0732 - accuracy: 0.9707 - val_loss: 0.0981 - val_accuracy: 0.9650 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0730 - accuracy: 0.9718 - val_loss: 0.0984 - val_accuracy: 0.9657 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0729 - accuracy: 0.9703 - val_loss: 0.0986 - val_accuracy: 0.9665 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0749 - accuracy: 0.9708 - val_loss: 0.0981 - val_accuracy: 0.9650 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0737 - accuracy: 0.9709 - val_loss: 0.0983 - val_accuracy: 0.9650 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0753 - accuracy: 0.9702 - val_loss: 0.0981 - val_accuracy: 0.9657 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0712 - accuracy: 0.9705 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0717 - accuracy: 0.9713 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0726 - accuracy: 0.9713 - val_loss: 0.0984 - val_accuracy: 0.9657 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0728 - accuracy: 0.9710 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0723 - accuracy: 0.9718 - val_loss: 0.0984 - val_accuracy: 0.9657 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0728 - accuracy: 0.9718 - val_loss: 0.0983 - val_accuracy: 0.9657 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0725 - accuracy: 0.9722 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 7s 39ms/step - loss: 0.0695 - accuracy: 0.9724 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0724 - accuracy: 0.9718 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0717 - accuracy: 0.9711 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0714 - accuracy: 0.9725 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 9s 47ms/step - loss: 0.0702 - accuracy: 0.9715 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0709 - accuracy: 0.9721 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0749 - accuracy: 0.9702 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0722 - accuracy: 0.9715 - val_loss: 0.0985 - val_accuracy: 0.9657 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0737 - accuracy: 0.9707 - val_loss: 0.0984 - val_accuracy: 0.9657 - lr: 1.6927e-05\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 33ms/step - loss: 0.3508 - accuracy: 0.9120 - val_loss: 0.5595 - val_accuracy: 0.7267 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1417 - accuracy: 0.9479 - val_loss: 0.3035 - val_accuracy: 0.9121 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1198 - accuracy: 0.9581 - val_loss: 0.1305 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1095 - accuracy: 0.9590 - val_loss: 0.1402 - val_accuracy: 0.9442 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.1080 - accuracy: 0.9585 - val_loss: 0.1200 - val_accuracy: 0.9516 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1019 - accuracy: 0.9621 - val_loss: 0.1245 - val_accuracy: 0.9546 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0966 - accuracy: 0.9635 - val_loss: 0.1184 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0913 - accuracy: 0.9648 - val_loss: 0.1224 - val_accuracy: 0.9531 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0911 - accuracy: 0.9660 - val_loss: 0.1150 - val_accuracy: 0.9583 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.1101 - val_accuracy: 0.9605 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0847 - accuracy: 0.9670 - val_loss: 0.1079 - val_accuracy: 0.9598 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0823 - accuracy: 0.9679 - val_loss: 0.1058 - val_accuracy: 0.9628 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0815 - accuracy: 0.9690 - val_loss: 0.1060 - val_accuracy: 0.9598 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0823 - accuracy: 0.9700 - val_loss: 0.1089 - val_accuracy: 0.9590 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0794 - accuracy: 0.9719 - val_loss: 0.1102 - val_accuracy: 0.9605 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0775 - accuracy: 0.9717 - val_loss: 0.1095 - val_accuracy: 0.9598 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0759 - accuracy: 0.9718 - val_loss: 0.1059 - val_accuracy: 0.9613 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0759 - accuracy: 0.9706 - val_loss: 0.1065 - val_accuracy: 0.9598 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0748 - accuracy: 0.9723 - val_loss: 0.1064 - val_accuracy: 0.9605 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0743 - accuracy: 0.9725 - val_loss: 0.1054 - val_accuracy: 0.9613 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0725 - accuracy: 0.9722 - val_loss: 0.1057 - val_accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0743 - accuracy: 0.9730 - val_loss: 0.1063 - val_accuracy: 0.9598 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0749 - accuracy: 0.9729 - val_loss: 0.1062 - val_accuracy: 0.9590 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0724 - accuracy: 0.9727 - val_loss: 0.1052 - val_accuracy: 0.9628 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0704 - accuracy: 0.9729 - val_loss: 0.1060 - val_accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0738 - accuracy: 0.9719 - val_loss: 0.1054 - val_accuracy: 0.9635 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0742 - accuracy: 0.9709 - val_loss: 0.1055 - val_accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0704 - accuracy: 0.9752 - val_loss: 0.1065 - val_accuracy: 0.9613 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0707 - accuracy: 0.9739 - val_loss: 0.1054 - val_accuracy: 0.9635 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0712 - accuracy: 0.9739 - val_loss: 0.1059 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0720 - accuracy: 0.9719 - val_loss: 0.1056 - val_accuracy: 0.9628 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0711 - accuracy: 0.9739 - val_loss: 0.1057 - val_accuracy: 0.9635 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0725 - accuracy: 0.9718 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 0.0741 - accuracy: 0.9709 - val_loss: 0.1054 - val_accuracy: 0.9635 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0715 - accuracy: 0.9729 - val_loss: 0.1051 - val_accuracy: 0.9643 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0721 - accuracy: 0.9733 - val_loss: 0.1052 - val_accuracy: 0.9650 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0702 - accuracy: 0.9739 - val_loss: 0.1055 - val_accuracy: 0.9635 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0722 - accuracy: 0.9735 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0718 - accuracy: 0.9735 - val_loss: 0.1052 - val_accuracy: 0.9643 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0725 - accuracy: 0.9735 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0711 - accuracy: 0.9734 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0707 - accuracy: 0.9731 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0716 - accuracy: 0.9726 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0687 - accuracy: 0.9733 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0696 - accuracy: 0.9748 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0715 - accuracy: 0.9735 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 9s 47ms/step - loss: 0.0722 - accuracy: 0.9744 - val_loss: 0.1052 - val_accuracy: 0.9643 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0676 - accuracy: 0.9740 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0699 - accuracy: 0.9731 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0688 - accuracy: 0.9746 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0714 - accuracy: 0.9745 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0697 - accuracy: 0.9741 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 0.0720 - accuracy: 0.9732 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0718 - accuracy: 0.9739 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0739 - accuracy: 0.9717 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0736 - accuracy: 0.9724 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0706 - accuracy: 0.9736 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0714 - accuracy: 0.9740 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0723 - accuracy: 0.9732 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0699 - accuracy: 0.9730 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0730 - accuracy: 0.9744 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0722 - accuracy: 0.9740 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0723 - accuracy: 0.9724 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0726 - accuracy: 0.9729 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0729 - accuracy: 0.9738 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0698 - accuracy: 0.9739 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0700 - accuracy: 0.9730 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 1.3162e-06\n",
            "Epoch 69/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0725 - accuracy: 0.9734 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8973e-07\n",
            "Epoch 70/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0708 - accuracy: 0.9725 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8973e-07\n",
            "Epoch 71/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0729 - accuracy: 0.9721 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 7.8973e-07\n",
            "Epoch 72/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0708 - accuracy: 0.9736 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 4.7384e-07\n",
            "Epoch 73/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0708 - accuracy: 0.9743 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 4.7384e-07\n",
            "Epoch 74/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0721 - accuracy: 0.9727 - val_loss: 0.1054 - val_accuracy: 0.9643 - lr: 4.7384e-07\n",
            "Epoch 75/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0704 - accuracy: 0.9739 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.8430e-07\n",
            "Epoch 76/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0721 - accuracy: 0.9736 - val_loss: 0.1053 - val_accuracy: 0.9643 - lr: 2.8430e-07\n",
            "1343/1343 [==============================] - 3s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 35ms/step - loss: 0.5809 - accuracy: 0.9133 - val_loss: 0.3122 - val_accuracy: 0.9278 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.1450 - accuracy: 0.9472 - val_loss: 0.1484 - val_accuracy: 0.9583 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 0.1275 - accuracy: 0.9523 - val_loss: 0.1548 - val_accuracy: 0.9434 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.1190 - accuracy: 0.9542 - val_loss: 0.1239 - val_accuracy: 0.9657 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1124 - accuracy: 0.9580 - val_loss: 0.1276 - val_accuracy: 0.9613 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1067 - accuracy: 0.9602 - val_loss: 0.1245 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1002 - accuracy: 0.9622 - val_loss: 0.1203 - val_accuracy: 0.9628 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1010 - accuracy: 0.9620 - val_loss: 0.1274 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0958 - accuracy: 0.9650 - val_loss: 0.1240 - val_accuracy: 0.9665 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0949 - accuracy: 0.9633 - val_loss: 0.1206 - val_accuracy: 0.9665 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0932 - accuracy: 0.9633 - val_loss: 0.1193 - val_accuracy: 0.9687 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0907 - accuracy: 0.9656 - val_loss: 0.1188 - val_accuracy: 0.9687 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0917 - accuracy: 0.9647 - val_loss: 0.1193 - val_accuracy: 0.9657 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0906 - accuracy: 0.9653 - val_loss: 0.1220 - val_accuracy: 0.9657 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0890 - accuracy: 0.9662 - val_loss: 0.1191 - val_accuracy: 0.9672 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0879 - accuracy: 0.9668 - val_loss: 0.1209 - val_accuracy: 0.9672 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0843 - accuracy: 0.9686 - val_loss: 0.1239 - val_accuracy: 0.9657 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0863 - accuracy: 0.9669 - val_loss: 0.1253 - val_accuracy: 0.9672 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0823 - accuracy: 0.9682 - val_loss: 0.1200 - val_accuracy: 0.9680 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0831 - accuracy: 0.9681 - val_loss: 0.1213 - val_accuracy: 0.9672 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0834 - accuracy: 0.9680 - val_loss: 0.1205 - val_accuracy: 0.9680 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0836 - accuracy: 0.9698 - val_loss: 0.1217 - val_accuracy: 0.9680 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0842 - accuracy: 0.9666 - val_loss: 0.1216 - val_accuracy: 0.9665 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0802 - accuracy: 0.9700 - val_loss: 0.1225 - val_accuracy: 0.9680 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0817 - accuracy: 0.9681 - val_loss: 0.1216 - val_accuracy: 0.9680 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0858 - accuracy: 0.9686 - val_loss: 0.1194 - val_accuracy: 0.9672 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0818 - accuracy: 0.9703 - val_loss: 0.1204 - val_accuracy: 0.9672 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 9s 47ms/step - loss: 0.0834 - accuracy: 0.9687 - val_loss: 0.1206 - val_accuracy: 0.9680 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0814 - accuracy: 0.9715 - val_loss: 0.1203 - val_accuracy: 0.9680 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0818 - accuracy: 0.9688 - val_loss: 0.1202 - val_accuracy: 0.9687 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0806 - accuracy: 0.9699 - val_loss: 0.1202 - val_accuracy: 0.9687 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0825 - accuracy: 0.9674 - val_loss: 0.1198 - val_accuracy: 0.9680 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0822 - accuracy: 0.9681 - val_loss: 0.1196 - val_accuracy: 0.9680 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0848 - accuracy: 0.9676 - val_loss: 0.1199 - val_accuracy: 0.9680 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.1199 - val_accuracy: 0.9687 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0803 - accuracy: 0.9682 - val_loss: 0.1204 - val_accuracy: 0.9687 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0818 - accuracy: 0.9700 - val_loss: 0.1203 - val_accuracy: 0.9680 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0839 - accuracy: 0.9677 - val_loss: 0.1202 - val_accuracy: 0.9680 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0830 - accuracy: 0.9682 - val_loss: 0.1202 - val_accuracy: 0.9680 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0822 - accuracy: 0.9695 - val_loss: 0.1202 - val_accuracy: 0.9680 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0789 - accuracy: 0.9703 - val_loss: 0.1203 - val_accuracy: 0.9680 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0840 - accuracy: 0.9683 - val_loss: 0.1203 - val_accuracy: 0.9680 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0842 - accuracy: 0.9673 - val_loss: 0.1202 - val_accuracy: 0.9680 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0814 - accuracy: 0.9704 - val_loss: 0.1203 - val_accuracy: 0.9672 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0813 - accuracy: 0.9702 - val_loss: 0.1204 - val_accuracy: 0.9672 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0825 - accuracy: 0.9695 - val_loss: 0.1201 - val_accuracy: 0.9672 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 7s 38ms/step - loss: 0.0807 - accuracy: 0.9705 - val_loss: 0.1202 - val_accuracy: 0.9672 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0828 - accuracy: 0.9700 - val_loss: 0.1202 - val_accuracy: 0.9672 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0842 - accuracy: 0.9701 - val_loss: 0.1202 - val_accuracy: 0.9680 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0822 - accuracy: 0.9694 - val_loss: 0.1202 - val_accuracy: 0.9672 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0826 - accuracy: 0.9687 - val_loss: 0.1202 - val_accuracy: 0.9672 - lr: 1.6927e-05\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 33ms/step - loss: 0.6515 - accuracy: 0.9055 - val_loss: 0.3349 - val_accuracy: 0.9449 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1545 - accuracy: 0.9437 - val_loss: 0.1597 - val_accuracy: 0.9531 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1313 - accuracy: 0.9516 - val_loss: 0.0990 - val_accuracy: 0.9672 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1212 - accuracy: 0.9552 - val_loss: 0.1175 - val_accuracy: 0.9613 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1167 - accuracy: 0.9564 - val_loss: 0.0953 - val_accuracy: 0.9695 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1105 - accuracy: 0.9571 - val_loss: 0.0920 - val_accuracy: 0.9687 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1053 - accuracy: 0.9602 - val_loss: 0.0842 - val_accuracy: 0.9739 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1001 - accuracy: 0.9630 - val_loss: 0.0838 - val_accuracy: 0.9717 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0988 - accuracy: 0.9625 - val_loss: 0.0812 - val_accuracy: 0.9717 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0943 - accuracy: 0.9654 - val_loss: 0.0841 - val_accuracy: 0.9724 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0917 - accuracy: 0.9633 - val_loss: 0.0792 - val_accuracy: 0.9732 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0897 - accuracy: 0.9664 - val_loss: 0.0779 - val_accuracy: 0.9739 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0887 - accuracy: 0.9672 - val_loss: 0.0820 - val_accuracy: 0.9717 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0873 - accuracy: 0.9682 - val_loss: 0.0795 - val_accuracy: 0.9710 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0853 - accuracy: 0.9680 - val_loss: 0.0772 - val_accuracy: 0.9732 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0832 - accuracy: 0.9710 - val_loss: 0.0765 - val_accuracy: 0.9732 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0830 - accuracy: 0.9691 - val_loss: 0.0776 - val_accuracy: 0.9695 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0819 - accuracy: 0.9698 - val_loss: 0.0777 - val_accuracy: 0.9724 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0798 - accuracy: 0.9695 - val_loss: 0.0757 - val_accuracy: 0.9717 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0820 - accuracy: 0.9689 - val_loss: 0.0785 - val_accuracy: 0.9710 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0822 - accuracy: 0.9707 - val_loss: 0.0773 - val_accuracy: 0.9724 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0807 - accuracy: 0.9694 - val_loss: 0.0775 - val_accuracy: 0.9717 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0815 - accuracy: 0.9701 - val_loss: 0.0777 - val_accuracy: 0.9717 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0807 - accuracy: 0.9710 - val_loss: 0.0774 - val_accuracy: 0.9717 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0813 - accuracy: 0.9695 - val_loss: 0.0769 - val_accuracy: 0.9724 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0799 - accuracy: 0.9711 - val_loss: 0.0766 - val_accuracy: 0.9717 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0788 - accuracy: 0.9709 - val_loss: 0.0771 - val_accuracy: 0.9717 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0797 - accuracy: 0.9715 - val_loss: 0.0768 - val_accuracy: 0.9724 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0766 - accuracy: 0.9717 - val_loss: 0.0769 - val_accuracy: 0.9724 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0807 - accuracy: 0.9700 - val_loss: 0.0767 - val_accuracy: 0.9724 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0780 - accuracy: 0.9713 - val_loss: 0.0765 - val_accuracy: 0.9724 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 9s 50ms/step - loss: 0.0798 - accuracy: 0.9707 - val_loss: 0.0764 - val_accuracy: 0.9732 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 0.0772 - accuracy: 0.9731 - val_loss: 0.0765 - val_accuracy: 0.9732 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0782 - accuracy: 0.9700 - val_loss: 0.0768 - val_accuracy: 0.9724 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0794 - accuracy: 0.9700 - val_loss: 0.0767 - val_accuracy: 0.9724 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0789 - accuracy: 0.9709 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0772 - accuracy: 0.9704 - val_loss: 0.0768 - val_accuracy: 0.9724 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0771 - accuracy: 0.9726 - val_loss: 0.0767 - val_accuracy: 0.9724 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0787 - accuracy: 0.9711 - val_loss: 0.0767 - val_accuracy: 0.9724 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0774 - accuracy: 0.9713 - val_loss: 0.0767 - val_accuracy: 0.9724 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0798 - accuracy: 0.9715 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0775 - accuracy: 0.9707 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0762 - accuracy: 0.9732 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0775 - accuracy: 0.9727 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0767 - accuracy: 0.9724 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0805 - accuracy: 0.9706 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.0766 - val_accuracy: 0.9724 - lr: 4.7018e-05\n",
            "1343/1343 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 34ms/step - loss: 0.3205 - accuracy: 0.8921 - val_loss: 0.6495 - val_accuracy: 0.7273 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.1517 - accuracy: 0.9446 - val_loss: 0.4645 - val_accuracy: 0.9218 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1279 - accuracy: 0.9521 - val_loss: 0.1413 - val_accuracy: 0.9478 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1214 - accuracy: 0.9544 - val_loss: 0.1241 - val_accuracy: 0.9516 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1150 - accuracy: 0.9569 - val_loss: 0.1323 - val_accuracy: 0.9501 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1074 - accuracy: 0.9590 - val_loss: 0.1155 - val_accuracy: 0.9545 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1034 - accuracy: 0.9614 - val_loss: 0.1222 - val_accuracy: 0.9590 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1007 - accuracy: 0.9620 - val_loss: 0.1321 - val_accuracy: 0.9583 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0978 - accuracy: 0.9633 - val_loss: 0.1194 - val_accuracy: 0.9575 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0967 - accuracy: 0.9624 - val_loss: 0.1139 - val_accuracy: 0.9575 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0917 - accuracy: 0.9643 - val_loss: 0.1115 - val_accuracy: 0.9568 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 0.1111 - val_accuracy: 0.9575 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0886 - accuracy: 0.9655 - val_loss: 0.1109 - val_accuracy: 0.9575 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0893 - accuracy: 0.9662 - val_loss: 0.1089 - val_accuracy: 0.9613 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0830 - accuracy: 0.9671 - val_loss: 0.1108 - val_accuracy: 0.9590 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0865 - accuracy: 0.9675 - val_loss: 0.1143 - val_accuracy: 0.9590 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0844 - accuracy: 0.9680 - val_loss: 0.1106 - val_accuracy: 0.9575 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0822 - accuracy: 0.9672 - val_loss: 0.1112 - val_accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0828 - accuracy: 0.9685 - val_loss: 0.1103 - val_accuracy: 0.9553 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0821 - accuracy: 0.9692 - val_loss: 0.1114 - val_accuracy: 0.9575 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0821 - accuracy: 0.9676 - val_loss: 0.1109 - val_accuracy: 0.9568 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0821 - accuracy: 0.9681 - val_loss: 0.1093 - val_accuracy: 0.9560 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0817 - accuracy: 0.9677 - val_loss: 0.1087 - val_accuracy: 0.9590 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0823 - accuracy: 0.9676 - val_loss: 0.1117 - val_accuracy: 0.9598 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0789 - accuracy: 0.9694 - val_loss: 0.1100 - val_accuracy: 0.9553 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0794 - accuracy: 0.9689 - val_loss: 0.1103 - val_accuracy: 0.9590 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0788 - accuracy: 0.9696 - val_loss: 0.1113 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0784 - accuracy: 0.9704 - val_loss: 0.1112 - val_accuracy: 0.9598 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0783 - accuracy: 0.9703 - val_loss: 0.1109 - val_accuracy: 0.9583 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 7s 40ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.1107 - val_accuracy: 0.9575 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0816 - accuracy: 0.9691 - val_loss: 0.1108 - val_accuracy: 0.9568 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0799 - accuracy: 0.9688 - val_loss: 0.1102 - val_accuracy: 0.9575 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0782 - accuracy: 0.9696 - val_loss: 0.1104 - val_accuracy: 0.9575 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0781 - accuracy: 0.9698 - val_loss: 0.1105 - val_accuracy: 0.9568 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0775 - accuracy: 0.9698 - val_loss: 0.1105 - val_accuracy: 0.9575 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0799 - accuracy: 0.9675 - val_loss: 0.1103 - val_accuracy: 0.9575 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0807 - accuracy: 0.9694 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0776 - accuracy: 0.9700 - val_loss: 0.1103 - val_accuracy: 0.9575 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0809 - accuracy: 0.9681 - val_loss: 0.1102 - val_accuracy: 0.9575 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0806 - accuracy: 0.9711 - val_loss: 0.1100 - val_accuracy: 0.9575 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0816 - accuracy: 0.9690 - val_loss: 0.1100 - val_accuracy: 0.9575 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0813 - accuracy: 0.9693 - val_loss: 0.1099 - val_accuracy: 0.9575 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0775 - accuracy: 0.9713 - val_loss: 0.1099 - val_accuracy: 0.9575 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0789 - accuracy: 0.9687 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0800 - accuracy: 0.9696 - val_loss: 0.1100 - val_accuracy: 0.9575 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 9s 48ms/step - loss: 0.0796 - accuracy: 0.9689 - val_loss: 0.1100 - val_accuracy: 0.9575 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0773 - accuracy: 0.9699 - val_loss: 0.1100 - val_accuracy: 0.9575 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0785 - accuracy: 0.9689 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0801 - accuracy: 0.9694 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0774 - accuracy: 0.9706 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0797 - accuracy: 0.9691 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0773 - accuracy: 0.9705 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 34ms/step - loss: 0.0779 - accuracy: 0.9688 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0814 - accuracy: 0.9685 - val_loss: 0.1101 - val_accuracy: 0.9575 - lr: 1.0156e-05\n",
            "1342/1342 [==============================] - 2s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 7s 33ms/step - loss: 0.2718 - accuracy: 0.8958 - val_loss: 0.7775 - val_accuracy: 0.2891 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1496 - accuracy: 0.9459 - val_loss: 0.5343 - val_accuracy: 0.7809 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.1274 - accuracy: 0.9521 - val_loss: 0.1885 - val_accuracy: 0.9501 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1225 - accuracy: 0.9544 - val_loss: 0.1273 - val_accuracy: 0.9508 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1134 - accuracy: 0.9565 - val_loss: 0.1184 - val_accuracy: 0.9508 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1035 - accuracy: 0.9610 - val_loss: 0.1188 - val_accuracy: 0.9531 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.1013 - accuracy: 0.9618 - val_loss: 0.1139 - val_accuracy: 0.9560 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0993 - accuracy: 0.9627 - val_loss: 0.1249 - val_accuracy: 0.9486 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0953 - accuracy: 0.9644 - val_loss: 0.1139 - val_accuracy: 0.9531 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0908 - accuracy: 0.9643 - val_loss: 0.1119 - val_accuracy: 0.9560 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0904 - accuracy: 0.9661 - val_loss: 0.1089 - val_accuracy: 0.9553 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0867 - accuracy: 0.9672 - val_loss: 0.1075 - val_accuracy: 0.9575 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0860 - accuracy: 0.9665 - val_loss: 0.1089 - val_accuracy: 0.9568 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 0.1114 - val_accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0813 - accuracy: 0.9688 - val_loss: 0.1103 - val_accuracy: 0.9575 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0811 - accuracy: 0.9689 - val_loss: 0.1090 - val_accuracy: 0.9583 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 0.0816 - accuracy: 0.9695 - val_loss: 0.1092 - val_accuracy: 0.9553 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.1080 - val_accuracy: 0.9583 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0782 - accuracy: 0.9710 - val_loss: 0.1079 - val_accuracy: 0.9575 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0780 - accuracy: 0.9692 - val_loss: 0.1069 - val_accuracy: 0.9553 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0779 - accuracy: 0.9711 - val_loss: 0.1070 - val_accuracy: 0.9605 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0786 - accuracy: 0.9702 - val_loss: 0.1067 - val_accuracy: 0.9583 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0769 - accuracy: 0.9702 - val_loss: 0.1079 - val_accuracy: 0.9583 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0774 - accuracy: 0.9715 - val_loss: 0.1060 - val_accuracy: 0.9590 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0767 - accuracy: 0.9708 - val_loss: 0.1058 - val_accuracy: 0.9605 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0755 - accuracy: 0.9718 - val_loss: 0.1052 - val_accuracy: 0.9605 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0771 - accuracy: 0.9712 - val_loss: 0.1060 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0771 - accuracy: 0.9705 - val_loss: 0.1058 - val_accuracy: 0.9590 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0775 - accuracy: 0.9707 - val_loss: 0.1072 - val_accuracy: 0.9575 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0741 - accuracy: 0.9729 - val_loss: 0.1063 - val_accuracy: 0.9590 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.1063 - val_accuracy: 0.9598 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0777 - accuracy: 0.9696 - val_loss: 0.1058 - val_accuracy: 0.9605 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0759 - accuracy: 0.9725 - val_loss: 0.1058 - val_accuracy: 0.9590 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0757 - accuracy: 0.9716 - val_loss: 0.1057 - val_accuracy: 0.9583 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0763 - accuracy: 0.9722 - val_loss: 0.1058 - val_accuracy: 0.9583 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0751 - accuracy: 0.9723 - val_loss: 0.1057 - val_accuracy: 0.9605 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0762 - accuracy: 0.9711 - val_loss: 0.1059 - val_accuracy: 0.9590 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0739 - accuracy: 0.9725 - val_loss: 0.1058 - val_accuracy: 0.9583 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0740 - accuracy: 0.9710 - val_loss: 0.1058 - val_accuracy: 0.9583 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0756 - accuracy: 0.9705 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0747 - accuracy: 0.9724 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0744 - accuracy: 0.9701 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0764 - accuracy: 0.9711 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0760 - accuracy: 0.9720 - val_loss: 0.1058 - val_accuracy: 0.9583 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0754 - accuracy: 0.9711 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0760 - accuracy: 0.9713 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0727 - accuracy: 0.9733 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0747 - accuracy: 0.9719 - val_loss: 0.1057 - val_accuracy: 0.9598 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0734 - accuracy: 0.9717 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0769 - accuracy: 0.9694 - val_loss: 0.1057 - val_accuracy: 0.9598 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "189/189 [==============================] - 9s 47ms/step - loss: 0.0738 - accuracy: 0.9732 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "189/189 [==============================] - 6s 32ms/step - loss: 0.0769 - accuracy: 0.9700 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "189/189 [==============================] - 6s 33ms/step - loss: 0.0769 - accuracy: 0.9709 - val_loss: 0.1057 - val_accuracy: 0.9590 - lr: 1.0156e-05\n",
            "1342/1342 [==============================] - 3s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "388610dd-3784-4abf-c2cf-ea841c6b14ec"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9657426097455148 ± 0.004514571878611231\n",
            "0.9621574686457981 ± 0.006778052699792235\n",
            "0.9705491127336013 ± 0.0038237537324600887\n",
            "0.9537658245579947 ± 0.01335963358900246\n",
            "0.9160115232473642 ± 0.011581990766664892\n",
            "0.9907999875980019 ± 0.003279298842209914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_collecton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397sLYBohyh7",
        "outputId": "7cca9c4f-0da1-4f80-9bf3-b7da2713807b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9815950920245399]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34deaee-7d0b-4258-9a2e-cce3874149b9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "210/210 [==============================] - 8s 37ms/step - loss: 0.3073 - accuracy: 0.9056 - val_loss: 0.6940 - val_accuracy: 0.3489 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.1443 - accuracy: 0.9476 - val_loss: 0.4291 - val_accuracy: 0.9433 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.1246 - accuracy: 0.9517 - val_loss: 0.1545 - val_accuracy: 0.9535 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.1186 - accuracy: 0.9559 - val_loss: 0.1503 - val_accuracy: 0.9445 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "210/210 [==============================] - 8s 38ms/step - loss: 0.1127 - accuracy: 0.9571 - val_loss: 0.1181 - val_accuracy: 0.9545 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.1034 - accuracy: 0.9595 - val_loss: 0.1175 - val_accuracy: 0.9561 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "210/210 [==============================] - 10s 49ms/step - loss: 0.1015 - accuracy: 0.9625 - val_loss: 0.1120 - val_accuracy: 0.9561 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0980 - accuracy: 0.9625 - val_loss: 0.1111 - val_accuracy: 0.9562 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0920 - accuracy: 0.9657 - val_loss: 0.1075 - val_accuracy: 0.9592 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0894 - accuracy: 0.9651 - val_loss: 0.1125 - val_accuracy: 0.9577 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0891 - accuracy: 0.9641 - val_loss: 0.1100 - val_accuracy: 0.9581 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0827 - accuracy: 0.9681 - val_loss: 0.1069 - val_accuracy: 0.9603 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0855 - accuracy: 0.9670 - val_loss: 0.1063 - val_accuracy: 0.9603 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0826 - accuracy: 0.9681 - val_loss: 0.1090 - val_accuracy: 0.9573 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.1075 - val_accuracy: 0.9618 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0826 - accuracy: 0.9686 - val_loss: 0.1039 - val_accuracy: 0.9610 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0788 - accuracy: 0.9683 - val_loss: 0.1065 - val_accuracy: 0.9606 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0793 - accuracy: 0.9707 - val_loss: 0.1051 - val_accuracy: 0.9606 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0772 - accuracy: 0.9701 - val_loss: 0.1070 - val_accuracy: 0.9600 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0771 - accuracy: 0.9695 - val_loss: 0.1075 - val_accuracy: 0.9603 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0768 - accuracy: 0.9706 - val_loss: 0.1052 - val_accuracy: 0.9617 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0752 - accuracy: 0.9716 - val_loss: 0.1059 - val_accuracy: 0.9611 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0753 - accuracy: 0.9717 - val_loss: 0.1044 - val_accuracy: 0.9618 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "210/210 [==============================] - 9s 41ms/step - loss: 0.0744 - accuracy: 0.9721 - val_loss: 0.1059 - val_accuracy: 0.9618 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0753 - accuracy: 0.9701 - val_loss: 0.1048 - val_accuracy: 0.9617 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0751 - accuracy: 0.9713 - val_loss: 0.1043 - val_accuracy: 0.9621 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0758 - accuracy: 0.9710 - val_loss: 0.1046 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0764 - accuracy: 0.9700 - val_loss: 0.1048 - val_accuracy: 0.9624 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0756 - accuracy: 0.9709 - val_loss: 0.1047 - val_accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0739 - accuracy: 0.9726 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0747 - accuracy: 0.9719 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "210/210 [==============================] - 7s 35ms/step - loss: 0.0748 - accuracy: 0.9714 - val_loss: 0.1051 - val_accuracy: 0.9619 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0736 - accuracy: 0.9721 - val_loss: 0.1050 - val_accuracy: 0.9618 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0731 - accuracy: 0.9708 - val_loss: 0.1052 - val_accuracy: 0.9618 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0741 - accuracy: 0.9719 - val_loss: 0.1054 - val_accuracy: 0.9615 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0750 - accuracy: 0.9721 - val_loss: 0.1050 - val_accuracy: 0.9617 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0746 - accuracy: 0.9721 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0741 - accuracy: 0.9717 - val_loss: 0.1049 - val_accuracy: 0.9621 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0741 - accuracy: 0.9716 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "210/210 [==============================] - 7s 36ms/step - loss: 0.0726 - accuracy: 0.9726 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0722 - accuracy: 0.9722 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0731 - accuracy: 0.9726 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0722 - accuracy: 0.9721 - val_loss: 0.1049 - val_accuracy: 0.9618 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0734 - accuracy: 0.9708 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0740 - accuracy: 0.9705 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0732 - accuracy: 0.9734 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0741 - accuracy: 0.9715 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0735 - accuracy: 0.9718 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "210/210 [==============================] - 9s 45ms/step - loss: 0.0752 - accuracy: 0.9718 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "210/210 [==============================] - 8s 40ms/step - loss: 0.0722 - accuracy: 0.9706 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0757 - accuracy: 0.9713 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "210/210 [==============================] - 8s 40ms/step - loss: 0.0752 - accuracy: 0.9704 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "210/210 [==============================] - 8s 38ms/step - loss: 0.0739 - accuracy: 0.9714 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0741 - accuracy: 0.9709 - val_loss: 0.1049 - val_accuracy: 0.9620 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0747 - accuracy: 0.9728 - val_loss: 0.1048 - val_accuracy: 0.9620 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0734 - accuracy: 0.9722 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "210/210 [==============================] - 8s 36ms/step - loss: 0.0736 - accuracy: 0.9708 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0733 - accuracy: 0.9725 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0746 - accuracy: 0.9716 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0738 - accuracy: 0.9725 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0755 - accuracy: 0.9713 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0722 - accuracy: 0.9723 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0741 - accuracy: 0.9716 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0744 - accuracy: 0.9712 - val_loss: 0.1049 - val_accuracy: 0.9619 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0732 - accuracy: 0.9713 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "210/210 [==============================] - 8s 37ms/step - loss: 0.0718 - accuracy: 0.9720 - val_loss: 0.1048 - val_accuracy: 0.9619 - lr: 1.3162e-06\n",
            "8953/8953 [==============================] - 15s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c241dee2-4203-449e-e21a-9fa28e7ab8e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9623589858148107\n",
            "0.9579101207100744\n",
            "0.968032278088144\n",
            "0.9477879633320048\n",
            "0.907729512154961\n",
            "0.9909900935111878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('AMP_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/AMP_tensorflow_model.zip /content/AMP_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "3c42bbb6-7e1d-4451-aae1-b4e813a2ca99"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/AMP_alternative_tensorflow_model/ (stored 0%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/keras_metadata.pb (deflated 89%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 31%)\n",
            "  adding: content/AMP_alternative_tensorflow_model/saved_model.pb (deflated 88%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUpbNoJgsxY3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}