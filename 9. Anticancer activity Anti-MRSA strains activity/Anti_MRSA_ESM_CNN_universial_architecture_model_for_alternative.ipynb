{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ead619b0-812e-4482-a264-6d12becb5f96"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/db/1e/af4e9cded5093a92e60d4ae7149a02c7427661b2db66c8ea4d34b17864a2/sklearn-0.0.post1.tar.gz#sha256=76b9ed1623775168657b86b5fe966d45752e5c87f528de6240c38923b94147c5 (from https://pypi.org/simple/sklearn/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.7.3)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1309 sha256=44722408e130d12025d0e667d0fa527d472b96ce512e84f513303239f4de7b19\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('SCMRSA_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('SCMRSA_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label'] \n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0068bca-e8af-457d-99d1-1600be6cd9c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('SCMRSA_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('SCMRSA_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'SCMRSA_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'SCMRSA_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "e285635a-f505-44df-c08d-615de3569b61"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(796, 320)\n",
            "(199, 320)\n",
            "(796,)\n",
            "(199,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb8e961-1139-4342-ca52-f7f0642f7746"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 2s 8ms/step - loss: 1.8691 - accuracy: 0.8994 - val_loss: 0.3580 - val_accuracy: 0.8750 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1315 - accuracy: 0.9581 - val_loss: 0.1943 - val_accuracy: 0.9250 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0690 - accuracy: 0.9791 - val_loss: 0.1327 - val_accuracy: 0.9500 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9763 - val_loss: 0.0967 - val_accuracy: 0.9750 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0476 - accuracy: 0.9888 - val_loss: 0.1109 - val_accuracy: 0.9625 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0408 - accuracy: 0.9902 - val_loss: 0.1249 - val_accuracy: 0.9625 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.1365 - val_accuracy: 0.9500 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0259 - accuracy: 0.9930 - val_loss: 0.1322 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.1004 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 0.0949 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 0.1136 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.1103 - val_accuracy: 0.9500 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0159 - accuracy: 0.9944 - val_loss: 0.1212 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0189 - accuracy: 0.9958 - val_loss: 0.1102 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.1133 - val_accuracy: 0.9750 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.1111 - val_accuracy: 0.9750 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.1189 - val_accuracy: 0.9750 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9930 - val_loss: 0.1124 - val_accuracy: 0.9750 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9944 - val_loss: 0.1117 - val_accuracy: 0.9750 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.1097 - val_accuracy: 0.9625 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9930 - val_loss: 0.1132 - val_accuracy: 0.9625 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9930 - val_loss: 0.1130 - val_accuracy: 0.9750 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9930 - val_loss: 0.1121 - val_accuracy: 0.9750 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9944 - val_loss: 0.1145 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.1135 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.1134 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.1141 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.1143 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9930 - val_loss: 0.1152 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.1153 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1153 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9944 - val_loss: 0.1156 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9930 - val_loss: 0.1156 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.1154 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9916 - val_loss: 0.1154 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9930 - val_loss: 0.1153 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.1151 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.1153 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.1151 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.1151 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9944 - val_loss: 0.1154 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0157 - accuracy: 0.9958 - val_loss: 0.1154 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9958 - val_loss: 0.1153 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 0.1152 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "80/80 [==============================] - 0s 944us/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 1.3669 - accuracy: 0.9050 - val_loss: 0.4071 - val_accuracy: 0.8750 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1399 - accuracy: 0.9539 - val_loss: 0.2830 - val_accuracy: 0.8750 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0987 - accuracy: 0.9721 - val_loss: 0.1657 - val_accuracy: 0.9375 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0757 - accuracy: 0.9777 - val_loss: 0.1701 - val_accuracy: 0.9375 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0701 - accuracy: 0.9777 - val_loss: 0.2021 - val_accuracy: 0.9375 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.2280 - val_accuracy: 0.9500 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9846 - val_loss: 0.2108 - val_accuracy: 0.9500 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0436 - accuracy: 0.9832 - val_loss: 0.2684 - val_accuracy: 0.9375 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0505 - accuracy: 0.9860 - val_loss: 0.2286 - val_accuracy: 0.9500 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0414 - accuracy: 0.9874 - val_loss: 0.2347 - val_accuracy: 0.9500 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.2608 - val_accuracy: 0.9375 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9888 - val_loss: 0.2688 - val_accuracy: 0.9375 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0312 - accuracy: 0.9888 - val_loss: 0.2724 - val_accuracy: 0.9375 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.2662 - val_accuracy: 0.9500 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.2688 - val_accuracy: 0.9500 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.2664 - val_accuracy: 0.9500 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9902 - val_loss: 0.2708 - val_accuracy: 0.9500 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.2735 - val_accuracy: 0.9500 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0244 - accuracy: 0.9930 - val_loss: 0.2733 - val_accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0258 - accuracy: 0.9902 - val_loss: 0.2711 - val_accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9930 - val_loss: 0.2687 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9916 - val_loss: 0.2697 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9930 - val_loss: 0.2734 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.2762 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0280 - accuracy: 0.9888 - val_loss: 0.2741 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0227 - accuracy: 0.9916 - val_loss: 0.2748 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.2757 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.2757 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9944 - val_loss: 0.2763 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9916 - val_loss: 0.2760 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0234 - accuracy: 0.9916 - val_loss: 0.2766 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0214 - accuracy: 0.9930 - val_loss: 0.2765 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.2767 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9916 - val_loss: 0.2751 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.2759 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9916 - val_loss: 0.2770 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.2769 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 0.2774 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9916 - val_loss: 0.2777 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0213 - accuracy: 0.9902 - val_loss: 0.2784 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.2789 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0211 - accuracy: 0.9902 - val_loss: 0.2793 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0250 - accuracy: 0.9902 - val_loss: 0.2793 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.2790 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9888 - val_loss: 0.2789 - val_accuracy: 0.9375 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 0.2787 - val_accuracy: 0.9375 - lr: 4.7018e-05\n",
            "80/80 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 7ms/step - loss: 0.6241 - accuracy: 0.9008 - val_loss: 0.4365 - val_accuracy: 0.8500 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1596 - accuracy: 0.9427 - val_loss: 0.4430 - val_accuracy: 0.8500 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0893 - accuracy: 0.9665 - val_loss: 0.3920 - val_accuracy: 0.8500 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0922 - accuracy: 0.9693 - val_loss: 0.3000 - val_accuracy: 0.8750 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0555 - accuracy: 0.9846 - val_loss: 0.1464 - val_accuracy: 0.9625 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0507 - accuracy: 0.9791 - val_loss: 0.0745 - val_accuracy: 0.9625 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0439 - accuracy: 0.9888 - val_loss: 0.0545 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0412 - accuracy: 0.9916 - val_loss: 0.0424 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0441 - accuracy: 0.9846 - val_loss: 0.0656 - val_accuracy: 0.9625 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9916 - val_loss: 0.0318 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 0.0391 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9958 - val_loss: 0.0472 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.0359 - accuracy: 0.9916 - val_loss: 0.0457 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.0519 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.0411 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 0.0369 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0242 - accuracy: 0.9902 - val_loss: 0.0571 - val_accuracy: 0.9750 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0347 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0229 - accuracy: 0.9930 - val_loss: 0.0388 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0206 - accuracy: 0.9944 - val_loss: 0.0388 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0396 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0177 - accuracy: 0.9930 - val_loss: 0.0366 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9972 - val_loss: 0.0357 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0358 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0392 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0175 - accuracy: 0.9972 - val_loss: 0.0404 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9972 - val_loss: 0.0424 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0431 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0439 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.9958 - val_loss: 0.0440 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0135 - accuracy: 0.9986 - val_loss: 0.0427 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 0.0426 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9958 - val_loss: 0.0421 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0238 - accuracy: 0.9902 - val_loss: 0.0430 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9972 - val_loss: 0.0424 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0123 - accuracy: 0.9972 - val_loss: 0.0422 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.0421 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9986 - val_loss: 0.0418 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9958 - val_loss: 0.0419 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.0419 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0149 - accuracy: 0.9958 - val_loss: 0.0418 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0418 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0417 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0419 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9972 - val_loss: 0.0419 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0418 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9958 - val_loss: 0.0418 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0417 - val_accuracy: 0.9875 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.0417 - val_accuracy: 0.9875 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0247 - accuracy: 0.9902 - val_loss: 0.0416 - val_accuracy: 0.9875 - lr: 2.8211e-05\n",
            "80/80 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 0.7961 - accuracy: 0.8953 - val_loss: 0.4069 - val_accuracy: 0.8875 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1392 - accuracy: 0.9358 - val_loss: 0.4171 - val_accuracy: 0.9875 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1098 - accuracy: 0.9525 - val_loss: 0.2811 - val_accuracy: 0.9625 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0840 - accuracy: 0.9595 - val_loss: 0.0978 - val_accuracy: 0.9875 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0699 - accuracy: 0.9721 - val_loss: 0.0559 - val_accuracy: 0.9875 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.0549 - accuracy: 0.9832 - val_loss: 0.0450 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 12ms/step - loss: 0.0548 - accuracy: 0.9777 - val_loss: 0.0356 - val_accuracy: 0.9875 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 11ms/step - loss: 0.0334 - accuracy: 0.9860 - val_loss: 0.0323 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.0382 - accuracy: 0.9846 - val_loss: 0.0327 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0242 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.0292 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0364 - accuracy: 0.9860 - val_loss: 0.0276 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0349 - accuracy: 0.9832 - val_loss: 0.0326 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9930 - val_loss: 0.0257 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9972 - val_loss: 0.0354 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9916 - val_loss: 0.0331 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9986 - val_loss: 0.0324 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.9972 - val_loss: 0.0349 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 0.0344 - val_accuracy: 0.9750 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0188 - accuracy: 0.9930 - val_loss: 0.0319 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0308 - val_accuracy: 0.9750 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 0.0330 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0334 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0319 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9902 - val_loss: 0.0332 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9972 - val_loss: 0.0338 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9958 - val_loss: 0.0330 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9944 - val_loss: 0.0328 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0331 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9944 - val_loss: 0.0342 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.0342 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 0.0349 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 0.0352 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0351 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0205 - accuracy: 0.9916 - val_loss: 0.0351 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0350 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9972 - val_loss: 0.0349 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.0346 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0154 - accuracy: 0.9930 - val_loss: 0.0349 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0349 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9972 - val_loss: 0.0350 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.0351 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "80/80 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 2.1574 - accuracy: 0.8324 - val_loss: 0.4013 - val_accuracy: 0.8625 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.4016 - accuracy: 0.8589 - val_loss: 0.4013 - val_accuracy: 0.8625 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.2016 - accuracy: 0.9288 - val_loss: 0.2665 - val_accuracy: 0.9000 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1499 - accuracy: 0.9455 - val_loss: 0.1211 - val_accuracy: 0.9750 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1943 - accuracy: 0.9651 - val_loss: 0.2258 - val_accuracy: 0.9125 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0921 - accuracy: 0.9679 - val_loss: 0.0759 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1008 - accuracy: 0.9665 - val_loss: 0.1337 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1006 - accuracy: 0.9749 - val_loss: 0.0698 - val_accuracy: 0.9750 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0837 - accuracy: 0.9749 - val_loss: 0.0690 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.0692 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0583 - accuracy: 0.9791 - val_loss: 0.0726 - val_accuracy: 0.9750 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0516 - accuracy: 0.9818 - val_loss: 0.0758 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9832 - val_loss: 0.0826 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0473 - accuracy: 0.9804 - val_loss: 0.0898 - val_accuracy: 0.9750 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0496 - accuracy: 0.9818 - val_loss: 0.0897 - val_accuracy: 0.9750 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0536 - accuracy: 0.9804 - val_loss: 0.0832 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0391 - accuracy: 0.9874 - val_loss: 0.0814 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0485 - accuracy: 0.9804 - val_loss: 0.0840 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0420 - accuracy: 0.9860 - val_loss: 0.0830 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0366 - accuracy: 0.9860 - val_loss: 0.0885 - val_accuracy: 0.9750 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0431 - accuracy: 0.9791 - val_loss: 0.0864 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.0876 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0399 - accuracy: 0.9818 - val_loss: 0.0870 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0407 - accuracy: 0.9818 - val_loss: 0.0874 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 0.0885 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0419 - accuracy: 0.9818 - val_loss: 0.0868 - val_accuracy: 0.9750 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0359 - accuracy: 0.9846 - val_loss: 0.0872 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0498 - accuracy: 0.9804 - val_loss: 0.0880 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0361 - accuracy: 0.9846 - val_loss: 0.0885 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 0s 5ms/step - loss: 0.0328 - accuracy: 0.9888 - val_loss: 0.0888 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0420 - accuracy: 0.9846 - val_loss: 0.0894 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0399 - accuracy: 0.9888 - val_loss: 0.0894 - val_accuracy: 0.9750 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9874 - val_loss: 0.0899 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 9ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.0899 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0370 - accuracy: 0.9860 - val_loss: 0.0899 - val_accuracy: 0.9750 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0440 - accuracy: 0.9832 - val_loss: 0.0900 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0433 - accuracy: 0.9846 - val_loss: 0.0904 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0292 - accuracy: 0.9860 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0356 - accuracy: 0.9874 - val_loss: 0.0907 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 0.0907 - val_accuracy: 0.9750 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0394 - accuracy: 0.9874 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0393 - accuracy: 0.9846 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9846 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0362 - accuracy: 0.9874 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.0907 - val_accuracy: 0.9750 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0385 - accuracy: 0.9846 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0322 - accuracy: 0.9902 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0424 - accuracy: 0.9832 - val_loss: 0.0908 - val_accuracy: 0.9750 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0341 - accuracy: 0.9860 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0393 - accuracy: 0.9846 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0369 - accuracy: 0.9860 - val_loss: 0.0909 - val_accuracy: 0.9750 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 0.0910 - val_accuracy: 0.9750 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0444 - accuracy: 0.9860 - val_loss: 0.0910 - val_accuracy: 0.9750 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0389 - accuracy: 0.9888 - val_loss: 0.0910 - val_accuracy: 0.9750 - lr: 1.0156e-05\n",
            "80/80 [==============================] - 0s 981us/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 10ms/step - loss: 1.5691 - accuracy: 0.8198 - val_loss: 0.4005 - val_accuracy: 0.8875 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1896 - accuracy: 0.9469 - val_loss: 0.5797 - val_accuracy: 0.8000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1025 - accuracy: 0.9693 - val_loss: 0.2371 - val_accuracy: 0.9375 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0895 - accuracy: 0.9735 - val_loss: 0.0942 - val_accuracy: 0.9750 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0783 - accuracy: 0.9777 - val_loss: 0.0492 - val_accuracy: 0.9750 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0520 - accuracy: 0.9818 - val_loss: 0.0309 - val_accuracy: 0.9875 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 0.0207 - val_accuracy: 1.0000 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.0313 - val_accuracy: 0.9875 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.0345 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0403 - accuracy: 0.9902 - val_loss: 0.0239 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0426 - val_accuracy: 0.9875 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0510 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0380 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.0281 - val_accuracy: 0.9875 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.0319 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9958 - val_loss: 0.0365 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0172 - val_accuracy: 0.9875 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0206 - accuracy: 0.9930 - val_loss: 0.0206 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0155 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.0171 - val_accuracy: 0.9875 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9944 - val_loss: 0.0141 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.0134 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.0177 - val_accuracy: 0.9875 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 0.0181 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 0.0172 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0183 - val_accuracy: 0.9875 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9958 - val_loss: 0.0176 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0176 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0177 - val_accuracy: 0.9875 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0135 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0180 - accuracy: 0.9972 - val_loss: 0.0164 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.0171 - val_accuracy: 0.9875 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0176 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0175 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 0.9875 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0175 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.0176 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.0174 - val_accuracy: 0.9875 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9972 - val_loss: 0.0171 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.0173 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9986 - val_loss: 0.0173 - val_accuracy: 0.9875 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9972 - val_loss: 0.0174 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9986 - val_loss: 0.0174 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0172 - val_accuracy: 0.9875 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9972 - val_loss: 0.0172 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.0172 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0197 - accuracy: 0.9958 - val_loss: 0.0171 - val_accuracy: 0.9875 - lr: 4.7018e-05\n",
            "80/80 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 1.9715 - accuracy: 0.8815 - val_loss: 0.4514 - val_accuracy: 0.7975 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1609 - accuracy: 0.9386 - val_loss: 0.2040 - val_accuracy: 0.9494 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0985 - accuracy: 0.9651 - val_loss: 0.1550 - val_accuracy: 0.9620 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9665 - val_loss: 0.1864 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0856 - accuracy: 0.9693 - val_loss: 0.1564 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0591 - accuracy: 0.9777 - val_loss: 0.2004 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0499 - accuracy: 0.9847 - val_loss: 0.1923 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0457 - accuracy: 0.9874 - val_loss: 0.1794 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.2211 - val_accuracy: 0.9494 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9847 - val_loss: 0.2335 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.2145 - val_accuracy: 0.9494 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0278 - accuracy: 0.9916 - val_loss: 0.2226 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0298 - accuracy: 0.9916 - val_loss: 0.2260 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0245 - accuracy: 0.9874 - val_loss: 0.2554 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.2365 - val_accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0299 - accuracy: 0.9874 - val_loss: 0.2315 - val_accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.2198 - val_accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.2154 - val_accuracy: 0.9494 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9902 - val_loss: 0.2196 - val_accuracy: 0.9494 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0181 - accuracy: 0.9930 - val_loss: 0.2217 - val_accuracy: 0.9494 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0192 - accuracy: 0.9916 - val_loss: 0.2258 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0177 - accuracy: 0.9930 - val_loss: 0.2268 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.2251 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9972 - val_loss: 0.2260 - val_accuracy: 0.9494 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9930 - val_loss: 0.2247 - val_accuracy: 0.9494 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 0.2283 - val_accuracy: 0.9494 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.2276 - val_accuracy: 0.9494 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0238 - accuracy: 0.9916 - val_loss: 0.2269 - val_accuracy: 0.9494 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9958 - val_loss: 0.2276 - val_accuracy: 0.9494 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9916 - val_loss: 0.2281 - val_accuracy: 0.9494 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0160 - accuracy: 0.9958 - val_loss: 0.2285 - val_accuracy: 0.9494 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0243 - accuracy: 0.9902 - val_loss: 0.2276 - val_accuracy: 0.9494 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.2274 - val_accuracy: 0.9494 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9930 - val_loss: 0.2269 - val_accuracy: 0.9494 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0233 - accuracy: 0.9930 - val_loss: 0.2275 - val_accuracy: 0.9494 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9902 - val_loss: 0.2276 - val_accuracy: 0.9494 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9916 - val_loss: 0.2276 - val_accuracy: 0.9494 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9916 - val_loss: 0.2271 - val_accuracy: 0.9494 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.2267 - val_accuracy: 0.9494 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.2269 - val_accuracy: 0.9494 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9944 - val_loss: 0.2268 - val_accuracy: 0.9494 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0253 - accuracy: 0.9902 - val_loss: 0.2266 - val_accuracy: 0.9494 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9902 - val_loss: 0.2271 - val_accuracy: 0.9494 - lr: 7.8364e-05\n",
            "79/79 [==============================] - 0s 959us/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 0.7015 - accuracy: 0.8815 - val_loss: 0.6584 - val_accuracy: 0.8861 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1307 - accuracy: 0.9554 - val_loss: 0.6860 - val_accuracy: 0.4051 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0855 - accuracy: 0.9805 - val_loss: 0.5955 - val_accuracy: 0.9747 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0620 - accuracy: 0.9791 - val_loss: 0.3210 - val_accuracy: 0.9620 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0527 - accuracy: 0.9819 - val_loss: 0.2514 - val_accuracy: 0.9620 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0380 - accuracy: 0.9888 - val_loss: 0.2823 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.3078 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 0.3802 - val_accuracy: 0.9367 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0268 - accuracy: 0.9944 - val_loss: 0.3489 - val_accuracy: 0.9494 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0193 - accuracy: 0.9958 - val_loss: 0.3744 - val_accuracy: 0.9494 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.4238 - val_accuracy: 0.9494 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.4408 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9944 - val_loss: 0.4265 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0200 - accuracy: 0.9930 - val_loss: 0.4201 - val_accuracy: 0.9494 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.4744 - val_accuracy: 0.9367 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.4465 - val_accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.4653 - val_accuracy: 0.9494 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.5015 - val_accuracy: 0.9494 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9958 - val_loss: 0.5002 - val_accuracy: 0.9367 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.4909 - val_accuracy: 0.9494 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9986 - val_loss: 0.4796 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0119 - accuracy: 0.9986 - val_loss: 0.4941 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.4764 - val_accuracy: 0.9494 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9958 - val_loss: 0.4816 - val_accuracy: 0.9494 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.4824 - val_accuracy: 0.9494 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.4748 - val_accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9958 - val_loss: 0.4774 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.4723 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0153 - accuracy: 0.9958 - val_loss: 0.4738 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9958 - val_loss: 0.4726 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.4700 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.4700 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9986 - val_loss: 0.4706 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.4717 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9986 - val_loss: 0.4762 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.4776 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9986 - val_loss: 0.4795 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 0.4829 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0114 - accuracy: 0.9986 - val_loss: 0.4816 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.4805 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.4806 - val_accuracy: 0.9620 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.4821 - val_accuracy: 0.9620 - lr: 7.8364e-05\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 1.3086 - accuracy: 0.8619 - val_loss: 0.2750 - val_accuracy: 0.9114 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1831 - accuracy: 0.9498 - val_loss: 0.2569 - val_accuracy: 0.9114 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1019 - accuracy: 0.9721 - val_loss: 0.1982 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0826 - accuracy: 0.9763 - val_loss: 0.1380 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0667 - accuracy: 0.9777 - val_loss: 0.1226 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0552 - accuracy: 0.9805 - val_loss: 0.1058 - val_accuracy: 0.9747 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0562 - accuracy: 0.9861 - val_loss: 0.1099 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.1177 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9861 - val_loss: 0.1361 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0433 - accuracy: 0.9902 - val_loss: 0.1202 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0336 - accuracy: 0.9902 - val_loss: 0.1273 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0430 - accuracy: 0.9861 - val_loss: 0.1321 - val_accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.1387 - val_accuracy: 0.9747 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0360 - accuracy: 0.9888 - val_loss: 0.1392 - val_accuracy: 0.9747 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9930 - val_loss: 0.1498 - val_accuracy: 0.9747 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.1499 - val_accuracy: 0.9747 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9930 - val_loss: 0.1529 - val_accuracy: 0.9620 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9902 - val_loss: 0.1519 - val_accuracy: 0.9620 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9944 - val_loss: 0.1560 - val_accuracy: 0.9747 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0258 - accuracy: 0.9902 - val_loss: 0.1526 - val_accuracy: 0.9620 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9902 - val_loss: 0.1532 - val_accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.1560 - val_accuracy: 0.9747 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0298 - accuracy: 0.9902 - val_loss: 0.1560 - val_accuracy: 0.9747 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.1555 - val_accuracy: 0.9747 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.1568 - val_accuracy: 0.9747 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.1562 - val_accuracy: 0.9747 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9916 - val_loss: 0.1563 - val_accuracy: 0.9747 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.1565 - val_accuracy: 0.9747 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.1586 - val_accuracy: 0.9747 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 0.1583 - val_accuracy: 0.9747 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0273 - accuracy: 0.9930 - val_loss: 0.1581 - val_accuracy: 0.9747 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.1587 - val_accuracy: 0.9747 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9930 - val_loss: 0.1592 - val_accuracy: 0.9747 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.1587 - val_accuracy: 0.9747 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0231 - accuracy: 0.9930 - val_loss: 0.1585 - val_accuracy: 0.9747 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0223 - accuracy: 0.9944 - val_loss: 0.1588 - val_accuracy: 0.9747 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.1589 - val_accuracy: 0.9747 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0297 - accuracy: 0.9916 - val_loss: 0.1589 - val_accuracy: 0.9747 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.1592 - val_accuracy: 0.9747 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.1593 - val_accuracy: 0.9747 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9902 - val_loss: 0.1590 - val_accuracy: 0.9747 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.1590 - val_accuracy: 0.9747 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.1593 - val_accuracy: 0.9747 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0275 - accuracy: 0.9916 - val_loss: 0.1594 - val_accuracy: 0.9747 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.1593 - val_accuracy: 0.9747 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9916 - val_loss: 0.1590 - val_accuracy: 0.9747 - lr: 4.7018e-05\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 1s 8ms/step - loss: 1.3025 - accuracy: 0.8968 - val_loss: 0.3484 - val_accuracy: 0.8354 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.1201 - accuracy: 0.9596 - val_loss: 0.2190 - val_accuracy: 0.9494 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0784 - accuracy: 0.9763 - val_loss: 0.1352 - val_accuracy: 0.9620 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0721 - accuracy: 0.9721 - val_loss: 0.1341 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0602 - accuracy: 0.9791 - val_loss: 0.1428 - val_accuracy: 0.9494 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9874 - val_loss: 0.1245 - val_accuracy: 0.9620 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9847 - val_loss: 0.1349 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0475 - accuracy: 0.9819 - val_loss: 0.2028 - val_accuracy: 0.9494 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.1416 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.1627 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 0.1900 - val_accuracy: 0.9620 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0203 - accuracy: 0.9930 - val_loss: 0.1670 - val_accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0220 - accuracy: 0.9944 - val_loss: 0.1757 - val_accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9902 - val_loss: 0.1724 - val_accuracy: 0.9620 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.1652 - val_accuracy: 0.9620 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.1792 - val_accuracy: 0.9620 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.1945 - val_accuracy: 0.9620 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9930 - val_loss: 0.1756 - val_accuracy: 0.9620 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.1746 - val_accuracy: 0.9620 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0209 - accuracy: 0.9916 - val_loss: 0.1714 - val_accuracy: 0.9620 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 0.1842 - val_accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0215 - accuracy: 0.9902 - val_loss: 0.1820 - val_accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0172 - accuracy: 0.9916 - val_loss: 0.1807 - val_accuracy: 0.9620 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.1690 - val_accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.1740 - val_accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0180 - accuracy: 0.9916 - val_loss: 0.1741 - val_accuracy: 0.9620 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.1754 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.1747 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0126 - accuracy: 0.9972 - val_loss: 0.1753 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.1772 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.1783 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9986 - val_loss: 0.1783 - val_accuracy: 0.9620 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.1795 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.1795 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9916 - val_loss: 0.1795 - val_accuracy: 0.9620 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9986 - val_loss: 0.1800 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.1798 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.1803 - val_accuracy: 0.9620 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.1806 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.1810 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0164 - accuracy: 0.9916 - val_loss: 0.1799 - val_accuracy: 0.9620 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.1797 - val_accuracy: 0.9620 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "90/90 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9930 - val_loss: 0.1806 - val_accuracy: 0.9620 - lr: 7.8364e-05\n",
            "79/79 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "8505cfc0-ec1e-4729-815c-864e862ee67d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9760917721518987 ± 0.015069157059107196\n",
            "0.9716010295561927 ± 0.026626543642595472\n",
            "0.9652380952380952 ± 0.04979423521270552\n",
            "0.97796396387429 ± 0.01463285092778108\n",
            "0.9054583397942533 ± 0.05261340591987753\n",
            "0.9780359548650902 ± 0.020790983784297903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2207cc4b-0edc-4821-ea35-cb4edd7cdd22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/100 [==============================] - 1s 7ms/step - loss: 1.1781 - accuracy: 0.8982 - val_loss: 0.2764 - val_accuracy: 0.9548 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.1172 - accuracy: 0.9585 - val_loss: 0.1241 - val_accuracy: 0.9799 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0856 - accuracy: 0.9661 - val_loss: 0.0743 - val_accuracy: 0.9799 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9749 - val_loss: 0.0413 - val_accuracy: 0.9849 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0758 - accuracy: 0.9749 - val_loss: 0.1268 - val_accuracy: 0.9698 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0571 - accuracy: 0.9862 - val_loss: 0.0327 - val_accuracy: 0.9899 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0448 - accuracy: 0.9862 - val_loss: 0.0381 - val_accuracy: 0.9849 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0434 - accuracy: 0.9862 - val_loss: 0.0359 - val_accuracy: 0.9799 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0390 - accuracy: 0.9887 - val_loss: 0.0351 - val_accuracy: 0.9799 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0345 - accuracy: 0.9899 - val_loss: 0.0353 - val_accuracy: 0.9799 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0286 - accuracy: 0.9925 - val_loss: 0.0358 - val_accuracy: 0.9799 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0485 - val_accuracy: 0.9799 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.0363 - val_accuracy: 0.9799 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9887 - val_loss: 0.0331 - val_accuracy: 0.9799 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.0405 - val_accuracy: 0.9799 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.0360 - val_accuracy: 0.9799 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0237 - accuracy: 0.9899 - val_loss: 0.0399 - val_accuracy: 0.9799 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0359 - val_accuracy: 0.9799 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0395 - val_accuracy: 0.9799 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.0387 - val_accuracy: 0.9799 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0175 - accuracy: 0.9950 - val_loss: 0.0355 - val_accuracy: 0.9799 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0170 - accuracy: 0.9912 - val_loss: 0.0345 - val_accuracy: 0.9799 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0180 - accuracy: 0.9950 - val_loss: 0.0340 - val_accuracy: 0.9849 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.0327 - val_accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0171 - accuracy: 0.9937 - val_loss: 0.0323 - val_accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9937 - val_loss: 0.0329 - val_accuracy: 0.9849 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0332 - val_accuracy: 0.9799 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0327 - val_accuracy: 0.9799 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0323 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.0326 - val_accuracy: 0.9799 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.0325 - val_accuracy: 0.9849 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0325 - val_accuracy: 0.9849 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0215 - accuracy: 0.9925 - val_loss: 0.0328 - val_accuracy: 0.9799 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 1s 12ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.0330 - val_accuracy: 0.9799 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 0.0174 - accuracy: 0.9937 - val_loss: 0.0331 - val_accuracy: 0.9799 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0332 - val_accuracy: 0.9799 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.0332 - val_accuracy: 0.9799 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0333 - val_accuracy: 0.9799 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 0.0333 - val_accuracy: 0.9799 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0333 - val_accuracy: 0.9799 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.0333 - val_accuracy: 0.9799 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.0334 - val_accuracy: 0.9799 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0335 - val_accuracy: 0.9799 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9950 - val_loss: 0.0335 - val_accuracy: 0.9799 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0216 - accuracy: 0.9912 - val_loss: 0.0336 - val_accuracy: 0.9799 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0336 - val_accuracy: 0.9799 - lr: 4.7018e-05\n",
            "199/199 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911f3bd0-4565-462f-ae3c-0e8afa079064"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9899497487437185\n",
            "0.9941520467836258\n",
            "1.0\n",
            "0.9883040935672515\n",
            "0.9604255067396437\n",
            "0.9986193293885601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Anti_MRSA_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/Anti_MRSA_tensorflow_model.zip /content/Anti_MRSA_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "8f171d95-ffcb-4c50-8fb9-11220f5768b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Anti_MRSA_tensorflow_model/ (stored 0%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 42%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/Anti_MRSA_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fhgta_V8n_M3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}