{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc472b55-f2b4-451d-c269-a66d635c1db6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (main dataset)"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('AMAP_train_main.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMAP_train_main_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('AMAP_test_main.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMAP_test_main_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'AMAP_train_main_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'AMAP_test_main_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "dbdb3ca9-11e7-4207-912e-a20e0b67dc22"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1819, 320)\n",
            "(455, 320)\n",
            "(1819, 1)\n",
            "(455,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (alternative dataset)"
      ],
      "metadata": {
        "id": "7qxqYf-d_dCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LXftqHY1_iEm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('AMAP_train_alternative.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMAP_train_alternative_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "VYDJ5sxJ_ilc"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('AMAP_test_alternative.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('AMAP_test_alternative_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "dH3XGmWJ_ifc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'AMAP_train_alternative_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'AMAP_test_alternative_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I_QVh1hA_ib4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk831Klh_iXF",
        "outputId": "c05ec3dc-2a45-42cd-bbec-90edf1abe1c8"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(653, 320)\n",
            "(163, 320)\n",
            "(653,)\n",
            "(163,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bd026e-81f4-4b8b-b7c5-a6bd746d4d29"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 13ms/step - loss: 1.6098 - accuracy: 0.8790 - val_loss: 0.3579 - val_accuracy: 0.8333 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.1665 - accuracy: 0.9455 - val_loss: 0.3097 - val_accuracy: 0.8636 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 13ms/step - loss: 0.0987 - accuracy: 0.9642 - val_loss: 0.1854 - val_accuracy: 0.9091 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0801 - accuracy: 0.9710 - val_loss: 0.1928 - val_accuracy: 0.9394 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.2465 - val_accuracy: 0.9091 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0473 - accuracy: 0.9847 - val_loss: 0.2469 - val_accuracy: 0.9091 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0449 - accuracy: 0.9830 - val_loss: 0.2481 - val_accuracy: 0.9091 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0390 - accuracy: 0.9864 - val_loss: 0.3024 - val_accuracy: 0.9242 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 0.3185 - val_accuracy: 0.9091 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.3058 - val_accuracy: 0.9242 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 0.3295 - val_accuracy: 0.9242 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.3323 - val_accuracy: 0.9242 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.3275 - val_accuracy: 0.9242 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.3336 - val_accuracy: 0.9091 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0172 - accuracy: 0.9932 - val_loss: 0.3384 - val_accuracy: 0.9242 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.3429 - val_accuracy: 0.9242 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9949 - val_loss: 0.3457 - val_accuracy: 0.9242 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0149 - accuracy: 0.9932 - val_loss: 0.3434 - val_accuracy: 0.9242 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 0.3464 - val_accuracy: 0.9242 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.3491 - val_accuracy: 0.9091 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9932 - val_loss: 0.3486 - val_accuracy: 0.9091 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.3463 - val_accuracy: 0.9091 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.3472 - val_accuracy: 0.9091 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.3480 - val_accuracy: 0.9091 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.3482 - val_accuracy: 0.9091 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.3494 - val_accuracy: 0.9091 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.3514 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.3527 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.3518 - val_accuracy: 0.9091 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9932 - val_loss: 0.3502 - val_accuracy: 0.9091 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.3506 - val_accuracy: 0.9091 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0158 - accuracy: 0.9949 - val_loss: 0.3509 - val_accuracy: 0.9091 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.3508 - val_accuracy: 0.9091 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.3502 - val_accuracy: 0.9091 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0123 - accuracy: 0.9932 - val_loss: 0.3503 - val_accuracy: 0.9091 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9091 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.3513 - val_accuracy: 0.9091 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.3519 - val_accuracy: 0.9091 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.3528 - val_accuracy: 0.9091 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.3528 - val_accuracy: 0.9091 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.3536 - val_accuracy: 0.9091 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0187 - accuracy: 0.9915 - val_loss: 0.3529 - val_accuracy: 0.9091 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0168 - accuracy: 0.9932 - val_loss: 0.3521 - val_accuracy: 0.9091 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0172 - accuracy: 0.9915 - val_loss: 0.3531 - val_accuracy: 0.9091 - lr: 7.8364e-05\n",
            "66/66 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 13ms/step - loss: 0.8670 - accuracy: 0.9012 - val_loss: 0.5982 - val_accuracy: 0.7727 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.1289 - accuracy: 0.9455 - val_loss: 0.6094 - val_accuracy: 0.7727 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.9710 - val_loss: 0.5888 - val_accuracy: 0.7727 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0718 - accuracy: 0.9693 - val_loss: 0.5411 - val_accuracy: 0.7879 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0595 - accuracy: 0.9847 - val_loss: 0.3931 - val_accuracy: 0.8939 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0292 - accuracy: 0.9881 - val_loss: 0.2524 - val_accuracy: 0.9091 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.2570 - val_accuracy: 0.9242 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.3218 - val_accuracy: 0.9091 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 0.3303 - val_accuracy: 0.9394 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 12ms/step - loss: 0.0153 - accuracy: 0.9932 - val_loss: 0.3931 - val_accuracy: 0.9242 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 0.4037 - val_accuracy: 0.9242 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.0136 - accuracy: 0.9932 - val_loss: 0.4152 - val_accuracy: 0.9394 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 16ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.4489 - val_accuracy: 0.9394 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.0122 - accuracy: 0.9932 - val_loss: 0.4143 - val_accuracy: 0.9242 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.4060 - val_accuracy: 0.9242 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.4357 - val_accuracy: 0.9394 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 0.9949 - val_loss: 0.4602 - val_accuracy: 0.9242 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.4654 - val_accuracy: 0.9242 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.4548 - val_accuracy: 0.9394 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 0.9966 - val_loss: 0.4568 - val_accuracy: 0.9394 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.4604 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0132 - accuracy: 0.9932 - val_loss: 0.4748 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.4759 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 0.9966 - val_loss: 0.4687 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4735 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.4758 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.4766 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0104 - accuracy: 0.9949 - val_loss: 0.4779 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9966 - val_loss: 0.4780 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0100 - accuracy: 0.9949 - val_loss: 0.4796 - val_accuracy: 0.9394 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0098 - accuracy: 0.9966 - val_loss: 0.4788 - val_accuracy: 0.9394 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0128 - accuracy: 0.9915 - val_loss: 0.4774 - val_accuracy: 0.9394 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.4782 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0095 - accuracy: 0.9949 - val_loss: 0.4798 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9949 - val_loss: 0.4778 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.4776 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.4778 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9966 - val_loss: 0.4779 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.4777 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.4781 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.4784 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 0.9983 - val_loss: 0.4778 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4776 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0088 - accuracy: 0.9966 - val_loss: 0.4774 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 0.9983 - val_loss: 0.4773 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.4776 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.4767 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.4781 - val_accuracy: 0.9394 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.4782 - val_accuracy: 0.9394 - lr: 2.8211e-05\n",
            "66/66 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 0.8826 - accuracy: 0.8228 - val_loss: 0.4593 - val_accuracy: 0.9242 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.2772 - accuracy: 0.8825 - val_loss: 0.7313 - val_accuracy: 0.3485 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9455 - val_loss: 0.5598 - val_accuracy: 0.7727 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1247 - accuracy: 0.9540 - val_loss: 0.7455 - val_accuracy: 0.4848 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1132 - accuracy: 0.9574 - val_loss: 0.2589 - val_accuracy: 0.9394 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0859 - accuracy: 0.9727 - val_loss: 0.1935 - val_accuracy: 0.9545 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0721 - accuracy: 0.9744 - val_loss: 0.2034 - val_accuracy: 0.9545 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0666 - accuracy: 0.9744 - val_loss: 0.2330 - val_accuracy: 0.9697 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0588 - accuracy: 0.9830 - val_loss: 0.2454 - val_accuracy: 0.9697 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0405 - accuracy: 0.9881 - val_loss: 0.2603 - val_accuracy: 0.9545 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0316 - accuracy: 0.9915 - val_loss: 0.2889 - val_accuracy: 0.9545 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0280 - accuracy: 0.9932 - val_loss: 0.3068 - val_accuracy: 0.9545 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0367 - accuracy: 0.9830 - val_loss: 0.3301 - val_accuracy: 0.9545 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0302 - accuracy: 0.9932 - val_loss: 0.3273 - val_accuracy: 0.9545 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0338 - accuracy: 0.9864 - val_loss: 0.3017 - val_accuracy: 0.9545 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0305 - accuracy: 0.9881 - val_loss: 0.3048 - val_accuracy: 0.9545 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.3092 - val_accuracy: 0.9697 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0303 - accuracy: 0.9932 - val_loss: 0.3181 - val_accuracy: 0.9545 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0355 - accuracy: 0.9830 - val_loss: 0.3235 - val_accuracy: 0.9545 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0294 - accuracy: 0.9932 - val_loss: 0.3299 - val_accuracy: 0.9394 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0327 - accuracy: 0.9881 - val_loss: 0.3278 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9949 - val_loss: 0.3259 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0194 - accuracy: 0.9949 - val_loss: 0.3345 - val_accuracy: 0.9394 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9881 - val_loss: 0.3408 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0348 - accuracy: 0.9864 - val_loss: 0.3470 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0206 - accuracy: 0.9966 - val_loss: 0.3438 - val_accuracy: 0.9394 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0291 - accuracy: 0.9915 - val_loss: 0.3467 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.3466 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.3493 - val_accuracy: 0.9394 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0201 - accuracy: 0.9966 - val_loss: 0.3500 - val_accuracy: 0.9394 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0207 - accuracy: 0.9949 - val_loss: 0.3522 - val_accuracy: 0.9545 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0273 - accuracy: 0.9881 - val_loss: 0.3514 - val_accuracy: 0.9394 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0358 - accuracy: 0.9881 - val_loss: 0.3523 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9881 - val_loss: 0.3528 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.3529 - val_accuracy: 0.9394 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 0.3533 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0325 - accuracy: 0.9864 - val_loss: 0.3515 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9881 - val_loss: 0.3522 - val_accuracy: 0.9394 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 0.3520 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0284 - accuracy: 0.9932 - val_loss: 0.3516 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.3530 - val_accuracy: 0.9394 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0255 - accuracy: 0.9898 - val_loss: 0.3531 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0318 - accuracy: 0.9881 - val_loss: 0.3535 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.3538 - val_accuracy: 0.9394 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0263 - accuracy: 0.9898 - val_loss: 0.3535 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0203 - accuracy: 0.9949 - val_loss: 0.3535 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.3531 - val_accuracy: 0.9394 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0231 - accuracy: 0.9915 - val_loss: 0.3534 - val_accuracy: 0.9394 - lr: 2.8211e-05\n",
            "66/66 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 1.1171 - accuracy: 0.8724 - val_loss: 0.4136 - val_accuracy: 0.8923 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1548 - accuracy: 0.9320 - val_loss: 0.4567 - val_accuracy: 0.9231 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0885 - accuracy: 0.9609 - val_loss: 0.3821 - val_accuracy: 0.9538 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0581 - accuracy: 0.9779 - val_loss: 0.1890 - val_accuracy: 0.9692 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0624 - accuracy: 0.9796 - val_loss: 0.1410 - val_accuracy: 0.9692 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0354 - accuracy: 0.9864 - val_loss: 0.1113 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.1270 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 0.1546 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.1757 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.1769 - val_accuracy: 0.9538 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9966 - val_loss: 0.2091 - val_accuracy: 0.9538 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.2127 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.2175 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0164 - accuracy: 0.9983 - val_loss: 0.1948 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 8ms/step - loss: 0.0082 - accuracy: 0.9966 - val_loss: 0.2009 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.2126 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0111 - accuracy: 0.9983 - val_loss: 0.2197 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.2235 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0114 - accuracy: 0.9949 - val_loss: 0.2210 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.2239 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 0.9983 - val_loss: 0.2282 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.2281 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.2271 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.2290 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2279 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.2271 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2284 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2283 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0089 - accuracy: 0.9983 - val_loss: 0.2293 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0095 - accuracy: 0.9966 - val_loss: 0.2288 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.2285 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 0.2285 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2288 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0098 - accuracy: 0.9949 - val_loss: 0.2294 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.2289 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.2286 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.2295 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 0.9983 - val_loss: 0.2294 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 0.9284 - accuracy: 0.8690 - val_loss: 0.4879 - val_accuracy: 0.8769 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.1600 - accuracy: 0.9490 - val_loss: 0.4814 - val_accuracy: 0.8769 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1005 - accuracy: 0.9609 - val_loss: 0.4180 - val_accuracy: 0.8769 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0711 - accuracy: 0.9796 - val_loss: 0.2955 - val_accuracy: 0.9231 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0590 - accuracy: 0.9847 - val_loss: 0.1618 - val_accuracy: 0.9692 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0594 - accuracy: 0.9762 - val_loss: 0.0894 - val_accuracy: 0.9846 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0370 - accuracy: 0.9864 - val_loss: 0.0380 - val_accuracy: 0.9846 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0402 - accuracy: 0.9864 - val_loss: 0.0193 - val_accuracy: 0.9846 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0363 - accuracy: 0.9847 - val_loss: 0.0314 - val_accuracy: 0.9846 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0236 - accuracy: 0.9915 - val_loss: 0.0373 - val_accuracy: 0.9846 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 0.0490 - val_accuracy: 0.9846 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0160 - accuracy: 0.9966 - val_loss: 0.0503 - val_accuracy: 0.9846 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.0457 - val_accuracy: 0.9846 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9932 - val_loss: 0.0436 - val_accuracy: 0.9846 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.0461 - val_accuracy: 0.9846 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.9932 - val_loss: 0.0464 - val_accuracy: 0.9846 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0157 - accuracy: 0.9915 - val_loss: 0.0435 - val_accuracy: 0.9846 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9898 - val_loss: 0.0418 - val_accuracy: 0.9846 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0455 - val_accuracy: 0.9846 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.0487 - val_accuracy: 0.9846 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0472 - val_accuracy: 0.9846 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0095 - accuracy: 0.9983 - val_loss: 0.0487 - val_accuracy: 0.9846 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9983 - val_loss: 0.0460 - val_accuracy: 0.9846 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0462 - val_accuracy: 0.9846 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 0.9932 - val_loss: 0.0441 - val_accuracy: 0.9846 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.0414 - val_accuracy: 0.9846 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.0440 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0125 - accuracy: 0.9949 - val_loss: 0.0421 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.0429 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0099 - accuracy: 0.9966 - val_loss: 0.0433 - val_accuracy: 0.9846 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.0435 - val_accuracy: 0.9846 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.0439 - val_accuracy: 0.9846 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0436 - val_accuracy: 0.9846 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9949 - val_loss: 0.0439 - val_accuracy: 0.9846 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.9966 - val_loss: 0.0440 - val_accuracy: 0.9846 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 0.9966 - val_loss: 0.0439 - val_accuracy: 0.9846 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 0.0440 - val_accuracy: 0.9846 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9932 - val_loss: 0.0435 - val_accuracy: 0.9846 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0124 - accuracy: 0.9949 - val_loss: 0.0436 - val_accuracy: 0.9846 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9966 - val_loss: 0.0436 - val_accuracy: 0.9846 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0436 - val_accuracy: 0.9846 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9949 - val_loss: 0.0438 - val_accuracy: 0.9846 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9915 - val_loss: 0.0438 - val_accuracy: 0.9846 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 0.9966 - val_loss: 0.0438 - val_accuracy: 0.9846 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 0.0439 - val_accuracy: 0.9846 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 0.9949 - val_loss: 0.0440 - val_accuracy: 0.9846 - lr: 4.7018e-05\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 0.6295 - accuracy: 0.8401 - val_loss: 0.5943 - val_accuracy: 0.8308 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.2189 - accuracy: 0.9150 - val_loss: 0.5965 - val_accuracy: 0.8308 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.1414 - accuracy: 0.9490 - val_loss: 0.6256 - val_accuracy: 0.8308 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1172 - accuracy: 0.9558 - val_loss: 0.5949 - val_accuracy: 0.8462 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0955 - accuracy: 0.9609 - val_loss: 0.4633 - val_accuracy: 0.9077 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0926 - accuracy: 0.9677 - val_loss: 0.1674 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0654 - accuracy: 0.9660 - val_loss: 0.0904 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0668 - accuracy: 0.9762 - val_loss: 0.1340 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0510 - accuracy: 0.9864 - val_loss: 0.0868 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0539 - accuracy: 0.9796 - val_loss: 0.0795 - val_accuracy: 0.9538 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0390 - accuracy: 0.9847 - val_loss: 0.1033 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 0.1042 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0295 - accuracy: 0.9915 - val_loss: 0.1157 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0318 - accuracy: 0.9847 - val_loss: 0.1228 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9932 - val_loss: 0.1146 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0288 - accuracy: 0.9881 - val_loss: 0.1152 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.1285 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0195 - accuracy: 0.9898 - val_loss: 0.1341 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0274 - accuracy: 0.9898 - val_loss: 0.1260 - val_accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0233 - accuracy: 0.9881 - val_loss: 0.1259 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0292 - accuracy: 0.9915 - val_loss: 0.1259 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0259 - accuracy: 0.9932 - val_loss: 0.1244 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9881 - val_loss: 0.1274 - val_accuracy: 0.9538 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.1297 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 0.9932 - val_loss: 0.1284 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.1254 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 0.1257 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.1281 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.1278 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.1287 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.1294 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9898 - val_loss: 0.1285 - val_accuracy: 0.9538 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0216 - accuracy: 0.9915 - val_loss: 0.1286 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.1287 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9983 - val_loss: 0.1291 - val_accuracy: 0.9538 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0243 - accuracy: 0.9881 - val_loss: 0.1294 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.1294 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.9932 - val_loss: 0.1296 - val_accuracy: 0.9538 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0238 - accuracy: 0.9915 - val_loss: 0.1296 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0192 - accuracy: 0.9932 - val_loss: 0.1299 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0160 - accuracy: 0.9949 - val_loss: 0.1299 - val_accuracy: 0.9538 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0225 - accuracy: 0.9898 - val_loss: 0.1297 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0173 - accuracy: 0.9932 - val_loss: 0.1298 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0208 - accuracy: 0.9915 - val_loss: 0.1297 - val_accuracy: 0.9538 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0212 - accuracy: 0.9915 - val_loss: 0.1297 - val_accuracy: 0.9538 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0243 - accuracy: 0.9881 - val_loss: 0.1298 - val_accuracy: 0.9538 - lr: 4.7018e-05\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 0.8537 - accuracy: 0.8673 - val_loss: 0.5954 - val_accuracy: 0.7385 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1542 - accuracy: 0.9371 - val_loss: 0.5554 - val_accuracy: 0.7385 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1201 - accuracy: 0.9439 - val_loss: 0.5103 - val_accuracy: 0.8308 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0837 - accuracy: 0.9626 - val_loss: 0.4487 - val_accuracy: 0.8769 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0787 - accuracy: 0.9660 - val_loss: 0.3000 - val_accuracy: 0.9077 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9762 - val_loss: 0.1736 - val_accuracy: 0.9231 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.1359 - val_accuracy: 0.9385 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0536 - accuracy: 0.9796 - val_loss: 0.1258 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0371 - accuracy: 0.9847 - val_loss: 0.1152 - val_accuracy: 0.9385 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0342 - accuracy: 0.9864 - val_loss: 0.1251 - val_accuracy: 0.9385 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0390 - accuracy: 0.9847 - val_loss: 0.1140 - val_accuracy: 0.9538 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.1225 - val_accuracy: 0.9692 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.1168 - val_accuracy: 0.9538 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.1328 - val_accuracy: 0.9692 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.1477 - val_accuracy: 0.9692 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0192 - accuracy: 0.9915 - val_loss: 0.1354 - val_accuracy: 0.9385 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9898 - val_loss: 0.1269 - val_accuracy: 0.9538 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 11ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.1302 - val_accuracy: 0.9385 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0268 - accuracy: 0.9898 - val_loss: 0.1295 - val_accuracy: 0.9538 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.1290 - val_accuracy: 0.9385 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.1316 - val_accuracy: 0.9385 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0207 - accuracy: 0.9898 - val_loss: 0.1282 - val_accuracy: 0.9385 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 0.9983 - val_loss: 0.1316 - val_accuracy: 0.9385 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.1319 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0167 - accuracy: 0.9898 - val_loss: 0.1338 - val_accuracy: 0.9385 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0128 - accuracy: 0.9949 - val_loss: 0.1383 - val_accuracy: 0.9538 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0201 - accuracy: 0.9881 - val_loss: 0.1367 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 0.1346 - val_accuracy: 0.9538 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0121 - accuracy: 0.9983 - val_loss: 0.1340 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0134 - accuracy: 0.9949 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0146 - accuracy: 0.9949 - val_loss: 0.1327 - val_accuracy: 0.9385 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9932 - val_loss: 0.1326 - val_accuracy: 0.9385 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0133 - accuracy: 0.9949 - val_loss: 0.1321 - val_accuracy: 0.9385 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 0.1325 - val_accuracy: 0.9385 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.1326 - val_accuracy: 0.9385 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 0.9983 - val_loss: 0.1326 - val_accuracy: 0.9385 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0110 - accuracy: 0.9949 - val_loss: 0.1330 - val_accuracy: 0.9385 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.1333 - val_accuracy: 0.9385 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 15ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.1334 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.0200 - accuracy: 0.9898 - val_loss: 0.1333 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 17ms/step - loss: 0.0168 - accuracy: 0.9915 - val_loss: 0.1334 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 18ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 14ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 0.1338 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9966 - val_loss: 0.1336 - val_accuracy: 0.9385 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0141 - accuracy: 0.9932 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.1336 - val_accuracy: 0.9385 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0148 - accuracy: 0.9915 - val_loss: 0.1337 - val_accuracy: 0.9385 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 0.9949 - val_loss: 0.1336 - val_accuracy: 0.9385 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9932 - val_loss: 0.1336 - val_accuracy: 0.9385 - lr: 1.6927e-05\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 13ms/step - loss: 1.6665 - accuracy: 0.8605 - val_loss: 0.4005 - val_accuracy: 0.8462 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.1983 - accuracy: 0.9371 - val_loss: 0.3258 - val_accuracy: 0.8462 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.1124 - accuracy: 0.9626 - val_loss: 0.2616 - val_accuracy: 0.8769 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0984 - accuracy: 0.9711 - val_loss: 0.1681 - val_accuracy: 0.9231 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0894 - accuracy: 0.9677 - val_loss: 0.1390 - val_accuracy: 0.9385 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0600 - accuracy: 0.9728 - val_loss: 0.1150 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0562 - accuracy: 0.9762 - val_loss: 0.1085 - val_accuracy: 0.9385 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0604 - accuracy: 0.9830 - val_loss: 0.1202 - val_accuracy: 0.9231 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0393 - accuracy: 0.9898 - val_loss: 0.2102 - val_accuracy: 0.9231 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 0.1386 - val_accuracy: 0.9385 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0352 - accuracy: 0.9830 - val_loss: 0.1623 - val_accuracy: 0.9231 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0272 - accuracy: 0.9881 - val_loss: 0.1873 - val_accuracy: 0.9231 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0309 - accuracy: 0.9881 - val_loss: 0.1639 - val_accuracy: 0.9231 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.1688 - val_accuracy: 0.9385 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0286 - accuracy: 0.9881 - val_loss: 0.2264 - val_accuracy: 0.9231 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0286 - accuracy: 0.9864 - val_loss: 0.1806 - val_accuracy: 0.9385 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.2076 - val_accuracy: 0.9231 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.2165 - val_accuracy: 0.9231 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0226 - accuracy: 0.9881 - val_loss: 0.2080 - val_accuracy: 0.9231 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0250 - accuracy: 0.9898 - val_loss: 0.2195 - val_accuracy: 0.9231 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.2085 - val_accuracy: 0.9231 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0219 - accuracy: 0.9898 - val_loss: 0.2054 - val_accuracy: 0.9231 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9915 - val_loss: 0.2172 - val_accuracy: 0.9231 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0249 - accuracy: 0.9915 - val_loss: 0.2007 - val_accuracy: 0.9231 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 0.9949 - val_loss: 0.2111 - val_accuracy: 0.9231 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0177 - accuracy: 0.9915 - val_loss: 0.2072 - val_accuracy: 0.9231 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9915 - val_loss: 0.2040 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 0.9932 - val_loss: 0.2004 - val_accuracy: 0.9231 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9932 - val_loss: 0.1955 - val_accuracy: 0.9385 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9949 - val_loss: 0.1979 - val_accuracy: 0.9385 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 0.9898 - val_loss: 0.2045 - val_accuracy: 0.9231 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0207 - accuracy: 0.9898 - val_loss: 0.2019 - val_accuracy: 0.9231 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0220 - accuracy: 0.9915 - val_loss: 0.2008 - val_accuracy: 0.9231 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.2007 - val_accuracy: 0.9231 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0203 - accuracy: 0.9915 - val_loss: 0.2000 - val_accuracy: 0.9231 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0294 - accuracy: 0.9847 - val_loss: 0.1990 - val_accuracy: 0.9231 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0217 - accuracy: 0.9898 - val_loss: 0.2003 - val_accuracy: 0.9231 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.2018 - val_accuracy: 0.9231 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0230 - accuracy: 0.9915 - val_loss: 0.2006 - val_accuracy: 0.9231 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.2018 - val_accuracy: 0.9231 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.2004 - val_accuracy: 0.9385 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.2009 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0277 - accuracy: 0.9864 - val_loss: 0.2008 - val_accuracy: 0.9385 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0202 - accuracy: 0.9915 - val_loss: 0.2011 - val_accuracy: 0.9231 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0206 - accuracy: 0.9915 - val_loss: 0.2012 - val_accuracy: 0.9231 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 0.2012 - val_accuracy: 0.9231 - lr: 4.7018e-05\n",
            "65/65 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 13ms/step - loss: 1.1751 - accuracy: 0.8588 - val_loss: 0.3532 - val_accuracy: 0.8308 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1922 - accuracy: 0.9116 - val_loss: 0.3213 - val_accuracy: 0.9077 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.1374 - accuracy: 0.9456 - val_loss: 0.2222 - val_accuracy: 0.9538 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1081 - accuracy: 0.9507 - val_loss: 0.1145 - val_accuracy: 0.9846 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0951 - accuracy: 0.9524 - val_loss: 0.0369 - val_accuracy: 1.0000 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0673 - accuracy: 0.9694 - val_loss: 0.0091 - val_accuracy: 1.0000 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0714 - accuracy: 0.9728 - val_loss: 0.0095 - val_accuracy: 1.0000 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0522 - accuracy: 0.9830 - val_loss: 0.0059 - val_accuracy: 1.0000 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0466 - accuracy: 0.9864 - val_loss: 0.0041 - val_accuracy: 1.0000 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0323 - accuracy: 0.9864 - val_loss: 9.5903e-04 - val_accuracy: 1.0000 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9830 - val_loss: 8.4964e-04 - val_accuracy: 1.0000 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0352 - accuracy: 0.9881 - val_loss: 9.9756e-04 - val_accuracy: 1.0000 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.9915 - val_loss: 6.8763e-04 - val_accuracy: 1.0000 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0257 - accuracy: 0.9898 - val_loss: 7.4097e-04 - val_accuracy: 1.0000 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0273 - accuracy: 0.9847 - val_loss: 7.4458e-04 - val_accuracy: 1.0000 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0193 - accuracy: 0.9966 - val_loss: 4.9089e-04 - val_accuracy: 1.0000 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 0.9915 - val_loss: 5.1621e-04 - val_accuracy: 1.0000 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 4.8318e-04 - val_accuracy: 1.0000 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0246 - accuracy: 0.9915 - val_loss: 4.7815e-04 - val_accuracy: 1.0000 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 5.2546e-04 - val_accuracy: 1.0000 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9966 - val_loss: 5.1536e-04 - val_accuracy: 1.0000 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9932 - val_loss: 4.8367e-04 - val_accuracy: 1.0000 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 5.4302e-04 - val_accuracy: 1.0000 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0230 - accuracy: 0.9949 - val_loss: 5.5716e-04 - val_accuracy: 1.0000 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0242 - accuracy: 0.9898 - val_loss: 5.4588e-04 - val_accuracy: 1.0000 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0166 - accuracy: 0.9949 - val_loss: 5.1323e-04 - val_accuracy: 1.0000 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0113 - accuracy: 0.9983 - val_loss: 4.9576e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0235 - accuracy: 0.9915 - val_loss: 4.9531e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9983 - val_loss: 4.8734e-04 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0203 - accuracy: 0.9966 - val_loss: 4.8499e-04 - val_accuracy: 1.0000 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 4.8068e-04 - val_accuracy: 1.0000 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9949 - val_loss: 4.8785e-04 - val_accuracy: 1.0000 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 5.0384e-04 - val_accuracy: 1.0000 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0228 - accuracy: 0.9915 - val_loss: 5.0283e-04 - val_accuracy: 1.0000 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 5.0965e-04 - val_accuracy: 1.0000 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0193 - accuracy: 0.9949 - val_loss: 5.1066e-04 - val_accuracy: 1.0000 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0163 - accuracy: 0.9983 - val_loss: 5.1822e-04 - val_accuracy: 1.0000 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0176 - accuracy: 0.9915 - val_loss: 5.0950e-04 - val_accuracy: 1.0000 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0223 - accuracy: 0.9898 - val_loss: 5.0428e-04 - val_accuracy: 1.0000 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0176 - accuracy: 0.9932 - val_loss: 4.9982e-04 - val_accuracy: 1.0000 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0176 - accuracy: 0.9915 - val_loss: 5.0915e-04 - val_accuracy: 1.0000 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 5.1093e-04 - val_accuracy: 1.0000 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0250 - accuracy: 0.9898 - val_loss: 5.0924e-04 - val_accuracy: 1.0000 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9915 - val_loss: 5.0694e-04 - val_accuracy: 1.0000 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 4.9869e-04 - val_accuracy: 1.0000 - lr: 4.7018e-05\n",
            "65/65 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74/74 [==============================] - 2s 12ms/step - loss: 1.1164 - accuracy: 0.8759 - val_loss: 0.3313 - val_accuracy: 0.8615 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.1361 - accuracy: 0.9524 - val_loss: 0.3515 - val_accuracy: 0.9077 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0902 - accuracy: 0.9609 - val_loss: 0.2833 - val_accuracy: 0.9385 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0720 - accuracy: 0.9677 - val_loss: 0.1863 - val_accuracy: 0.9231 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0534 - accuracy: 0.9762 - val_loss: 0.1458 - val_accuracy: 0.9538 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0448 - accuracy: 0.9830 - val_loss: 0.1299 - val_accuracy: 0.9538 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0328 - accuracy: 0.9847 - val_loss: 0.1461 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0302 - accuracy: 0.9881 - val_loss: 0.1723 - val_accuracy: 0.9692 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0197 - accuracy: 0.9898 - val_loss: 0.1851 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.1634 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0201 - accuracy: 0.9881 - val_loss: 0.2079 - val_accuracy: 0.9692 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0225 - accuracy: 0.9881 - val_loss: 0.1750 - val_accuracy: 0.9692 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9932 - val_loss: 0.1759 - val_accuracy: 0.9846 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0170 - accuracy: 0.9915 - val_loss: 0.1951 - val_accuracy: 0.9692 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.1974 - val_accuracy: 0.9692 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0221 - accuracy: 0.9915 - val_loss: 0.1764 - val_accuracy: 0.9846 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1888 - val_accuracy: 0.9692 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.1918 - val_accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0154 - accuracy: 0.9932 - val_loss: 0.1916 - val_accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9949 - val_loss: 0.1972 - val_accuracy: 0.9692 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0194 - accuracy: 0.9915 - val_loss: 0.1924 - val_accuracy: 0.9692 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0137 - accuracy: 0.9983 - val_loss: 0.1965 - val_accuracy: 0.9692 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.1966 - val_accuracy: 0.9692 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9692 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.1970 - val_accuracy: 0.9692 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9692 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1939 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.1957 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0127 - accuracy: 0.9983 - val_loss: 0.1956 - val_accuracy: 0.9692 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0130 - accuracy: 0.9949 - val_loss: 0.1938 - val_accuracy: 0.9692 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9949 - val_loss: 0.1935 - val_accuracy: 0.9692 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.1939 - val_accuracy: 0.9692 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0096 - accuracy: 0.9966 - val_loss: 0.1930 - val_accuracy: 0.9692 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.1924 - val_accuracy: 0.9692 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0096 - accuracy: 0.9983 - val_loss: 0.1923 - val_accuracy: 0.9692 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1923 - val_accuracy: 0.9692 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0094 - accuracy: 0.9949 - val_loss: 0.1923 - val_accuracy: 0.9692 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.9983 - val_loss: 0.1930 - val_accuracy: 0.9692 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 0.1926 - val_accuracy: 0.9692 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.1926 - val_accuracy: 0.9692 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0107 - accuracy: 0.9983 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0138 - accuracy: 0.9966 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 0.9983 - val_loss: 0.1930 - val_accuracy: 0.9692 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.1933 - val_accuracy: 0.9692 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0122 - accuracy: 0.9966 - val_loss: 0.1929 - val_accuracy: 0.9692 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0128 - accuracy: 0.9932 - val_loss: 0.1929 - val_accuracy: 0.9692 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0128 - accuracy: 0.9966 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.1927 - val_accuracy: 0.9692 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "74/74 [==============================] - 1s 9ms/step - loss: 0.0113 - accuracy: 0.9966 - val_loss: 0.1930 - val_accuracy: 0.9692 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "74/74 [==============================] - 1s 10ms/step - loss: 0.0146 - accuracy: 0.9932 - val_loss: 0.1933 - val_accuracy: 0.9692 - lr: 1.6927e-05\n",
            "65/65 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "ca6b5ab8-2d6c-4bea-d6e1-f4486481fa89"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9679254079254079 ± 0.019494886009330258\n",
            "0.958523953171012 ± 0.032767742316934384\n",
            "0.9424664224664224 ± 0.06297559791341326\n",
            "0.9745814838756015 ± 0.017720334904160737\n",
            "0.8750757926127642 ± 0.07510612759780215\n",
            "0.9678133419625546 ± 0.04491376065460708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACC_collecton"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "397sLYBohyh7",
        "outputId": "7cca9c4f-0da1-4f80-9bf3-b7da2713807b"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9815950920245399]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dcc2b0-5c95-482d-c612-5111b15a1e27"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/82 [==============================] - 2s 12ms/step - loss: 1.2458 - accuracy: 0.8836 - val_loss: 0.5401 - val_accuracy: 0.8282 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.1424 - accuracy: 0.9372 - val_loss: 0.4789 - val_accuracy: 0.8528 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0968 - accuracy: 0.9648 - val_loss: 0.3865 - val_accuracy: 0.8896 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0843 - accuracy: 0.9709 - val_loss: 0.1568 - val_accuracy: 0.9693 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0752 - accuracy: 0.9724 - val_loss: 0.1065 - val_accuracy: 0.9632 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0637 - accuracy: 0.9786 - val_loss: 0.0781 - val_accuracy: 0.9693 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0643 - accuracy: 0.9770 - val_loss: 0.0959 - val_accuracy: 0.9693 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0506 - accuracy: 0.9801 - val_loss: 0.0962 - val_accuracy: 0.9755 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0387 - accuracy: 0.9893 - val_loss: 0.1151 - val_accuracy: 0.9693 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0398 - accuracy: 0.9862 - val_loss: 0.1013 - val_accuracy: 0.9755 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0345 - accuracy: 0.9877 - val_loss: 0.1109 - val_accuracy: 0.9755 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.1138 - val_accuracy: 0.9693 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 0.1186 - val_accuracy: 0.9693 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.1139 - val_accuracy: 0.9693 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.1139 - val_accuracy: 0.9693 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 0.1110 - val_accuracy: 0.9755 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.1074 - val_accuracy: 0.9755 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0234 - accuracy: 0.9877 - val_loss: 0.1061 - val_accuracy: 0.9755 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 0.9893 - val_loss: 0.1122 - val_accuracy: 0.9755 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.1099 - val_accuracy: 0.9755 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.1076 - val_accuracy: 0.9755 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 0.1113 - val_accuracy: 0.9755 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9969 - val_loss: 0.1125 - val_accuracy: 0.9755 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.1125 - val_accuracy: 0.9755 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0157 - accuracy: 0.9969 - val_loss: 0.1122 - val_accuracy: 0.9755 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0251 - accuracy: 0.9923 - val_loss: 0.1136 - val_accuracy: 0.9755 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0186 - accuracy: 0.9923 - val_loss: 0.1139 - val_accuracy: 0.9755 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.1140 - val_accuracy: 0.9755 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0228 - accuracy: 0.9908 - val_loss: 0.1147 - val_accuracy: 0.9755 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 0.1150 - val_accuracy: 0.9755 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0195 - accuracy: 0.9923 - val_loss: 0.1144 - val_accuracy: 0.9755 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.1152 - val_accuracy: 0.9755 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.1148 - val_accuracy: 0.9755 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.1149 - val_accuracy: 0.9755 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9755 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 0.9908 - val_loss: 0.1150 - val_accuracy: 0.9755 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.1151 - val_accuracy: 0.9755 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0137 - accuracy: 0.9985 - val_loss: 0.1149 - val_accuracy: 0.9755 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0208 - accuracy: 0.9954 - val_loss: 0.1150 - val_accuracy: 0.9755 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.1150 - val_accuracy: 0.9755 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9908 - val_loss: 0.1150 - val_accuracy: 0.9755 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.1152 - val_accuracy: 0.9755 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.1152 - val_accuracy: 0.9755 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 0.1155 - val_accuracy: 0.9755 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0162 - accuracy: 0.9985 - val_loss: 0.1156 - val_accuracy: 0.9755 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0211 - accuracy: 0.9908 - val_loss: 0.1157 - val_accuracy: 0.9755 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "82/82 [==============================] - 1s 10ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.1155 - val_accuracy: 0.9755 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "82/82 [==============================] - 1s 9ms/step - loss: 0.0237 - accuracy: 0.9908 - val_loss: 0.1156 - val_accuracy: 0.9755 - lr: 2.8211e-05\n",
            "163/163 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433577a1-b6a9-427d-dcbe-529409067832"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9754601226993865\n",
            "0.9698203256597417\n",
            "0.9615384615384616\n",
            "0.9781021897810219\n",
            "0.9121428430507218\n",
            "0.987037037037037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('AMAP_alternative_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/AMAP_alternative_tensorflow_model.zip /content/AMAP_alternative_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "ae3dcee0-0964-4333-ac2e-e61ce01ed7ad"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/AMAP_alternative_tensorflow_model/ (stored 0%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/variables/variables.index (deflated 63%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 46%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/AMAP_alternative_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    }
  ]
}