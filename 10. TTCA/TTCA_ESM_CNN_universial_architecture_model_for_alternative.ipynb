{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c386d1-5062-4735-a4f6-9278b0b73edf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 996 kB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('TTCA_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('TTCA_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label'] \n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('TTCA_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('TTCA_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'TTCA_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'TTCA_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "94275252-2981-4b44-8dd9-cf20e18cff47"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(788, 320)\n",
            "(197, 320)\n",
            "(788,)\n",
            "(197,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d62997c5-4c07-467f-f921-5593fefa70fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "89/89 [==============================] - 2s 12ms/step - loss: 1.1575 - accuracy: 0.5853 - val_loss: 0.6937 - val_accuracy: 0.5570 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6668 - accuracy: 0.6121 - val_loss: 0.7071 - val_accuracy: 0.5570 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6443 - accuracy: 0.6432 - val_loss: 0.6868 - val_accuracy: 0.5823 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6297 - accuracy: 0.6827 - val_loss: 0.6905 - val_accuracy: 0.5696 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 14ms/step - loss: 0.6182 - accuracy: 0.6756 - val_loss: 0.6475 - val_accuracy: 0.6076 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 2s 18ms/step - loss: 0.5747 - accuracy: 0.7080 - val_loss: 0.6222 - val_accuracy: 0.6582 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 2s 18ms/step - loss: 0.5507 - accuracy: 0.7320 - val_loss: 0.6113 - val_accuracy: 0.6582 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.5174 - accuracy: 0.7602 - val_loss: 0.6154 - val_accuracy: 0.6709 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.5000 - accuracy: 0.7630 - val_loss: 0.6297 - val_accuracy: 0.6709 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.4874 - accuracy: 0.7814 - val_loss: 0.6484 - val_accuracy: 0.6582 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 2s 18ms/step - loss: 0.4509 - accuracy: 0.8011 - val_loss: 0.6311 - val_accuracy: 0.6962 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 13ms/step - loss: 0.4415 - accuracy: 0.8096 - val_loss: 0.6200 - val_accuracy: 0.6962 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 14ms/step - loss: 0.4294 - accuracy: 0.8110 - val_loss: 0.6067 - val_accuracy: 0.6962 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4121 - accuracy: 0.8307 - val_loss: 0.6163 - val_accuracy: 0.7215 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3958 - accuracy: 0.8420 - val_loss: 0.6401 - val_accuracy: 0.6835 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3913 - accuracy: 0.8392 - val_loss: 0.6390 - val_accuracy: 0.6709 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4005 - accuracy: 0.8293 - val_loss: 0.6216 - val_accuracy: 0.6835 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3693 - accuracy: 0.8406 - val_loss: 0.6361 - val_accuracy: 0.6835 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3436 - accuracy: 0.8688 - val_loss: 0.6442 - val_accuracy: 0.6582 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.3395 - accuracy: 0.8590 - val_loss: 0.6542 - val_accuracy: 0.6709 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3610 - accuracy: 0.8463 - val_loss: 0.6494 - val_accuracy: 0.6835 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3437 - accuracy: 0.8505 - val_loss: 0.6519 - val_accuracy: 0.6962 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3452 - accuracy: 0.8575 - val_loss: 0.6393 - val_accuracy: 0.6962 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3419 - accuracy: 0.8660 - val_loss: 0.6439 - val_accuracy: 0.6835 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3193 - accuracy: 0.8688 - val_loss: 0.6525 - val_accuracy: 0.6835 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3235 - accuracy: 0.8759 - val_loss: 0.6511 - val_accuracy: 0.6835 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3265 - accuracy: 0.8787 - val_loss: 0.6546 - val_accuracy: 0.6835 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3397 - accuracy: 0.8674 - val_loss: 0.6594 - val_accuracy: 0.6835 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3146 - accuracy: 0.8717 - val_loss: 0.6523 - val_accuracy: 0.6962 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3317 - accuracy: 0.8618 - val_loss: 0.6517 - val_accuracy: 0.6962 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3371 - accuracy: 0.8590 - val_loss: 0.6545 - val_accuracy: 0.6962 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3379 - accuracy: 0.8618 - val_loss: 0.6595 - val_accuracy: 0.6835 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3135 - accuracy: 0.8731 - val_loss: 0.6612 - val_accuracy: 0.6835 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.8787 - val_loss: 0.6627 - val_accuracy: 0.6835 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.8505 - val_loss: 0.6605 - val_accuracy: 0.6835 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3234 - accuracy: 0.8759 - val_loss: 0.6602 - val_accuracy: 0.6835 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3264 - accuracy: 0.8646 - val_loss: 0.6599 - val_accuracy: 0.6835 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3279 - accuracy: 0.8688 - val_loss: 0.6608 - val_accuracy: 0.6835 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3182 - accuracy: 0.8717 - val_loss: 0.6616 - val_accuracy: 0.6835 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3189 - accuracy: 0.8801 - val_loss: 0.6611 - val_accuracy: 0.6835 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3139 - accuracy: 0.8674 - val_loss: 0.6614 - val_accuracy: 0.6835 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3170 - accuracy: 0.8759 - val_loss: 0.6611 - val_accuracy: 0.6835 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 13ms/step - loss: 0.3026 - accuracy: 0.8787 - val_loss: 0.6621 - val_accuracy: 0.6835 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3436 - accuracy: 0.8632 - val_loss: 0.6621 - val_accuracy: 0.6835 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3054 - accuracy: 0.8787 - val_loss: 0.6627 - val_accuracy: 0.6835 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3227 - accuracy: 0.8674 - val_loss: 0.6627 - val_accuracy: 0.6835 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3253 - accuracy: 0.8618 - val_loss: 0.6629 - val_accuracy: 0.6835 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3224 - accuracy: 0.8759 - val_loss: 0.6625 - val_accuracy: 0.6835 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3189 - accuracy: 0.8702 - val_loss: 0.6622 - val_accuracy: 0.6835 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3498 - accuracy: 0.8491 - val_loss: 0.6624 - val_accuracy: 0.6835 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3067 - accuracy: 0.8829 - val_loss: 0.6622 - val_accuracy: 0.6835 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3297 - accuracy: 0.8632 - val_loss: 0.6621 - val_accuracy: 0.6835 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3197 - accuracy: 0.8674 - val_loss: 0.6625 - val_accuracy: 0.6835 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3140 - accuracy: 0.8688 - val_loss: 0.6623 - val_accuracy: 0.6835 - lr: 1.0156e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 1.4166 - accuracy: 0.5952 - val_loss: 0.7043 - val_accuracy: 0.4937 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6626 - accuracy: 0.6192 - val_loss: 0.7214 - val_accuracy: 0.4937 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6314 - accuracy: 0.6474 - val_loss: 0.7065 - val_accuracy: 0.5316 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6119 - accuracy: 0.6601 - val_loss: 0.6638 - val_accuracy: 0.5823 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5798 - accuracy: 0.6812 - val_loss: 0.6671 - val_accuracy: 0.6076 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5524 - accuracy: 0.7193 - val_loss: 0.6187 - val_accuracy: 0.6582 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5355 - accuracy: 0.7137 - val_loss: 0.6447 - val_accuracy: 0.6456 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5272 - accuracy: 0.7306 - val_loss: 0.7319 - val_accuracy: 0.6203 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4795 - accuracy: 0.7630 - val_loss: 0.6985 - val_accuracy: 0.6582 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4762 - accuracy: 0.7546 - val_loss: 0.6454 - val_accuracy: 0.6709 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4596 - accuracy: 0.7602 - val_loss: 0.6408 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4397 - accuracy: 0.7814 - val_loss: 0.7333 - val_accuracy: 0.6709 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4277 - accuracy: 0.8054 - val_loss: 0.7039 - val_accuracy: 0.6456 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4181 - accuracy: 0.7997 - val_loss: 0.7663 - val_accuracy: 0.6709 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4104 - accuracy: 0.7983 - val_loss: 0.6892 - val_accuracy: 0.6203 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3923 - accuracy: 0.8082 - val_loss: 0.6486 - val_accuracy: 0.6329 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.3807 - accuracy: 0.8181 - val_loss: 0.6914 - val_accuracy: 0.6456 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3776 - accuracy: 0.8166 - val_loss: 0.6705 - val_accuracy: 0.6329 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3775 - accuracy: 0.8322 - val_loss: 0.7324 - val_accuracy: 0.6456 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3554 - accuracy: 0.8533 - val_loss: 0.7292 - val_accuracy: 0.6582 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3630 - accuracy: 0.8392 - val_loss: 0.7428 - val_accuracy: 0.6582 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3617 - accuracy: 0.8279 - val_loss: 0.6822 - val_accuracy: 0.6203 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3622 - accuracy: 0.8293 - val_loss: 0.6829 - val_accuracy: 0.6076 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3533 - accuracy: 0.8364 - val_loss: 0.6793 - val_accuracy: 0.6076 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3533 - accuracy: 0.8350 - val_loss: 0.7031 - val_accuracy: 0.6329 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3453 - accuracy: 0.8364 - val_loss: 0.6861 - val_accuracy: 0.6329 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3432 - accuracy: 0.8519 - val_loss: 0.7351 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3471 - accuracy: 0.8434 - val_loss: 0.7132 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3338 - accuracy: 0.8434 - val_loss: 0.7091 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.3481 - accuracy: 0.8449 - val_loss: 0.7092 - val_accuracy: 0.6329 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.3292 - accuracy: 0.8420 - val_loss: 0.7277 - val_accuracy: 0.6329 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3247 - accuracy: 0.8604 - val_loss: 0.7206 - val_accuracy: 0.6076 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.8505 - val_loss: 0.7244 - val_accuracy: 0.6329 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3321 - accuracy: 0.8533 - val_loss: 0.7221 - val_accuracy: 0.6203 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3294 - accuracy: 0.8646 - val_loss: 0.7275 - val_accuracy: 0.6329 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 15ms/step - loss: 0.3280 - accuracy: 0.8604 - val_loss: 0.7259 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 14ms/step - loss: 0.3241 - accuracy: 0.8505 - val_loss: 0.7238 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 2s 20ms/step - loss: 0.3399 - accuracy: 0.8420 - val_loss: 0.7196 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.3482 - accuracy: 0.8378 - val_loss: 0.7216 - val_accuracy: 0.6329 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 15ms/step - loss: 0.3399 - accuracy: 0.8279 - val_loss: 0.7278 - val_accuracy: 0.6329 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3335 - accuracy: 0.8420 - val_loss: 0.7270 - val_accuracy: 0.6329 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3274 - accuracy: 0.8604 - val_loss: 0.7275 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3177 - accuracy: 0.8717 - val_loss: 0.7297 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 14ms/step - loss: 0.3439 - accuracy: 0.8350 - val_loss: 0.7283 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 13ms/step - loss: 0.3621 - accuracy: 0.8237 - val_loss: 0.7253 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.3299 - accuracy: 0.8505 - val_loss: 0.7261 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 15ms/step - loss: 0.3315 - accuracy: 0.8561 - val_loss: 0.7280 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3403 - accuracy: 0.8505 - val_loss: 0.7277 - val_accuracy: 0.6329 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3446 - accuracy: 0.8378 - val_loss: 0.7258 - val_accuracy: 0.6329 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3261 - accuracy: 0.8519 - val_loss: 0.7257 - val_accuracy: 0.6329 - lr: 2.8211e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 12ms/step - loss: 1.0065 - accuracy: 0.5839 - val_loss: 0.6756 - val_accuracy: 0.5949 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6771 - accuracy: 0.5839 - val_loss: 0.6701 - val_accuracy: 0.5949 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6669 - accuracy: 0.6121 - val_loss: 0.6769 - val_accuracy: 0.5949 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6542 - accuracy: 0.6333 - val_loss: 0.6738 - val_accuracy: 0.6076 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6412 - accuracy: 0.6474 - val_loss: 0.6543 - val_accuracy: 0.6203 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6314 - accuracy: 0.6615 - val_loss: 0.6373 - val_accuracy: 0.6709 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6026 - accuracy: 0.6827 - val_loss: 0.6141 - val_accuracy: 0.6962 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5930 - accuracy: 0.6996 - val_loss: 0.6392 - val_accuracy: 0.6456 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5841 - accuracy: 0.6939 - val_loss: 0.6519 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5815 - accuracy: 0.6968 - val_loss: 0.6324 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5586 - accuracy: 0.7123 - val_loss: 0.6466 - val_accuracy: 0.6203 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5600 - accuracy: 0.7151 - val_loss: 0.5962 - val_accuracy: 0.6709 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5384 - accuracy: 0.7292 - val_loss: 0.6086 - val_accuracy: 0.6456 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5417 - accuracy: 0.7137 - val_loss: 0.6039 - val_accuracy: 0.6582 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5219 - accuracy: 0.7278 - val_loss: 0.6221 - val_accuracy: 0.6203 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5051 - accuracy: 0.7391 - val_loss: 0.6002 - val_accuracy: 0.6835 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5123 - accuracy: 0.7306 - val_loss: 0.6246 - val_accuracy: 0.6456 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4960 - accuracy: 0.7362 - val_loss: 0.6201 - val_accuracy: 0.6456 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4856 - accuracy: 0.7377 - val_loss: 0.6239 - val_accuracy: 0.6076 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4922 - accuracy: 0.7306 - val_loss: 0.6615 - val_accuracy: 0.6203 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4789 - accuracy: 0.7518 - val_loss: 0.6253 - val_accuracy: 0.6329 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4706 - accuracy: 0.7504 - val_loss: 0.6166 - val_accuracy: 0.6582 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4887 - accuracy: 0.7377 - val_loss: 0.6648 - val_accuracy: 0.6076 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4682 - accuracy: 0.7391 - val_loss: 0.6293 - val_accuracy: 0.6329 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4723 - accuracy: 0.7348 - val_loss: 0.6631 - val_accuracy: 0.6203 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4699 - accuracy: 0.7475 - val_loss: 0.6307 - val_accuracy: 0.6456 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4526 - accuracy: 0.7560 - val_loss: 0.6450 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4776 - accuracy: 0.7292 - val_loss: 0.6264 - val_accuracy: 0.6203 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4563 - accuracy: 0.7461 - val_loss: 0.6356 - val_accuracy: 0.6203 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4581 - accuracy: 0.7461 - val_loss: 0.6514 - val_accuracy: 0.6329 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4492 - accuracy: 0.7405 - val_loss: 0.6426 - val_accuracy: 0.6076 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4566 - accuracy: 0.7546 - val_loss: 0.6469 - val_accuracy: 0.6203 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4657 - accuracy: 0.7405 - val_loss: 0.6357 - val_accuracy: 0.6329 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4565 - accuracy: 0.7518 - val_loss: 0.6367 - val_accuracy: 0.6329 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4313 - accuracy: 0.7645 - val_loss: 0.6486 - val_accuracy: 0.6329 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4516 - accuracy: 0.7504 - val_loss: 0.6407 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4549 - accuracy: 0.7461 - val_loss: 0.6331 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4523 - accuracy: 0.7489 - val_loss: 0.6409 - val_accuracy: 0.6329 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4407 - accuracy: 0.7560 - val_loss: 0.6486 - val_accuracy: 0.6329 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4488 - accuracy: 0.7518 - val_loss: 0.6487 - val_accuracy: 0.6203 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4482 - accuracy: 0.7546 - val_loss: 0.6496 - val_accuracy: 0.6203 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4370 - accuracy: 0.7574 - val_loss: 0.6506 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4466 - accuracy: 0.7574 - val_loss: 0.6476 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4466 - accuracy: 0.7588 - val_loss: 0.6484 - val_accuracy: 0.6329 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.4395 - accuracy: 0.7475 - val_loss: 0.6479 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4422 - accuracy: 0.7560 - val_loss: 0.6475 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4503 - accuracy: 0.7419 - val_loss: 0.6480 - val_accuracy: 0.6329 - lr: 4.7018e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 2.4875 - accuracy: 0.5797 - val_loss: 0.7012 - val_accuracy: 0.5443 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.6546 - accuracy: 0.6234 - val_loss: 0.6819 - val_accuracy: 0.5696 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6171 - accuracy: 0.6615 - val_loss: 0.6454 - val_accuracy: 0.6456 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5684 - accuracy: 0.7080 - val_loss: 0.6020 - val_accuracy: 0.6456 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.5619 - accuracy: 0.7010 - val_loss: 0.6281 - val_accuracy: 0.6329 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5118 - accuracy: 0.7433 - val_loss: 0.6185 - val_accuracy: 0.6709 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5120 - accuracy: 0.7433 - val_loss: 0.6332 - val_accuracy: 0.6203 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4876 - accuracy: 0.7489 - val_loss: 0.6667 - val_accuracy: 0.6329 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4564 - accuracy: 0.7814 - val_loss: 0.6492 - val_accuracy: 0.6582 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4363 - accuracy: 0.7927 - val_loss: 0.6684 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4310 - accuracy: 0.7983 - val_loss: 0.6864 - val_accuracy: 0.6076 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4033 - accuracy: 0.8138 - val_loss: 0.6358 - val_accuracy: 0.6709 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4010 - accuracy: 0.8181 - val_loss: 0.6584 - val_accuracy: 0.6329 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3807 - accuracy: 0.8350 - val_loss: 0.6749 - val_accuracy: 0.6456 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3702 - accuracy: 0.8449 - val_loss: 0.6542 - val_accuracy: 0.6456 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3660 - accuracy: 0.8364 - val_loss: 0.6661 - val_accuracy: 0.6582 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3597 - accuracy: 0.8350 - val_loss: 0.6989 - val_accuracy: 0.6456 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3668 - accuracy: 0.8223 - val_loss: 0.7123 - val_accuracy: 0.6203 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3644 - accuracy: 0.8265 - val_loss: 0.7041 - val_accuracy: 0.6456 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3353 - accuracy: 0.8505 - val_loss: 0.7057 - val_accuracy: 0.6582 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3405 - accuracy: 0.8533 - val_loss: 0.7262 - val_accuracy: 0.6329 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3348 - accuracy: 0.8420 - val_loss: 0.6952 - val_accuracy: 0.6456 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3290 - accuracy: 0.8392 - val_loss: 0.7148 - val_accuracy: 0.6582 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3381 - accuracy: 0.8477 - val_loss: 0.7104 - val_accuracy: 0.6582 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3106 - accuracy: 0.8604 - val_loss: 0.7121 - val_accuracy: 0.6456 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3267 - accuracy: 0.8688 - val_loss: 0.7205 - val_accuracy: 0.6456 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3143 - accuracy: 0.8632 - val_loss: 0.7158 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3145 - accuracy: 0.8604 - val_loss: 0.7258 - val_accuracy: 0.6456 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3090 - accuracy: 0.8674 - val_loss: 0.7298 - val_accuracy: 0.6329 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3176 - accuracy: 0.8773 - val_loss: 0.7297 - val_accuracy: 0.6456 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3258 - accuracy: 0.8618 - val_loss: 0.7285 - val_accuracy: 0.6582 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2921 - accuracy: 0.8688 - val_loss: 0.7362 - val_accuracy: 0.6456 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3137 - accuracy: 0.8533 - val_loss: 0.7328 - val_accuracy: 0.6456 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.2989 - accuracy: 0.8702 - val_loss: 0.7365 - val_accuracy: 0.6456 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2988 - accuracy: 0.8688 - val_loss: 0.7373 - val_accuracy: 0.6582 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3174 - accuracy: 0.8575 - val_loss: 0.7390 - val_accuracy: 0.6456 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3014 - accuracy: 0.8717 - val_loss: 0.7387 - val_accuracy: 0.6456 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3134 - accuracy: 0.8632 - val_loss: 0.7377 - val_accuracy: 0.6456 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3068 - accuracy: 0.8688 - val_loss: 0.7373 - val_accuracy: 0.6582 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3173 - accuracy: 0.8717 - val_loss: 0.7393 - val_accuracy: 0.6582 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3200 - accuracy: 0.8632 - val_loss: 0.7386 - val_accuracy: 0.6582 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3095 - accuracy: 0.8674 - val_loss: 0.7385 - val_accuracy: 0.6582 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2971 - accuracy: 0.8745 - val_loss: 0.7396 - val_accuracy: 0.6582 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3003 - accuracy: 0.8801 - val_loss: 0.7401 - val_accuracy: 0.6582 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3059 - accuracy: 0.8717 - val_loss: 0.7392 - val_accuracy: 0.6582 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2959 - accuracy: 0.8745 - val_loss: 0.7401 - val_accuracy: 0.6582 - lr: 4.7018e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 12ms/step - loss: 1.2121 - accuracy: 0.5882 - val_loss: 0.6750 - val_accuracy: 0.5949 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6722 - accuracy: 0.6135 - val_loss: 0.6762 - val_accuracy: 0.5949 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6378 - accuracy: 0.6516 - val_loss: 0.6644 - val_accuracy: 0.5949 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6279 - accuracy: 0.6460 - val_loss: 0.6745 - val_accuracy: 0.6076 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6111 - accuracy: 0.6671 - val_loss: 0.5828 - val_accuracy: 0.7089 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5768 - accuracy: 0.7038 - val_loss: 0.5715 - val_accuracy: 0.7089 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5684 - accuracy: 0.7123 - val_loss: 0.5756 - val_accuracy: 0.7089 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5458 - accuracy: 0.7362 - val_loss: 0.5472 - val_accuracy: 0.7215 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5025 - accuracy: 0.7518 - val_loss: 0.5199 - val_accuracy: 0.7215 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4938 - accuracy: 0.7645 - val_loss: 0.5776 - val_accuracy: 0.6456 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.7913 - val_loss: 0.5638 - val_accuracy: 0.6962 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4370 - accuracy: 0.7856 - val_loss: 0.5148 - val_accuracy: 0.7342 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4232 - accuracy: 0.7983 - val_loss: 0.4962 - val_accuracy: 0.7595 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4221 - accuracy: 0.8096 - val_loss: 0.4924 - val_accuracy: 0.7848 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4058 - accuracy: 0.8082 - val_loss: 0.5044 - val_accuracy: 0.7595 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3841 - accuracy: 0.8293 - val_loss: 0.5115 - val_accuracy: 0.7342 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3930 - accuracy: 0.8237 - val_loss: 0.5199 - val_accuracy: 0.7848 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3757 - accuracy: 0.8463 - val_loss: 0.5131 - val_accuracy: 0.7722 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3636 - accuracy: 0.8406 - val_loss: 0.5292 - val_accuracy: 0.7215 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3615 - accuracy: 0.8322 - val_loss: 0.5189 - val_accuracy: 0.7595 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3443 - accuracy: 0.8491 - val_loss: 0.5288 - val_accuracy: 0.7595 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3399 - accuracy: 0.8561 - val_loss: 0.5296 - val_accuracy: 0.7595 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3441 - accuracy: 0.8533 - val_loss: 0.5153 - val_accuracy: 0.7848 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3354 - accuracy: 0.8646 - val_loss: 0.5259 - val_accuracy: 0.7468 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3220 - accuracy: 0.8604 - val_loss: 0.5322 - val_accuracy: 0.7722 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3364 - accuracy: 0.8660 - val_loss: 0.5235 - val_accuracy: 0.7722 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.8773 - val_loss: 0.5309 - val_accuracy: 0.7595 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3123 - accuracy: 0.8674 - val_loss: 0.5358 - val_accuracy: 0.7595 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3123 - accuracy: 0.8604 - val_loss: 0.5393 - val_accuracy: 0.7468 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3076 - accuracy: 0.8773 - val_loss: 0.5353 - val_accuracy: 0.7595 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3275 - accuracy: 0.8660 - val_loss: 0.5403 - val_accuracy: 0.7468 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3157 - accuracy: 0.8688 - val_loss: 0.5329 - val_accuracy: 0.7595 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.8660 - val_loss: 0.5388 - val_accuracy: 0.7468 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3084 - accuracy: 0.8787 - val_loss: 0.5393 - val_accuracy: 0.7342 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3176 - accuracy: 0.8731 - val_loss: 0.5387 - val_accuracy: 0.7468 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2958 - accuracy: 0.8999 - val_loss: 0.5430 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3342 - accuracy: 0.8632 - val_loss: 0.5429 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3103 - accuracy: 0.8745 - val_loss: 0.5423 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3359 - accuracy: 0.8575 - val_loss: 0.5408 - val_accuracy: 0.7468 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3084 - accuracy: 0.8858 - val_loss: 0.5440 - val_accuracy: 0.7342 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3092 - accuracy: 0.8843 - val_loss: 0.5443 - val_accuracy: 0.7342 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3084 - accuracy: 0.8843 - val_loss: 0.5463 - val_accuracy: 0.7342 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3220 - accuracy: 0.8688 - val_loss: 0.5465 - val_accuracy: 0.7342 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3122 - accuracy: 0.8646 - val_loss: 0.5465 - val_accuracy: 0.7342 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3310 - accuracy: 0.8590 - val_loss: 0.5462 - val_accuracy: 0.7342 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3206 - accuracy: 0.8660 - val_loss: 0.5460 - val_accuracy: 0.7342 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3046 - accuracy: 0.8745 - val_loss: 0.5460 - val_accuracy: 0.7342 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3095 - accuracy: 0.8702 - val_loss: 0.5464 - val_accuracy: 0.7342 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3158 - accuracy: 0.8731 - val_loss: 0.5460 - val_accuracy: 0.7342 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3039 - accuracy: 0.8787 - val_loss: 0.5459 - val_accuracy: 0.7342 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3067 - accuracy: 0.8829 - val_loss: 0.5456 - val_accuracy: 0.7342 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3250 - accuracy: 0.8717 - val_loss: 0.5459 - val_accuracy: 0.7342 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3265 - accuracy: 0.8632 - val_loss: 0.5461 - val_accuracy: 0.7342 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.3321 - accuracy: 0.8604 - val_loss: 0.5461 - val_accuracy: 0.7342 - lr: 1.0156e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 1.5041 - accuracy: 0.5839 - val_loss: 0.6958 - val_accuracy: 0.5316 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6571 - accuracy: 0.6220 - val_loss: 0.7038 - val_accuracy: 0.5316 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6239 - accuracy: 0.6615 - val_loss: 0.6931 - val_accuracy: 0.5443 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.6040 - accuracy: 0.6728 - val_loss: 0.6769 - val_accuracy: 0.5823 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.5817 - accuracy: 0.7024 - val_loss: 0.6766 - val_accuracy: 0.5696 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5399 - accuracy: 0.7320 - val_loss: 0.6954 - val_accuracy: 0.6076 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5245 - accuracy: 0.7165 - val_loss: 0.7142 - val_accuracy: 0.6203 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5268 - accuracy: 0.7377 - val_loss: 0.7402 - val_accuracy: 0.6329 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4970 - accuracy: 0.7715 - val_loss: 0.6619 - val_accuracy: 0.6076 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4845 - accuracy: 0.7659 - val_loss: 0.6774 - val_accuracy: 0.5949 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4669 - accuracy: 0.7687 - val_loss: 0.7217 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4415 - accuracy: 0.8039 - val_loss: 0.7744 - val_accuracy: 0.5949 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 8ms/step - loss: 0.4391 - accuracy: 0.7941 - val_loss: 0.7161 - val_accuracy: 0.6835 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4253 - accuracy: 0.7814 - val_loss: 0.6992 - val_accuracy: 0.6456 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4187 - accuracy: 0.8011 - val_loss: 0.7346 - val_accuracy: 0.6329 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4137 - accuracy: 0.8025 - val_loss: 0.7253 - val_accuracy: 0.6835 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4107 - accuracy: 0.7997 - val_loss: 0.7119 - val_accuracy: 0.6582 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3921 - accuracy: 0.8166 - val_loss: 0.7479 - val_accuracy: 0.6835 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4049 - accuracy: 0.7927 - val_loss: 0.7370 - val_accuracy: 0.6582 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3837 - accuracy: 0.8223 - val_loss: 0.7328 - val_accuracy: 0.6709 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.8265 - val_loss: 0.7247 - val_accuracy: 0.6709 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3937 - accuracy: 0.8124 - val_loss: 0.7213 - val_accuracy: 0.6582 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3889 - accuracy: 0.8209 - val_loss: 0.7220 - val_accuracy: 0.6835 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3620 - accuracy: 0.8138 - val_loss: 0.7375 - val_accuracy: 0.6835 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3776 - accuracy: 0.8181 - val_loss: 0.7275 - val_accuracy: 0.6709 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3553 - accuracy: 0.8307 - val_loss: 0.7255 - val_accuracy: 0.6709 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3646 - accuracy: 0.8279 - val_loss: 0.7344 - val_accuracy: 0.6709 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 0.3625 - accuracy: 0.8420 - val_loss: 0.7502 - val_accuracy: 0.6456 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 2s 20ms/step - loss: 0.3652 - accuracy: 0.8209 - val_loss: 0.7376 - val_accuracy: 0.6709 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 16ms/step - loss: 0.3598 - accuracy: 0.8110 - val_loss: 0.7474 - val_accuracy: 0.6709 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 15ms/step - loss: 0.3503 - accuracy: 0.8378 - val_loss: 0.7469 - val_accuracy: 0.6709 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3631 - accuracy: 0.8293 - val_loss: 0.7504 - val_accuracy: 0.6582 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3702 - accuracy: 0.8293 - val_loss: 0.7480 - val_accuracy: 0.6709 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3615 - accuracy: 0.8364 - val_loss: 0.7438 - val_accuracy: 0.6582 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3526 - accuracy: 0.8307 - val_loss: 0.7456 - val_accuracy: 0.6582 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3581 - accuracy: 0.8251 - val_loss: 0.7475 - val_accuracy: 0.6582 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3632 - accuracy: 0.8195 - val_loss: 0.7476 - val_accuracy: 0.6582 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3698 - accuracy: 0.8181 - val_loss: 0.7455 - val_accuracy: 0.6709 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3534 - accuracy: 0.8477 - val_loss: 0.7443 - val_accuracy: 0.6582 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3481 - accuracy: 0.8406 - val_loss: 0.7445 - val_accuracy: 0.6709 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3518 - accuracy: 0.8392 - val_loss: 0.7465 - val_accuracy: 0.6709 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3606 - accuracy: 0.8181 - val_loss: 0.7479 - val_accuracy: 0.6709 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3588 - accuracy: 0.8279 - val_loss: 0.7492 - val_accuracy: 0.6582 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3940 - accuracy: 0.8054 - val_loss: 0.7468 - val_accuracy: 0.6582 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3439 - accuracy: 0.8364 - val_loss: 0.7478 - val_accuracy: 0.6582 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3605 - accuracy: 0.8420 - val_loss: 0.7464 - val_accuracy: 0.6582 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3661 - accuracy: 0.8025 - val_loss: 0.7465 - val_accuracy: 0.6582 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3560 - accuracy: 0.8237 - val_loss: 0.7477 - val_accuracy: 0.6582 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3572 - accuracy: 0.8364 - val_loss: 0.7476 - val_accuracy: 0.6582 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3465 - accuracy: 0.8449 - val_loss: 0.7487 - val_accuracy: 0.6582 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3596 - accuracy: 0.8378 - val_loss: 0.7484 - val_accuracy: 0.6582 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3367 - accuracy: 0.8420 - val_loss: 0.7494 - val_accuracy: 0.6582 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3487 - accuracy: 0.8336 - val_loss: 0.7490 - val_accuracy: 0.6582 - lr: 1.6927e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 1.6307 - accuracy: 0.5882 - val_loss: 1.2135 - val_accuracy: 0.6582 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6499 - accuracy: 0.6333 - val_loss: 0.6998 - val_accuracy: 0.6582 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5996 - accuracy: 0.6812 - val_loss: 0.6014 - val_accuracy: 0.7342 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5987 - accuracy: 0.6827 - val_loss: 0.6099 - val_accuracy: 0.7215 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5921 - accuracy: 0.6855 - val_loss: 0.5634 - val_accuracy: 0.7215 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5494 - accuracy: 0.7137 - val_loss: 0.5554 - val_accuracy: 0.6835 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5340 - accuracy: 0.7236 - val_loss: 0.5454 - val_accuracy: 0.7089 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5095 - accuracy: 0.7362 - val_loss: 0.5847 - val_accuracy: 0.6582 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4642 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7089 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4643 - accuracy: 0.7715 - val_loss: 0.7116 - val_accuracy: 0.6329 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4622 - accuracy: 0.7828 - val_loss: 0.5572 - val_accuracy: 0.6962 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4438 - accuracy: 0.7842 - val_loss: 0.5357 - val_accuracy: 0.6582 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4112 - accuracy: 0.8039 - val_loss: 0.5531 - val_accuracy: 0.7089 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4195 - accuracy: 0.8039 - val_loss: 0.5806 - val_accuracy: 0.7089 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3916 - accuracy: 0.8209 - val_loss: 0.6300 - val_accuracy: 0.6709 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3914 - accuracy: 0.8138 - val_loss: 0.5640 - val_accuracy: 0.6962 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3819 - accuracy: 0.8307 - val_loss: 0.5961 - val_accuracy: 0.6709 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3738 - accuracy: 0.8195 - val_loss: 0.5598 - val_accuracy: 0.7089 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.8336 - val_loss: 0.5501 - val_accuracy: 0.7089 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3577 - accuracy: 0.8477 - val_loss: 0.5863 - val_accuracy: 0.7215 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3464 - accuracy: 0.8378 - val_loss: 0.5871 - val_accuracy: 0.7089 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3502 - accuracy: 0.8336 - val_loss: 0.5754 - val_accuracy: 0.7089 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3666 - accuracy: 0.8434 - val_loss: 0.5830 - val_accuracy: 0.7215 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3391 - accuracy: 0.8561 - val_loss: 0.5631 - val_accuracy: 0.7215 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3575 - accuracy: 0.8392 - val_loss: 0.5695 - val_accuracy: 0.7342 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3195 - accuracy: 0.8561 - val_loss: 0.5792 - val_accuracy: 0.7342 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3519 - accuracy: 0.8350 - val_loss: 0.5726 - val_accuracy: 0.7342 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3262 - accuracy: 0.8590 - val_loss: 0.5762 - val_accuracy: 0.7342 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3312 - accuracy: 0.8575 - val_loss: 0.5794 - val_accuracy: 0.7342 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3286 - accuracy: 0.8590 - val_loss: 0.5854 - val_accuracy: 0.7342 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3396 - accuracy: 0.8491 - val_loss: 0.5881 - val_accuracy: 0.7342 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3278 - accuracy: 0.8575 - val_loss: 0.5882 - val_accuracy: 0.7342 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3363 - accuracy: 0.8463 - val_loss: 0.5884 - val_accuracy: 0.7342 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3417 - accuracy: 0.8519 - val_loss: 0.5882 - val_accuracy: 0.7342 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3354 - accuracy: 0.8491 - val_loss: 0.5853 - val_accuracy: 0.7342 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3296 - accuracy: 0.8604 - val_loss: 0.5853 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3153 - accuracy: 0.8702 - val_loss: 0.5871 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3203 - accuracy: 0.8646 - val_loss: 0.5850 - val_accuracy: 0.7342 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3196 - accuracy: 0.8688 - val_loss: 0.5863 - val_accuracy: 0.7342 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3226 - accuracy: 0.8745 - val_loss: 0.5859 - val_accuracy: 0.7342 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3293 - accuracy: 0.8547 - val_loss: 0.5872 - val_accuracy: 0.7342 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3286 - accuracy: 0.8604 - val_loss: 0.5875 - val_accuracy: 0.7342 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3139 - accuracy: 0.8759 - val_loss: 0.5883 - val_accuracy: 0.7342 - lr: 7.8364e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 1.7239 - accuracy: 0.5628 - val_loss: 0.6737 - val_accuracy: 0.6709 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6623 - accuracy: 0.6164 - val_loss: 0.6446 - val_accuracy: 0.6709 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6168 - accuracy: 0.6559 - val_loss: 0.6243 - val_accuracy: 0.6709 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5873 - accuracy: 0.6869 - val_loss: 0.6027 - val_accuracy: 0.7089 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5474 - accuracy: 0.7292 - val_loss: 0.5708 - val_accuracy: 0.6709 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5055 - accuracy: 0.7532 - val_loss: 0.5915 - val_accuracy: 0.7215 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4782 - accuracy: 0.7602 - val_loss: 0.5966 - val_accuracy: 0.7215 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4873 - accuracy: 0.7504 - val_loss: 0.6285 - val_accuracy: 0.6962 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4427 - accuracy: 0.7814 - val_loss: 0.6344 - val_accuracy: 0.6835 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4466 - accuracy: 0.7856 - val_loss: 0.5968 - val_accuracy: 0.7468 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3975 - accuracy: 0.8054 - val_loss: 0.6065 - val_accuracy: 0.7468 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3800 - accuracy: 0.8166 - val_loss: 0.6502 - val_accuracy: 0.6962 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3595 - accuracy: 0.8279 - val_loss: 0.6978 - val_accuracy: 0.6835 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3653 - accuracy: 0.8364 - val_loss: 0.6856 - val_accuracy: 0.6962 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3458 - accuracy: 0.8265 - val_loss: 0.6849 - val_accuracy: 0.6709 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3241 - accuracy: 0.8604 - val_loss: 0.6886 - val_accuracy: 0.7089 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3443 - accuracy: 0.8434 - val_loss: 0.6631 - val_accuracy: 0.7215 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3168 - accuracy: 0.8731 - val_loss: 0.7081 - val_accuracy: 0.6835 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3079 - accuracy: 0.8745 - val_loss: 0.6660 - val_accuracy: 0.7468 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3013 - accuracy: 0.8731 - val_loss: 0.6843 - val_accuracy: 0.6962 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3005 - accuracy: 0.8731 - val_loss: 0.7461 - val_accuracy: 0.6582 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3004 - accuracy: 0.8717 - val_loss: 0.6967 - val_accuracy: 0.6835 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3029 - accuracy: 0.8688 - val_loss: 0.7088 - val_accuracy: 0.7089 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2853 - accuracy: 0.8872 - val_loss: 0.7107 - val_accuracy: 0.6962 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2982 - accuracy: 0.8759 - val_loss: 0.6951 - val_accuracy: 0.7089 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2701 - accuracy: 0.8829 - val_loss: 0.7178 - val_accuracy: 0.6962 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2888 - accuracy: 0.8843 - val_loss: 0.7126 - val_accuracy: 0.7089 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2799 - accuracy: 0.8872 - val_loss: 0.7123 - val_accuracy: 0.7089 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2910 - accuracy: 0.8604 - val_loss: 0.7107 - val_accuracy: 0.6962 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2827 - accuracy: 0.8914 - val_loss: 0.7078 - val_accuracy: 0.7089 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2594 - accuracy: 0.8942 - val_loss: 0.7177 - val_accuracy: 0.6962 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2853 - accuracy: 0.8829 - val_loss: 0.7175 - val_accuracy: 0.6962 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2721 - accuracy: 0.8815 - val_loss: 0.7186 - val_accuracy: 0.6962 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2771 - accuracy: 0.8660 - val_loss: 0.7109 - val_accuracy: 0.7089 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2683 - accuracy: 0.8928 - val_loss: 0.7201 - val_accuracy: 0.6962 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2651 - accuracy: 0.8843 - val_loss: 0.7145 - val_accuracy: 0.7089 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2734 - accuracy: 0.8914 - val_loss: 0.7140 - val_accuracy: 0.7089 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2839 - accuracy: 0.8759 - val_loss: 0.7182 - val_accuracy: 0.7089 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2663 - accuracy: 0.8759 - val_loss: 0.7194 - val_accuracy: 0.6962 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2664 - accuracy: 0.8942 - val_loss: 0.7194 - val_accuracy: 0.6962 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2857 - accuracy: 0.8815 - val_loss: 0.7184 - val_accuracy: 0.6962 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2673 - accuracy: 0.8815 - val_loss: 0.7181 - val_accuracy: 0.7089 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2536 - accuracy: 0.8928 - val_loss: 0.7182 - val_accuracy: 0.7089 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2670 - accuracy: 0.8829 - val_loss: 0.7174 - val_accuracy: 0.7089 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2700 - accuracy: 0.8928 - val_loss: 0.7175 - val_accuracy: 0.7089 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2702 - accuracy: 0.8984 - val_loss: 0.7180 - val_accuracy: 0.7089 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2508 - accuracy: 0.8956 - val_loss: 0.7174 - val_accuracy: 0.7089 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2724 - accuracy: 0.8801 - val_loss: 0.7173 - val_accuracy: 0.7089 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2772 - accuracy: 0.8858 - val_loss: 0.7172 - val_accuracy: 0.7089 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2675 - accuracy: 0.8801 - val_loss: 0.7180 - val_accuracy: 0.7089 - lr: 2.8211e-05\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 0.9479 - accuracy: 0.5915 - val_loss: 0.6610 - val_accuracy: 0.6282 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6765 - accuracy: 0.6028 - val_loss: 0.6623 - val_accuracy: 0.6282 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6627 - accuracy: 0.6183 - val_loss: 0.6562 - val_accuracy: 0.6282 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6437 - accuracy: 0.6423 - val_loss: 0.6505 - val_accuracy: 0.6282 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6236 - accuracy: 0.6676 - val_loss: 0.6455 - val_accuracy: 0.6538 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6145 - accuracy: 0.6662 - val_loss: 0.6273 - val_accuracy: 0.6538 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6001 - accuracy: 0.6803 - val_loss: 0.5842 - val_accuracy: 0.7436 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5898 - accuracy: 0.6972 - val_loss: 0.5948 - val_accuracy: 0.7179 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5719 - accuracy: 0.7070 - val_loss: 0.5514 - val_accuracy: 0.7051 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5680 - accuracy: 0.7113 - val_loss: 0.5504 - val_accuracy: 0.7308 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5572 - accuracy: 0.7183 - val_loss: 0.5488 - val_accuracy: 0.7179 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5616 - accuracy: 0.7113 - val_loss: 0.5236 - val_accuracy: 0.7692 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5534 - accuracy: 0.7197 - val_loss: 0.5438 - val_accuracy: 0.7692 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5501 - accuracy: 0.7225 - val_loss: 0.5463 - val_accuracy: 0.7564 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5266 - accuracy: 0.7380 - val_loss: 0.5551 - val_accuracy: 0.7308 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5149 - accuracy: 0.7451 - val_loss: 0.5311 - val_accuracy: 0.7821 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5135 - accuracy: 0.7563 - val_loss: 0.5500 - val_accuracy: 0.7564 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4811 - accuracy: 0.8014 - val_loss: 0.5264 - val_accuracy: 0.7436 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4966 - accuracy: 0.7732 - val_loss: 0.5645 - val_accuracy: 0.7436 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4875 - accuracy: 0.7676 - val_loss: 0.5465 - val_accuracy: 0.7821 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4802 - accuracy: 0.7831 - val_loss: 0.5418 - val_accuracy: 0.7949 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7986 - val_loss: 0.5320 - val_accuracy: 0.7564 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4738 - accuracy: 0.7859 - val_loss: 0.5349 - val_accuracy: 0.7564 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4788 - accuracy: 0.7775 - val_loss: 0.5354 - val_accuracy: 0.7564 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4645 - accuracy: 0.7901 - val_loss: 0.5394 - val_accuracy: 0.7692 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4615 - accuracy: 0.8085 - val_loss: 0.5369 - val_accuracy: 0.7821 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4641 - accuracy: 0.7986 - val_loss: 0.5289 - val_accuracy: 0.7564 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4602 - accuracy: 0.7958 - val_loss: 0.5467 - val_accuracy: 0.7564 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4537 - accuracy: 0.7972 - val_loss: 0.5553 - val_accuracy: 0.7436 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4781 - accuracy: 0.7873 - val_loss: 0.5403 - val_accuracy: 0.7692 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4489 - accuracy: 0.7972 - val_loss: 0.5458 - val_accuracy: 0.7564 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4509 - accuracy: 0.7972 - val_loss: 0.5494 - val_accuracy: 0.7564 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4529 - accuracy: 0.8014 - val_loss: 0.5511 - val_accuracy: 0.7436 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4509 - accuracy: 0.8014 - val_loss: 0.5402 - val_accuracy: 0.7692 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4725 - accuracy: 0.7817 - val_loss: 0.5426 - val_accuracy: 0.7564 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4620 - accuracy: 0.7986 - val_loss: 0.5403 - val_accuracy: 0.7564 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4642 - accuracy: 0.7901 - val_loss: 0.5415 - val_accuracy: 0.7564 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4627 - accuracy: 0.7986 - val_loss: 0.5440 - val_accuracy: 0.7692 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4537 - accuracy: 0.8014 - val_loss: 0.5428 - val_accuracy: 0.7692 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4566 - accuracy: 0.7901 - val_loss: 0.5421 - val_accuracy: 0.7564 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4555 - accuracy: 0.8028 - val_loss: 0.5447 - val_accuracy: 0.7564 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4551 - accuracy: 0.7986 - val_loss: 0.5442 - val_accuracy: 0.7564 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4530 - accuracy: 0.8014 - val_loss: 0.5443 - val_accuracy: 0.7564 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4520 - accuracy: 0.7958 - val_loss: 0.5442 - val_accuracy: 0.7564 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4435 - accuracy: 0.8085 - val_loss: 0.5445 - val_accuracy: 0.7564 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4492 - accuracy: 0.8000 - val_loss: 0.5449 - val_accuracy: 0.7564 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.8141 - val_loss: 0.5447 - val_accuracy: 0.7564 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4456 - accuracy: 0.8014 - val_loss: 0.5448 - val_accuracy: 0.7564 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4568 - accuracy: 0.8070 - val_loss: 0.5441 - val_accuracy: 0.7564 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4617 - accuracy: 0.8028 - val_loss: 0.5438 - val_accuracy: 0.7564 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4466 - accuracy: 0.8113 - val_loss: 0.5440 - val_accuracy: 0.7564 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4399 - accuracy: 0.8056 - val_loss: 0.5441 - val_accuracy: 0.7564 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4576 - accuracy: 0.8056 - val_loss: 0.5443 - val_accuracy: 0.7564 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4420 - accuracy: 0.8099 - val_loss: 0.5442 - val_accuracy: 0.7564 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4484 - accuracy: 0.8042 - val_loss: 0.5441 - val_accuracy: 0.7564 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4555 - accuracy: 0.7986 - val_loss: 0.5437 - val_accuracy: 0.7564 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4388 - accuracy: 0.8127 - val_loss: 0.5436 - val_accuracy: 0.7564 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4705 - accuracy: 0.7873 - val_loss: 0.5437 - val_accuracy: 0.7564 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4497 - accuracy: 0.7972 - val_loss: 0.5437 - val_accuracy: 0.7564 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4650 - accuracy: 0.7944 - val_loss: 0.5436 - val_accuracy: 0.7564 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4542 - accuracy: 0.7986 - val_loss: 0.5436 - val_accuracy: 0.7564 - lr: 3.6562e-06\n",
            "78/78 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "89/89 [==============================] - 2s 11ms/step - loss: 0.9642 - accuracy: 0.5662 - val_loss: 0.6571 - val_accuracy: 0.6923 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6834 - accuracy: 0.5859 - val_loss: 0.6269 - val_accuracy: 0.6923 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6806 - accuracy: 0.5859 - val_loss: 0.6351 - val_accuracy: 0.6923 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6779 - accuracy: 0.5901 - val_loss: 0.6170 - val_accuracy: 0.6923 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6601 - accuracy: 0.6169 - val_loss: 0.6284 - val_accuracy: 0.6923 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6512 - accuracy: 0.6239 - val_loss: 0.6171 - val_accuracy: 0.7179 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6369 - accuracy: 0.6366 - val_loss: 0.6190 - val_accuracy: 0.7051 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6222 - accuracy: 0.6479 - val_loss: 0.6026 - val_accuracy: 0.7692 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6094 - accuracy: 0.6535 - val_loss: 0.5996 - val_accuracy: 0.7564 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5957 - accuracy: 0.6479 - val_loss: 0.5388 - val_accuracy: 0.7692 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5872 - accuracy: 0.6634 - val_loss: 0.5791 - val_accuracy: 0.7821 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5722 - accuracy: 0.6761 - val_loss: 0.5549 - val_accuracy: 0.7821 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5627 - accuracy: 0.6704 - val_loss: 0.5635 - val_accuracy: 0.7821 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5396 - accuracy: 0.6915 - val_loss: 0.5456 - val_accuracy: 0.7564 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5263 - accuracy: 0.6915 - val_loss: 0.5391 - val_accuracy: 0.7821 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5308 - accuracy: 0.6859 - val_loss: 0.5331 - val_accuracy: 0.7821 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5200 - accuracy: 0.6817 - val_loss: 0.5363 - val_accuracy: 0.7692 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4966 - accuracy: 0.7254 - val_loss: 0.5505 - val_accuracy: 0.6795 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5043 - accuracy: 0.7211 - val_loss: 0.5279 - val_accuracy: 0.7051 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4935 - accuracy: 0.7183 - val_loss: 0.5399 - val_accuracy: 0.6667 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4725 - accuracy: 0.7380 - val_loss: 0.5496 - val_accuracy: 0.7051 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4762 - accuracy: 0.7493 - val_loss: 0.5312 - val_accuracy: 0.7179 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4766 - accuracy: 0.7380 - val_loss: 0.5357 - val_accuracy: 0.6923 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4600 - accuracy: 0.7549 - val_loss: 0.5505 - val_accuracy: 0.7051 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4658 - accuracy: 0.7380 - val_loss: 0.5378 - val_accuracy: 0.6923 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4430 - accuracy: 0.7732 - val_loss: 0.5451 - val_accuracy: 0.7051 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4561 - accuracy: 0.7634 - val_loss: 0.5424 - val_accuracy: 0.7051 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4495 - accuracy: 0.7676 - val_loss: 0.5451 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4550 - accuracy: 0.7493 - val_loss: 0.5406 - val_accuracy: 0.6923 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4473 - accuracy: 0.7577 - val_loss: 0.5413 - val_accuracy: 0.7051 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4489 - accuracy: 0.7704 - val_loss: 0.5470 - val_accuracy: 0.7051 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4482 - accuracy: 0.7775 - val_loss: 0.5434 - val_accuracy: 0.6923 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4471 - accuracy: 0.7831 - val_loss: 0.5419 - val_accuracy: 0.7051 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4308 - accuracy: 0.7789 - val_loss: 0.5438 - val_accuracy: 0.7179 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4454 - accuracy: 0.7676 - val_loss: 0.5434 - val_accuracy: 0.7051 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4370 - accuracy: 0.7634 - val_loss: 0.5453 - val_accuracy: 0.7051 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4427 - accuracy: 0.7606 - val_loss: 0.5442 - val_accuracy: 0.7051 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4368 - accuracy: 0.7803 - val_loss: 0.5444 - val_accuracy: 0.7051 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4481 - accuracy: 0.7789 - val_loss: 0.5443 - val_accuracy: 0.6923 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4556 - accuracy: 0.7408 - val_loss: 0.5442 - val_accuracy: 0.6923 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4330 - accuracy: 0.7831 - val_loss: 0.5469 - val_accuracy: 0.6923 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4327 - accuracy: 0.7831 - val_loss: 0.5469 - val_accuracy: 0.6923 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4284 - accuracy: 0.7887 - val_loss: 0.5469 - val_accuracy: 0.6923 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4463 - accuracy: 0.7465 - val_loss: 0.5459 - val_accuracy: 0.6923 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.7746 - val_loss: 0.5463 - val_accuracy: 0.6923 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4406 - accuracy: 0.7775 - val_loss: 0.5463 - val_accuracy: 0.6923 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4318 - accuracy: 0.7690 - val_loss: 0.5461 - val_accuracy: 0.6923 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.7789 - val_loss: 0.5465 - val_accuracy: 0.6923 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4394 - accuracy: 0.7704 - val_loss: 0.5463 - val_accuracy: 0.6923 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4367 - accuracy: 0.7676 - val_loss: 0.5468 - val_accuracy: 0.6923 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4440 - accuracy: 0.7634 - val_loss: 0.5469 - val_accuracy: 0.6923 - lr: 1.6927e-05\n",
            "78/78 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "08d146ac-f3b3-41bc-fe31-3662edabfb61"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7285783836416748 ± 0.04780021761134589\n",
            "0.7487234101926231 ± 0.05132703673475653\n",
            "0.7176646108507146 ± 0.06208603593870916\n",
            "0.7797822095345315 ± 0.08959138605474613\n",
            "0.4236075475711559 ± 0.07562842881460459\n",
            "0.7156243740189678 ± 0.03963673957508091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d6242ae-faa7-4217-d74d-d44294996a7d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99/99 [==============================] - 2s 11ms/step - loss: 1.1373 - accuracy: 0.5952 - val_loss: 0.6711 - val_accuracy: 0.6193 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.6507 - accuracy: 0.6332 - val_loss: 0.6661 - val_accuracy: 0.6193 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.6132 - accuracy: 0.6789 - val_loss: 0.6564 - val_accuracy: 0.6193 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.5952 - accuracy: 0.6789 - val_loss: 0.6485 - val_accuracy: 0.6345 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.5879 - accuracy: 0.7018 - val_loss: 0.6057 - val_accuracy: 0.6701 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.5399 - accuracy: 0.7234 - val_loss: 0.5417 - val_accuracy: 0.7259 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.5055 - accuracy: 0.7500 - val_loss: 0.5476 - val_accuracy: 0.7107 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4943 - accuracy: 0.7728 - val_loss: 0.5653 - val_accuracy: 0.6954 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4568 - accuracy: 0.7868 - val_loss: 0.5392 - val_accuracy: 0.7310 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4434 - accuracy: 0.7957 - val_loss: 0.5328 - val_accuracy: 0.7208 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4304 - accuracy: 0.7944 - val_loss: 0.5643 - val_accuracy: 0.7310 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4146 - accuracy: 0.8033 - val_loss: 0.5702 - val_accuracy: 0.7056 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.4132 - accuracy: 0.8223 - val_loss: 0.5390 - val_accuracy: 0.7513 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3951 - accuracy: 0.8185 - val_loss: 0.5721 - val_accuracy: 0.7310 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.3697 - accuracy: 0.8388 - val_loss: 0.5551 - val_accuracy: 0.7411 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3640 - accuracy: 0.8464 - val_loss: 0.5550 - val_accuracy: 0.7462 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3521 - accuracy: 0.8541 - val_loss: 0.5633 - val_accuracy: 0.7360 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.3445 - accuracy: 0.8541 - val_loss: 0.5899 - val_accuracy: 0.7208 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3403 - accuracy: 0.8528 - val_loss: 0.6352 - val_accuracy: 0.7157 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3396 - accuracy: 0.8604 - val_loss: 0.6070 - val_accuracy: 0.7107 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3077 - accuracy: 0.8934 - val_loss: 0.5738 - val_accuracy: 0.7310 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3107 - accuracy: 0.8756 - val_loss: 0.5975 - val_accuracy: 0.7157 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3234 - accuracy: 0.8680 - val_loss: 0.5824 - val_accuracy: 0.7310 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3189 - accuracy: 0.8693 - val_loss: 0.5922 - val_accuracy: 0.7310 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2984 - accuracy: 0.8782 - val_loss: 0.5939 - val_accuracy: 0.7360 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2909 - accuracy: 0.8820 - val_loss: 0.5980 - val_accuracy: 0.7310 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.2893 - accuracy: 0.8997 - val_loss: 0.6131 - val_accuracy: 0.7157 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3093 - accuracy: 0.8832 - val_loss: 0.5980 - val_accuracy: 0.7259 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3063 - accuracy: 0.8794 - val_loss: 0.6023 - val_accuracy: 0.7310 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2989 - accuracy: 0.8896 - val_loss: 0.6017 - val_accuracy: 0.7411 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2991 - accuracy: 0.8947 - val_loss: 0.6089 - val_accuracy: 0.7310 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3048 - accuracy: 0.8731 - val_loss: 0.6059 - val_accuracy: 0.7411 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2828 - accuracy: 0.8972 - val_loss: 0.6105 - val_accuracy: 0.7310 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2884 - accuracy: 0.8896 - val_loss: 0.6129 - val_accuracy: 0.7157 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2837 - accuracy: 0.8934 - val_loss: 0.6061 - val_accuracy: 0.7360 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2996 - accuracy: 0.8820 - val_loss: 0.6070 - val_accuracy: 0.7360 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2854 - accuracy: 0.8858 - val_loss: 0.6081 - val_accuracy: 0.7310 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2844 - accuracy: 0.8972 - val_loss: 0.6088 - val_accuracy: 0.7360 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2856 - accuracy: 0.8896 - val_loss: 0.6079 - val_accuracy: 0.7360 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.2955 - accuracy: 0.8845 - val_loss: 0.6067 - val_accuracy: 0.7360 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2851 - accuracy: 0.8858 - val_loss: 0.6069 - val_accuracy: 0.7360 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2861 - accuracy: 0.8934 - val_loss: 0.6073 - val_accuracy: 0.7360 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2807 - accuracy: 0.8934 - val_loss: 0.6070 - val_accuracy: 0.7360 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2956 - accuracy: 0.8820 - val_loss: 0.6067 - val_accuracy: 0.7360 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2844 - accuracy: 0.8871 - val_loss: 0.6075 - val_accuracy: 0.7360 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2834 - accuracy: 0.8997 - val_loss: 0.6068 - val_accuracy: 0.7360 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2956 - accuracy: 0.8807 - val_loss: 0.6072 - val_accuracy: 0.7360 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.2943 - accuracy: 0.8820 - val_loss: 0.6076 - val_accuracy: 0.7360 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.2802 - accuracy: 0.9010 - val_loss: 0.6077 - val_accuracy: 0.7360 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2784 - accuracy: 0.8921 - val_loss: 0.6077 - val_accuracy: 0.7360 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "99/99 [==============================] - 1s 10ms/step - loss: 0.2959 - accuracy: 0.8832 - val_loss: 0.6072 - val_accuracy: 0.7360 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.3055 - accuracy: 0.8706 - val_loss: 0.6079 - val_accuracy: 0.7360 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "99/99 [==============================] - 1s 9ms/step - loss: 0.2765 - accuracy: 0.9048 - val_loss: 0.6078 - val_accuracy: 0.7360 - lr: 1.6927e-05\n",
            "197/197 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988ca7a0-28c7-4be6-ab2f-e7b2b30a75bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.751269035532995\n",
            "0.7433639295460184\n",
            "0.762589928057554\n",
            "0.7241379310344828\n",
            "0.45687464281069984\n",
            "0.7882513661202186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('TTCA_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/TTCA_tensorflow_model.zip /content/TTCA_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "5fcecc5e-3463-4d04-c5ab-97c0e83f6b57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/TTCA_tensorflow_model/ (stored 0%)\n",
            "  adding: content/TTCA_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/TTCA_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/TTCA_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 39%)\n",
            "  adding: content/TTCA_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/TTCA_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/TTCA_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fhgta_V8n_M3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}