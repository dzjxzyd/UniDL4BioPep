{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('bitter_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "\n",
        "# employ ESM model for converting and save the converted data in csv format\n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('bitter_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('bitter_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "\n",
        "# employ ESM model for converting and save the converted data in csv format\n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('bitter_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'bitter_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'bitter_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HubTATKXslKw",
        "outputId": "3b54783e-551d-41b0-f23e-0dac1b382dad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(512, 320)\n",
            "(128, 320)\n",
            "(512,)\n",
            "(128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_loss', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9646a5c-58b5-44ed-a67f-4966d19d6672"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 10ms/step - loss: 1.1301 - accuracy: 0.6413 - val_loss: 0.6766 - val_accuracy: 0.5962 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5806 - accuracy: 0.7152 - val_loss: 0.6782 - val_accuracy: 0.5962 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8043 - val_loss: 0.6760 - val_accuracy: 0.5962 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8435 - val_loss: 0.6737 - val_accuracy: 0.5962 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3087 - accuracy: 0.8630 - val_loss: 0.6661 - val_accuracy: 0.5962 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2574 - accuracy: 0.8804 - val_loss: 0.6123 - val_accuracy: 0.7885 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2460 - accuracy: 0.8913 - val_loss: 0.5626 - val_accuracy: 0.8269 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2094 - accuracy: 0.9022 - val_loss: 0.4314 - val_accuracy: 0.8462 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.9217 - val_loss: 0.3228 - val_accuracy: 0.9038 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1649 - accuracy: 0.9304 - val_loss: 0.2666 - val_accuracy: 0.9231 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1595 - accuracy: 0.9217 - val_loss: 0.3147 - val_accuracy: 0.8462 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1334 - accuracy: 0.9457 - val_loss: 0.2751 - val_accuracy: 0.8846 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1100 - accuracy: 0.9457 - val_loss: 0.3151 - val_accuracy: 0.8846 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 0.9565 - val_loss: 0.3033 - val_accuracy: 0.9038 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9348 - val_loss: 0.2613 - val_accuracy: 0.9231 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1222 - accuracy: 0.9413 - val_loss: 0.2966 - val_accuracy: 0.9038 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9630 - val_loss: 0.2986 - val_accuracy: 0.9038 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0851 - accuracy: 0.9652 - val_loss: 0.2949 - val_accuracy: 0.9038 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0828 - accuracy: 0.9609 - val_loss: 0.2937 - val_accuracy: 0.8846 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.9630 - val_loss: 0.2979 - val_accuracy: 0.8846 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0931 - accuracy: 0.9652 - val_loss: 0.3092 - val_accuracy: 0.8846 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 0.9543 - val_loss: 0.2940 - val_accuracy: 0.8846 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0802 - accuracy: 0.9696 - val_loss: 0.2935 - val_accuracy: 0.8846 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0838 - accuracy: 0.9674 - val_loss: 0.2946 - val_accuracy: 0.9038 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0836 - accuracy: 0.9696 - val_loss: 0.2880 - val_accuracy: 0.9038 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0711 - accuracy: 0.9761 - val_loss: 0.2936 - val_accuracy: 0.9038 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0675 - accuracy: 0.9783 - val_loss: 0.2878 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9739 - val_loss: 0.2952 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9739 - val_loss: 0.2952 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9696 - val_loss: 0.2976 - val_accuracy: 0.9038 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9696 - val_loss: 0.2898 - val_accuracy: 0.9038 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0719 - accuracy: 0.9652 - val_loss: 0.2933 - val_accuracy: 0.8846 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9696 - val_loss: 0.2934 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9696 - val_loss: 0.2959 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0815 - accuracy: 0.9717 - val_loss: 0.2953 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9696 - val_loss: 0.2969 - val_accuracy: 0.8846 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9739 - val_loss: 0.2985 - val_accuracy: 0.8846 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1014 - accuracy: 0.9500 - val_loss: 0.2985 - val_accuracy: 0.8846 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0714 - accuracy: 0.9674 - val_loss: 0.2968 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9739 - val_loss: 0.2980 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9609 - val_loss: 0.2982 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0712 - accuracy: 0.9674 - val_loss: 0.2972 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.2971 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0788 - accuracy: 0.9717 - val_loss: 0.2974 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0823 - accuracy: 0.9630 - val_loss: 0.2978 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0799 - accuracy: 0.9587 - val_loss: 0.2977 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0736 - accuracy: 0.9739 - val_loss: 0.2975 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9674 - val_loss: 0.2975 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0666 - accuracy: 0.9717 - val_loss: 0.2975 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9500 - val_loss: 0.2975 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9696 - val_loss: 0.2973 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0746 - accuracy: 0.9696 - val_loss: 0.2974 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9478 - val_loss: 0.2976 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0757 - accuracy: 0.9674 - val_loss: 0.2977 - val_accuracy: 0.8846 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9543 - val_loss: 0.2975 - val_accuracy: 0.8846 - lr: 1.0156e-05\n",
            "52/52 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 10ms/step - loss: 1.5274 - accuracy: 0.6500 - val_loss: 0.7268 - val_accuracy: 0.4231 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5196 - accuracy: 0.7522 - val_loss: 0.8334 - val_accuracy: 0.4231 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4733 - accuracy: 0.7848 - val_loss: 0.7730 - val_accuracy: 0.4231 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3799 - accuracy: 0.8261 - val_loss: 0.7007 - val_accuracy: 0.4808 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8239 - val_loss: 0.6144 - val_accuracy: 0.6346 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2798 - accuracy: 0.8652 - val_loss: 0.4838 - val_accuracy: 0.7500 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.2772 - accuracy: 0.8717 - val_loss: 0.3974 - val_accuracy: 0.8462 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2427 - accuracy: 0.8978 - val_loss: 0.3554 - val_accuracy: 0.8077 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2017 - accuracy: 0.9152 - val_loss: 0.3344 - val_accuracy: 0.8269 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2039 - accuracy: 0.9217 - val_loss: 0.3604 - val_accuracy: 0.8077 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1990 - accuracy: 0.9087 - val_loss: 0.3927 - val_accuracy: 0.8269 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1807 - accuracy: 0.9174 - val_loss: 0.4091 - val_accuracy: 0.8269 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1575 - accuracy: 0.9370 - val_loss: 0.4382 - val_accuracy: 0.8269 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1535 - accuracy: 0.9326 - val_loss: 0.4726 - val_accuracy: 0.8269 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1559 - accuracy: 0.9261 - val_loss: 0.4480 - val_accuracy: 0.8462 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1545 - accuracy: 0.9217 - val_loss: 0.4479 - val_accuracy: 0.8462 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1371 - accuracy: 0.9478 - val_loss: 0.4563 - val_accuracy: 0.8462 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1301 - accuracy: 0.9413 - val_loss: 0.4580 - val_accuracy: 0.8462 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1306 - accuracy: 0.9391 - val_loss: 0.4543 - val_accuracy: 0.8462 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1361 - accuracy: 0.9391 - val_loss: 0.4783 - val_accuracy: 0.8462 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1272 - accuracy: 0.9543 - val_loss: 0.4735 - val_accuracy: 0.8462 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1219 - accuracy: 0.9435 - val_loss: 0.4771 - val_accuracy: 0.8462 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9522 - val_loss: 0.4816 - val_accuracy: 0.8462 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1355 - accuracy: 0.9370 - val_loss: 0.4808 - val_accuracy: 0.8462 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.9543 - val_loss: 0.4768 - val_accuracy: 0.8462 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0997 - accuracy: 0.9674 - val_loss: 0.4908 - val_accuracy: 0.8462 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1141 - accuracy: 0.9565 - val_loss: 0.4969 - val_accuracy: 0.8462 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1178 - accuracy: 0.9522 - val_loss: 0.4949 - val_accuracy: 0.8462 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9609 - val_loss: 0.4935 - val_accuracy: 0.8462 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1197 - accuracy: 0.9500 - val_loss: 0.4926 - val_accuracy: 0.8462 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1341 - accuracy: 0.9522 - val_loss: 0.4877 - val_accuracy: 0.8462 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 0.9522 - val_loss: 0.4868 - val_accuracy: 0.8462 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1216 - accuracy: 0.9500 - val_loss: 0.4858 - val_accuracy: 0.8462 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1168 - accuracy: 0.9500 - val_loss: 0.4882 - val_accuracy: 0.8462 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0965 - accuracy: 0.9630 - val_loss: 0.4901 - val_accuracy: 0.8462 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1354 - accuracy: 0.9435 - val_loss: 0.4880 - val_accuracy: 0.8462 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1234 - accuracy: 0.9391 - val_loss: 0.4892 - val_accuracy: 0.8462 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1280 - accuracy: 0.9435 - val_loss: 0.4889 - val_accuracy: 0.8462 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1281 - accuracy: 0.9413 - val_loss: 0.4886 - val_accuracy: 0.8462 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1270 - accuracy: 0.9435 - val_loss: 0.4885 - val_accuracy: 0.8462 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1192 - accuracy: 0.9522 - val_loss: 0.4882 - val_accuracy: 0.8462 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1177 - accuracy: 0.9478 - val_loss: 0.4881 - val_accuracy: 0.8462 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1147 - accuracy: 0.9478 - val_loss: 0.4889 - val_accuracy: 0.8462 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1285 - accuracy: 0.9413 - val_loss: 0.4896 - val_accuracy: 0.8462 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1104 - accuracy: 0.9522 - val_loss: 0.4898 - val_accuracy: 0.8462 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1249 - accuracy: 0.9500 - val_loss: 0.4896 - val_accuracy: 0.8462 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 0.9522 - val_loss: 0.4896 - val_accuracy: 0.8462 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1079 - accuracy: 0.9609 - val_loss: 0.4895 - val_accuracy: 0.8462 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1218 - accuracy: 0.9478 - val_loss: 0.4899 - val_accuracy: 0.8462 - lr: 2.8211e-05\n",
            "52/52 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.9422 - accuracy: 0.6594 - val_loss: 0.7124 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4407 - accuracy: 0.8069 - val_loss: 0.6918 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.8655 - val_loss: 0.6716 - val_accuracy: 0.5294 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.3081 - accuracy: 0.8764 - val_loss: 0.6546 - val_accuracy: 0.5882 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2331 - accuracy: 0.9046 - val_loss: 0.5435 - val_accuracy: 0.7843 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2296 - accuracy: 0.9024 - val_loss: 0.4413 - val_accuracy: 0.7843 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1658 - accuracy: 0.9328 - val_loss: 0.3992 - val_accuracy: 0.7843 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1608 - accuracy: 0.9436 - val_loss: 0.2972 - val_accuracy: 0.8627 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1230 - accuracy: 0.9436 - val_loss: 0.3246 - val_accuracy: 0.8627 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0956 - accuracy: 0.9610 - val_loss: 0.3404 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0969 - accuracy: 0.9675 - val_loss: 0.3773 - val_accuracy: 0.7843 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9718 - val_loss: 0.3531 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0761 - accuracy: 0.9718 - val_loss: 0.3495 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0747 - accuracy: 0.9783 - val_loss: 0.3534 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0624 - accuracy: 0.9805 - val_loss: 0.3476 - val_accuracy: 0.8431 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0555 - accuracy: 0.9826 - val_loss: 0.3574 - val_accuracy: 0.8039 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.9913 - val_loss: 0.3662 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0575 - accuracy: 0.9805 - val_loss: 0.3698 - val_accuracy: 0.8039 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0477 - accuracy: 0.9913 - val_loss: 0.3649 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 0.9935 - val_loss: 0.3650 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0478 - accuracy: 0.9913 - val_loss: 0.3647 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9935 - val_loss: 0.3816 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9761 - val_loss: 0.3665 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0426 - accuracy: 0.9892 - val_loss: 0.3669 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 0.9935 - val_loss: 0.3685 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9892 - val_loss: 0.3697 - val_accuracy: 0.8431 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0405 - accuracy: 0.9935 - val_loss: 0.3767 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 0.9826 - val_loss: 0.3730 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0384 - accuracy: 0.9935 - val_loss: 0.3719 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0405 - accuracy: 0.9892 - val_loss: 0.3725 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0470 - accuracy: 0.9913 - val_loss: 0.3733 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0433 - accuracy: 0.9935 - val_loss: 0.3749 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0449 - accuracy: 0.9826 - val_loss: 0.3749 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.3749 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0543 - accuracy: 0.9826 - val_loss: 0.3766 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9892 - val_loss: 0.3755 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0402 - accuracy: 0.9935 - val_loss: 0.3763 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0485 - accuracy: 0.9870 - val_loss: 0.3772 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0492 - accuracy: 0.9870 - val_loss: 0.3773 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.3772 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0537 - accuracy: 0.9826 - val_loss: 0.3771 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 0.3770 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9978 - val_loss: 0.3770 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9892 - val_loss: 0.3773 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9892 - val_loss: 0.3770 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9935 - val_loss: 0.3772 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0400 - accuracy: 0.9913 - val_loss: 0.3772 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0407 - accuracy: 0.9870 - val_loss: 0.3771 - val_accuracy: 0.8627 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "58/58 [==============================] - 1s 11ms/step - loss: 1.6854 - accuracy: 0.6204 - val_loss: 0.6951 - val_accuracy: 0.5490 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5264 - accuracy: 0.7397 - val_loss: 0.6870 - val_accuracy: 0.5490 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.3921 - accuracy: 0.8373 - val_loss: 0.6667 - val_accuracy: 0.5490 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8460 - val_loss: 0.6189 - val_accuracy: 0.5882 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2879 - accuracy: 0.8764 - val_loss: 0.5257 - val_accuracy: 0.7451 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2229 - accuracy: 0.8980 - val_loss: 0.5060 - val_accuracy: 0.7255 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.1907 - accuracy: 0.9154 - val_loss: 0.4337 - val_accuracy: 0.8039 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.1869 - accuracy: 0.9024 - val_loss: 0.4320 - val_accuracy: 0.8039 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9501 - val_loss: 0.5015 - val_accuracy: 0.7843 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1289 - accuracy: 0.9523 - val_loss: 0.5234 - val_accuracy: 0.8627 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.9523 - val_loss: 0.5872 - val_accuracy: 0.8824 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1066 - accuracy: 0.9544 - val_loss: 0.5873 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9675 - val_loss: 0.6302 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0917 - accuracy: 0.9631 - val_loss: 0.6420 - val_accuracy: 0.8824 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0750 - accuracy: 0.9675 - val_loss: 0.6662 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9696 - val_loss: 0.6788 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.6907 - val_accuracy: 0.8431 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0685 - accuracy: 0.9696 - val_loss: 0.7139 - val_accuracy: 0.8431 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0718 - accuracy: 0.9675 - val_loss: 0.7131 - val_accuracy: 0.8431 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0513 - accuracy: 0.9848 - val_loss: 0.7185 - val_accuracy: 0.8431 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0647 - accuracy: 0.9740 - val_loss: 0.7204 - val_accuracy: 0.8431 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0638 - accuracy: 0.9783 - val_loss: 0.7274 - val_accuracy: 0.8431 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0590 - accuracy: 0.9826 - val_loss: 0.7401 - val_accuracy: 0.8431 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0506 - accuracy: 0.9805 - val_loss: 0.7403 - val_accuracy: 0.8431 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9675 - val_loss: 0.7381 - val_accuracy: 0.8431 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9848 - val_loss: 0.7450 - val_accuracy: 0.8431 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0512 - accuracy: 0.9870 - val_loss: 0.7412 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0474 - accuracy: 0.9870 - val_loss: 0.7403 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9740 - val_loss: 0.7340 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0634 - accuracy: 0.9783 - val_loss: 0.7307 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0472 - accuracy: 0.9892 - val_loss: 0.7329 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0674 - accuracy: 0.9761 - val_loss: 0.7315 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0692 - accuracy: 0.9740 - val_loss: 0.7328 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0605 - accuracy: 0.9892 - val_loss: 0.7319 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 0.7313 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0493 - accuracy: 0.9870 - val_loss: 0.7320 - val_accuracy: 0.8431 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9805 - val_loss: 0.7308 - val_accuracy: 0.8431 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0609 - accuracy: 0.9783 - val_loss: 0.7296 - val_accuracy: 0.8431 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9892 - val_loss: 0.7303 - val_accuracy: 0.8431 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0556 - accuracy: 0.9913 - val_loss: 0.7304 - val_accuracy: 0.8431 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0482 - accuracy: 0.9870 - val_loss: 0.7308 - val_accuracy: 0.8431 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9740 - val_loss: 0.7297 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0476 - accuracy: 0.9870 - val_loss: 0.7303 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9761 - val_loss: 0.7299 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0626 - accuracy: 0.9848 - val_loss: 0.7307 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0560 - accuracy: 0.9870 - val_loss: 0.7312 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9892 - val_loss: 0.7320 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9783 - val_loss: 0.7310 - val_accuracy: 0.8431 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.0747 - accuracy: 0.4772 - val_loss: 0.6915 - val_accuracy: 0.5294 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.6902 - accuracy: 0.5423 - val_loss: 0.7028 - val_accuracy: 0.4706 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.6407 - accuracy: 0.6226 - val_loss: 0.6956 - val_accuracy: 0.4706 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5954 - accuracy: 0.7093 - val_loss: 0.7538 - val_accuracy: 0.4706 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7310 - val_loss: 0.7570 - val_accuracy: 0.4706 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4351 - accuracy: 0.8069 - val_loss: 0.7029 - val_accuracy: 0.4902 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3987 - accuracy: 0.8308 - val_loss: 0.5336 - val_accuracy: 0.7647 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3777 - accuracy: 0.8460 - val_loss: 0.5106 - val_accuracy: 0.8039 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8547 - val_loss: 0.4382 - val_accuracy: 0.7843 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8590 - val_loss: 0.4089 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2631 - accuracy: 0.8980 - val_loss: 0.4099 - val_accuracy: 0.8039 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2582 - accuracy: 0.9067 - val_loss: 0.4560 - val_accuracy: 0.7843 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2313 - accuracy: 0.9197 - val_loss: 0.4312 - val_accuracy: 0.8431 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1935 - accuracy: 0.9241 - val_loss: 0.4854 - val_accuracy: 0.7843 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2132 - accuracy: 0.9089 - val_loss: 0.4804 - val_accuracy: 0.8431 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1873 - accuracy: 0.9436 - val_loss: 0.5058 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1987 - accuracy: 0.9241 - val_loss: 0.5575 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1883 - accuracy: 0.9328 - val_loss: 0.5310 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1569 - accuracy: 0.9479 - val_loss: 0.5553 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1715 - accuracy: 0.9306 - val_loss: 0.5108 - val_accuracy: 0.8039 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1552 - accuracy: 0.9588 - val_loss: 0.5362 - val_accuracy: 0.8431 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1635 - accuracy: 0.9414 - val_loss: 0.5587 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1562 - accuracy: 0.9436 - val_loss: 0.5122 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1365 - accuracy: 0.9588 - val_loss: 0.5478 - val_accuracy: 0.8039 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1664 - accuracy: 0.9284 - val_loss: 0.5347 - val_accuracy: 0.8039 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1567 - accuracy: 0.9414 - val_loss: 0.5439 - val_accuracy: 0.8039 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1531 - accuracy: 0.9393 - val_loss: 0.5467 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1381 - accuracy: 0.9501 - val_loss: 0.5504 - val_accuracy: 0.8039 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1496 - accuracy: 0.9501 - val_loss: 0.5556 - val_accuracy: 0.8039 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.9523 - val_loss: 0.5581 - val_accuracy: 0.8039 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1438 - accuracy: 0.9523 - val_loss: 0.5582 - val_accuracy: 0.8039 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1406 - accuracy: 0.9588 - val_loss: 0.5597 - val_accuracy: 0.8235 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1447 - accuracy: 0.9436 - val_loss: 0.5565 - val_accuracy: 0.8039 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1413 - accuracy: 0.9588 - val_loss: 0.5547 - val_accuracy: 0.8039 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1246 - accuracy: 0.9566 - val_loss: 0.5441 - val_accuracy: 0.8039 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1484 - accuracy: 0.9414 - val_loss: 0.5465 - val_accuracy: 0.8039 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1389 - accuracy: 0.9566 - val_loss: 0.5497 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1425 - accuracy: 0.9479 - val_loss: 0.5533 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1659 - accuracy: 0.9371 - val_loss: 0.5527 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1445 - accuracy: 0.9501 - val_loss: 0.5539 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.5526 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1367 - accuracy: 0.9458 - val_loss: 0.5538 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1218 - accuracy: 0.9653 - val_loss: 0.5540 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1492 - accuracy: 0.9414 - val_loss: 0.5527 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9523 - val_loss: 0.5537 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.1512 - accuracy: 0.9501 - val_loss: 0.5536 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1468 - accuracy: 0.9458 - val_loss: 0.5539 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9523 - val_loss: 0.5544 - val_accuracy: 0.8235 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1399 - accuracy: 0.9458 - val_loss: 0.5540 - val_accuracy: 0.8235 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9501 - val_loss: 0.5536 - val_accuracy: 0.8235 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.5864 - accuracy: 0.6659 - val_loss: 0.6953 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4384 - accuracy: 0.8243 - val_loss: 0.7177 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.8590 - val_loss: 0.6969 - val_accuracy: 0.4510 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2478 - accuracy: 0.9002 - val_loss: 0.6568 - val_accuracy: 0.7451 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2332 - accuracy: 0.9046 - val_loss: 0.6214 - val_accuracy: 0.6863 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1870 - accuracy: 0.9241 - val_loss: 0.5342 - val_accuracy: 0.7451 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1590 - accuracy: 0.9284 - val_loss: 0.4960 - val_accuracy: 0.7647 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1535 - accuracy: 0.9414 - val_loss: 0.5813 - val_accuracy: 0.7843 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1138 - accuracy: 0.9501 - val_loss: 0.6128 - val_accuracy: 0.7843 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.9610 - val_loss: 0.6362 - val_accuracy: 0.8039 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9718 - val_loss: 0.7451 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9696 - val_loss: 0.7138 - val_accuracy: 0.8039 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9761 - val_loss: 0.7210 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.9740 - val_loss: 0.7797 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0632 - accuracy: 0.9696 - val_loss: 0.8086 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9826 - val_loss: 0.7783 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9892 - val_loss: 0.8103 - val_accuracy: 0.8039 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0462 - accuracy: 0.9892 - val_loss: 0.8350 - val_accuracy: 0.8039 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0521 - accuracy: 0.9826 - val_loss: 0.8076 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0525 - accuracy: 0.9805 - val_loss: 0.8104 - val_accuracy: 0.8039 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0616 - accuracy: 0.9740 - val_loss: 0.8012 - val_accuracy: 0.8039 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0510 - accuracy: 0.9848 - val_loss: 0.8118 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0620 - accuracy: 0.9740 - val_loss: 0.8348 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.8429 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0458 - accuracy: 0.9935 - val_loss: 0.8390 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0421 - accuracy: 0.9913 - val_loss: 0.8338 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9957 - val_loss: 0.8447 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0526 - accuracy: 0.9848 - val_loss: 0.8334 - val_accuracy: 0.8039 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0420 - accuracy: 0.9892 - val_loss: 0.8403 - val_accuracy: 0.8039 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0470 - accuracy: 0.9870 - val_loss: 0.8429 - val_accuracy: 0.8039 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0463 - accuracy: 0.9892 - val_loss: 0.8428 - val_accuracy: 0.8039 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0368 - accuracy: 0.9913 - val_loss: 0.8457 - val_accuracy: 0.8039 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9848 - val_loss: 0.8525 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9892 - val_loss: 0.8516 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0487 - accuracy: 0.9826 - val_loss: 0.8547 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0511 - accuracy: 0.9870 - val_loss: 0.8550 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.9870 - val_loss: 0.8533 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0432 - accuracy: 0.9870 - val_loss: 0.8515 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0501 - accuracy: 0.9892 - val_loss: 0.8531 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0398 - accuracy: 0.9957 - val_loss: 0.8535 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.9805 - val_loss: 0.8542 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0461 - accuracy: 0.9913 - val_loss: 0.8545 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0525 - accuracy: 0.9848 - val_loss: 0.8530 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0484 - accuracy: 0.9892 - val_loss: 0.8513 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0479 - accuracy: 0.9870 - val_loss: 0.8531 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0472 - accuracy: 0.9892 - val_loss: 0.8524 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.9892 - val_loss: 0.8524 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.7487 - accuracy: 0.6399 - val_loss: 0.6967 - val_accuracy: 0.3922 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4686 - accuracy: 0.7983 - val_loss: 0.6970 - val_accuracy: 0.3922 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3756 - accuracy: 0.8373 - val_loss: 0.6865 - val_accuracy: 0.6471 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8568 - val_loss: 0.6855 - val_accuracy: 0.5294 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2693 - accuracy: 0.8937 - val_loss: 0.5849 - val_accuracy: 0.7255 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2408 - accuracy: 0.8915 - val_loss: 0.4455 - val_accuracy: 0.8431 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1889 - accuracy: 0.9111 - val_loss: 0.3835 - val_accuracy: 0.8627 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1820 - accuracy: 0.9111 - val_loss: 0.3493 - val_accuracy: 0.8431 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1534 - accuracy: 0.9436 - val_loss: 0.4203 - val_accuracy: 0.8431 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1370 - accuracy: 0.9414 - val_loss: 0.4546 - val_accuracy: 0.8431 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1172 - accuracy: 0.9414 - val_loss: 0.4393 - val_accuracy: 0.8824 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9696 - val_loss: 0.4316 - val_accuracy: 0.8824 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.4916 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1081 - accuracy: 0.9523 - val_loss: 0.4847 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.4860 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9675 - val_loss: 0.5073 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.5238 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0908 - accuracy: 0.9653 - val_loss: 0.5354 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0674 - accuracy: 0.9848 - val_loss: 0.5396 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0797 - accuracy: 0.9718 - val_loss: 0.5640 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0615 - accuracy: 0.9870 - val_loss: 0.5650 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0737 - accuracy: 0.9718 - val_loss: 0.5665 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0567 - accuracy: 0.9848 - val_loss: 0.5661 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0528 - accuracy: 0.9913 - val_loss: 0.5717 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0739 - accuracy: 0.9783 - val_loss: 0.5586 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 1s 14ms/step - loss: 0.0626 - accuracy: 0.9848 - val_loss: 0.5641 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0691 - accuracy: 0.9783 - val_loss: 0.5617 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0754 - accuracy: 0.9718 - val_loss: 0.5499 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9783 - val_loss: 0.5483 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9848 - val_loss: 0.5464 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0607 - accuracy: 0.9805 - val_loss: 0.5460 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9783 - val_loss: 0.5467 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.5473 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0587 - accuracy: 0.9761 - val_loss: 0.5442 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9892 - val_loss: 0.5469 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0574 - accuracy: 0.9848 - val_loss: 0.5462 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0605 - accuracy: 0.9783 - val_loss: 0.5460 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 1s 8ms/step - loss: 0.0538 - accuracy: 0.9826 - val_loss: 0.5458 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9826 - val_loss: 0.5463 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0777 - accuracy: 0.9610 - val_loss: 0.5477 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0595 - accuracy: 0.9783 - val_loss: 0.5478 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9870 - val_loss: 0.5495 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0594 - accuracy: 0.9848 - val_loss: 0.5483 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0587 - accuracy: 0.9826 - val_loss: 0.5481 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 0.5467 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0662 - accuracy: 0.9761 - val_loss: 0.5448 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0680 - accuracy: 0.9740 - val_loss: 0.5457 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 0.5459 - val_accuracy: 0.8627 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 10ms/step - loss: 1.0064 - accuracy: 0.6009 - val_loss: 0.7345 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7245 - val_loss: 0.8266 - val_accuracy: 0.4510 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5321 - accuracy: 0.7137 - val_loss: 0.7910 - val_accuracy: 0.4510 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8026 - val_loss: 0.7923 - val_accuracy: 0.4510 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4011 - accuracy: 0.8200 - val_loss: 0.7034 - val_accuracy: 0.4706 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3192 - accuracy: 0.8590 - val_loss: 0.6879 - val_accuracy: 0.4902 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2683 - accuracy: 0.8807 - val_loss: 0.5076 - val_accuracy: 0.7059 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2384 - accuracy: 0.8829 - val_loss: 0.3769 - val_accuracy: 0.8431 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1966 - accuracy: 0.9154 - val_loss: 0.3618 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1532 - accuracy: 0.9436 - val_loss: 0.3471 - val_accuracy: 0.8627 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1653 - accuracy: 0.9328 - val_loss: 0.4097 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1305 - accuracy: 0.9544 - val_loss: 0.4342 - val_accuracy: 0.8431 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1239 - accuracy: 0.9566 - val_loss: 0.4184 - val_accuracy: 0.8431 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1211 - accuracy: 0.9610 - val_loss: 0.4351 - val_accuracy: 0.8431 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1071 - accuracy: 0.9696 - val_loss: 0.4128 - val_accuracy: 0.8431 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9675 - val_loss: 0.4258 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0947 - accuracy: 0.9653 - val_loss: 0.4373 - val_accuracy: 0.8431 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1055 - accuracy: 0.9631 - val_loss: 0.4315 - val_accuracy: 0.8431 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0938 - accuracy: 0.9696 - val_loss: 0.4600 - val_accuracy: 0.8431 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9675 - val_loss: 0.4737 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9675 - val_loss: 0.4773 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0901 - accuracy: 0.9718 - val_loss: 0.4646 - val_accuracy: 0.8431 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0855 - accuracy: 0.9740 - val_loss: 0.4658 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0675 - accuracy: 0.9848 - val_loss: 0.4654 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9826 - val_loss: 0.4659 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9718 - val_loss: 0.4625 - val_accuracy: 0.8431 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9870 - val_loss: 0.4628 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9805 - val_loss: 0.4570 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0682 - accuracy: 0.9783 - val_loss: 0.4617 - val_accuracy: 0.8431 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9740 - val_loss: 0.4592 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0676 - accuracy: 0.9740 - val_loss: 0.4618 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0668 - accuracy: 0.9783 - val_loss: 0.4615 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9826 - val_loss: 0.4622 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0785 - accuracy: 0.9783 - val_loss: 0.4633 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0731 - accuracy: 0.9783 - val_loss: 0.4574 - val_accuracy: 0.8431 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0610 - accuracy: 0.9870 - val_loss: 0.4584 - val_accuracy: 0.8431 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0597 - accuracy: 0.9870 - val_loss: 0.4583 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0566 - accuracy: 0.9870 - val_loss: 0.4581 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 0.9761 - val_loss: 0.4589 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9826 - val_loss: 0.4595 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9740 - val_loss: 0.4607 - val_accuracy: 0.8431 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0591 - accuracy: 0.9848 - val_loss: 0.4606 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0642 - accuracy: 0.9783 - val_loss: 0.4608 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.4615 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9740 - val_loss: 0.4615 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0617 - accuracy: 0.9892 - val_loss: 0.4614 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9783 - val_loss: 0.4618 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0551 - accuracy: 0.9870 - val_loss: 0.4620 - val_accuracy: 0.8431 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0621 - accuracy: 0.9761 - val_loss: 0.4617 - val_accuracy: 0.8431 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0639 - accuracy: 0.9761 - val_loss: 0.4619 - val_accuracy: 0.8431 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.0531 - accuracy: 0.5987 - val_loss: 0.7340 - val_accuracy: 0.4314 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5838 - accuracy: 0.7440 - val_loss: 0.8305 - val_accuracy: 0.4314 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4428 - accuracy: 0.8048 - val_loss: 0.7971 - val_accuracy: 0.4314 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.4090 - accuracy: 0.8178 - val_loss: 0.7955 - val_accuracy: 0.4314 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3921 - accuracy: 0.8243 - val_loss: 0.7657 - val_accuracy: 0.4314 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2926 - accuracy: 0.8807 - val_loss: 0.6584 - val_accuracy: 0.5294 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2520 - accuracy: 0.9002 - val_loss: 0.5255 - val_accuracy: 0.7647 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2311 - accuracy: 0.9002 - val_loss: 0.4366 - val_accuracy: 0.7843 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1781 - accuracy: 0.9241 - val_loss: 0.3856 - val_accuracy: 0.8039 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1571 - accuracy: 0.9328 - val_loss: 0.3850 - val_accuracy: 0.9020 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1930 - accuracy: 0.9067 - val_loss: 0.3992 - val_accuracy: 0.9020 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9479 - val_loss: 0.4644 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.1395 - accuracy: 0.9328 - val_loss: 0.5469 - val_accuracy: 0.8431 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1478 - accuracy: 0.9284 - val_loss: 0.4576 - val_accuracy: 0.8627 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.1170 - accuracy: 0.9544 - val_loss: 0.5077 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1224 - accuracy: 0.9523 - val_loss: 0.4894 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1152 - accuracy: 0.9610 - val_loss: 0.5256 - val_accuracy: 0.8627 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 1s 13ms/step - loss: 0.0988 - accuracy: 0.9653 - val_loss: 0.5129 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.0900 - accuracy: 0.9653 - val_loss: 0.5176 - val_accuracy: 0.8627 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 1s 16ms/step - loss: 0.0991 - accuracy: 0.9631 - val_loss: 0.5076 - val_accuracy: 0.8824 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 1s 15ms/step - loss: 0.1063 - accuracy: 0.9523 - val_loss: 0.5340 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1158 - accuracy: 0.9544 - val_loss: 0.5339 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0846 - accuracy: 0.9740 - val_loss: 0.5561 - val_accuracy: 0.8627 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0980 - accuracy: 0.9610 - val_loss: 0.5461 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1010 - accuracy: 0.9653 - val_loss: 0.5619 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0996 - accuracy: 0.9610 - val_loss: 0.5526 - val_accuracy: 0.8627 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0966 - accuracy: 0.9610 - val_loss: 0.5438 - val_accuracy: 0.8824 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0947 - accuracy: 0.9653 - val_loss: 0.5491 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0964 - accuracy: 0.9653 - val_loss: 0.5476 - val_accuracy: 0.8627 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0843 - accuracy: 0.9761 - val_loss: 0.5509 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1015 - accuracy: 0.9610 - val_loss: 0.5557 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 0.9718 - val_loss: 0.5588 - val_accuracy: 0.8627 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1069 - accuracy: 0.9566 - val_loss: 0.5545 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9566 - val_loss: 0.5506 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9631 - val_loss: 0.5470 - val_accuracy: 0.8627 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0766 - accuracy: 0.9761 - val_loss: 0.5475 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.5472 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0752 - accuracy: 0.9805 - val_loss: 0.5494 - val_accuracy: 0.8627 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0989 - accuracy: 0.9631 - val_loss: 0.5480 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0815 - accuracy: 0.9805 - val_loss: 0.5503 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 0.9610 - val_loss: 0.5504 - val_accuracy: 0.8627 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0769 - accuracy: 0.9805 - val_loss: 0.5511 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.9761 - val_loss: 0.5524 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0839 - accuracy: 0.9740 - val_loss: 0.5526 - val_accuracy: 0.8627 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0946 - accuracy: 0.9588 - val_loss: 0.5521 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0821 - accuracy: 0.9761 - val_loss: 0.5530 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0840 - accuracy: 0.9718 - val_loss: 0.5540 - val_accuracy: 0.8627 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0777 - accuracy: 0.9761 - val_loss: 0.5544 - val_accuracy: 0.8627 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0846 - accuracy: 0.9761 - val_loss: 0.5544 - val_accuracy: 0.8627 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.5541 - val_accuracy: 0.8627 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 1s 11ms/step - loss: 1.2954 - accuracy: 0.6356 - val_loss: 0.7135 - val_accuracy: 0.4902 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.7549 - val_loss: 0.7323 - val_accuracy: 0.4902 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.3804 - accuracy: 0.8351 - val_loss: 0.7662 - val_accuracy: 0.4902 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3705 - accuracy: 0.8460 - val_loss: 0.7799 - val_accuracy: 0.4902 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.3014 - accuracy: 0.8872 - val_loss: 0.6828 - val_accuracy: 0.5294 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2609 - accuracy: 0.8937 - val_loss: 0.6065 - val_accuracy: 0.5882 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.2250 - accuracy: 0.8937 - val_loss: 0.4952 - val_accuracy: 0.7647 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.2043 - accuracy: 0.9111 - val_loss: 0.4433 - val_accuracy: 0.7647 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1690 - accuracy: 0.9154 - val_loss: 0.4259 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1704 - accuracy: 0.9371 - val_loss: 0.4745 - val_accuracy: 0.8235 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1602 - accuracy: 0.9306 - val_loss: 0.5137 - val_accuracy: 0.8039 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1305 - accuracy: 0.9566 - val_loss: 0.5721 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1194 - accuracy: 0.9544 - val_loss: 0.5864 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1167 - accuracy: 0.9566 - val_loss: 0.6759 - val_accuracy: 0.8235 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.1253 - accuracy: 0.9523 - val_loss: 0.6369 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.6519 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.1061 - accuracy: 0.9610 - val_loss: 0.6404 - val_accuracy: 0.8235 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9653 - val_loss: 0.6773 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0788 - accuracy: 0.9805 - val_loss: 0.7086 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0841 - accuracy: 0.9761 - val_loss: 0.6791 - val_accuracy: 0.8235 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0828 - accuracy: 0.9783 - val_loss: 0.6818 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0886 - accuracy: 0.9718 - val_loss: 0.6786 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0902 - accuracy: 0.9761 - val_loss: 0.6913 - val_accuracy: 0.8235 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0880 - accuracy: 0.9696 - val_loss: 0.7014 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9783 - val_loss: 0.7183 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0793 - accuracy: 0.9783 - val_loss: 0.7192 - val_accuracy: 0.8235 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0746 - accuracy: 0.9805 - val_loss: 0.7182 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0820 - accuracy: 0.9783 - val_loss: 0.7106 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0740 - accuracy: 0.9848 - val_loss: 0.7173 - val_accuracy: 0.8235 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9805 - val_loss: 0.7171 - val_accuracy: 0.8431 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0869 - accuracy: 0.9696 - val_loss: 0.7136 - val_accuracy: 0.8235 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0827 - accuracy: 0.9826 - val_loss: 0.7123 - val_accuracy: 0.8235 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0763 - accuracy: 0.9783 - val_loss: 0.7135 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0683 - accuracy: 0.9870 - val_loss: 0.7196 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0799 - accuracy: 0.9783 - val_loss: 0.7216 - val_accuracy: 0.8235 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0829 - accuracy: 0.9740 - val_loss: 0.7230 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.9783 - val_loss: 0.7236 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 1s 9ms/step - loss: 0.0763 - accuracy: 0.9718 - val_loss: 0.7209 - val_accuracy: 0.8235 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0821 - accuracy: 0.9805 - val_loss: 0.7233 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0660 - accuracy: 0.9870 - val_loss: 0.7249 - val_accuracy: 0.8235 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9718 - val_loss: 0.7240 - val_accuracy: 0.8431 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0693 - accuracy: 0.9848 - val_loss: 0.7235 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9805 - val_loss: 0.7234 - val_accuracy: 0.8235 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9761 - val_loss: 0.7236 - val_accuracy: 0.8431 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0739 - accuracy: 0.9870 - val_loss: 0.7237 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 7ms/step - loss: 0.0888 - accuracy: 0.9675 - val_loss: 0.7247 - val_accuracy: 0.8431 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 0.9848 - val_loss: 0.7253 - val_accuracy: 0.8235 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 0.9783 - val_loss: 0.7252 - val_accuracy: 0.8235 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 8ms/step - loss: 0.0757 - accuracy: 0.9805 - val_loss: 0.7247 - val_accuracy: 0.8235 - lr: 2.8211e-05\n",
            "51/51 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "d83b2d27-b890-42db-82ca-ced084ea79b7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8436274509803922  0.046354042261516765\n",
            "0.8451833578903087  0.04535267386942948\n",
            "0.8472818665252876  0.062383802203329515\n",
            "0.8430848492553298  0.06595380921003595\n",
            "0.6870940673431497  0.0897090661409879\n",
            "0.9147550263941262  0.03135277887354698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb46ad44-6bcc-44f2-b4c9-6c038666c34b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 1s 11ms/step - loss: 1.2182 - accuracy: 0.6699 - val_loss: 0.6945 - val_accuracy: 0.5000 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.4414 - accuracy: 0.8047 - val_loss: 0.6954 - val_accuracy: 0.5000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.3617 - accuracy: 0.8320 - val_loss: 0.6930 - val_accuracy: 0.5000 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.2810 - accuracy: 0.8867 - val_loss: 0.6908 - val_accuracy: 0.5078 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.2524 - accuracy: 0.8809 - val_loss: 0.5629 - val_accuracy: 0.8359 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.2159 - accuracy: 0.9043 - val_loss: 0.4176 - val_accuracy: 0.8750 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.1810 - accuracy: 0.9258 - val_loss: 0.3719 - val_accuracy: 0.8906 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.1468 - accuracy: 0.9395 - val_loss: 0.2761 - val_accuracy: 0.8750 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.1463 - accuracy: 0.9258 - val_loss: 0.2213 - val_accuracy: 0.9141 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.1324 - accuracy: 0.9473 - val_loss: 0.2141 - val_accuracy: 0.9141 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.1280 - accuracy: 0.9492 - val_loss: 0.1906 - val_accuracy: 0.9219 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.1000 - accuracy: 0.9668 - val_loss: 0.1956 - val_accuracy: 0.9219 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.0948 - accuracy: 0.9609 - val_loss: 0.1890 - val_accuracy: 0.9375 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0866 - accuracy: 0.9609 - val_loss: 0.1977 - val_accuracy: 0.9375 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0810 - accuracy: 0.9746 - val_loss: 0.1801 - val_accuracy: 0.9375 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9746 - val_loss: 0.1894 - val_accuracy: 0.9375 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0706 - accuracy: 0.9766 - val_loss: 0.1919 - val_accuracy: 0.9375 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.1954 - val_accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 0.1926 - val_accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "64/64 [==============================] - 0s 6ms/step - loss: 0.0601 - accuracy: 0.9746 - val_loss: 0.2020 - val_accuracy: 0.9375 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9922 - val_loss: 0.2013 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0582 - accuracy: 0.9824 - val_loss: 0.1921 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.2120 - val_accuracy: 0.9375 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: 0.2023 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.1976 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0531 - accuracy: 0.9902 - val_loss: 0.1969 - val_accuracy: 0.9375 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.9785 - val_loss: 0.1969 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9844 - val_loss: 0.1988 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.2009 - val_accuracy: 0.9375 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0500 - accuracy: 0.9863 - val_loss: 0.1968 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.0545 - accuracy: 0.9844 - val_loss: 0.1958 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0562 - accuracy: 0.9824 - val_loss: 0.2004 - val_accuracy: 0.9375 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0656 - accuracy: 0.9766 - val_loss: 0.1992 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0539 - accuracy: 0.9844 - val_loss: 0.1984 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 0.9844 - val_loss: 0.1959 - val_accuracy: 0.9375 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.0504 - accuracy: 0.9824 - val_loss: 0.1961 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "64/64 [==============================] - 0s 8ms/step - loss: 0.0584 - accuracy: 0.9844 - val_loss: 0.1969 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0435 - accuracy: 0.9922 - val_loss: 0.1974 - val_accuracy: 0.9375 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9863 - val_loss: 0.1979 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9824 - val_loss: 0.1979 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9844 - val_loss: 0.1984 - val_accuracy: 0.9375 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0626 - accuracy: 0.9785 - val_loss: 0.1983 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0603 - accuracy: 0.9785 - val_loss: 0.1986 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0662 - accuracy: 0.9746 - val_loss: 0.1993 - val_accuracy: 0.9375 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0615 - accuracy: 0.9805 - val_loss: 0.1991 - val_accuracy: 0.9375 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0466 - accuracy: 0.9941 - val_loss: 0.1988 - val_accuracy: 0.9375 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 0.1987 - val_accuracy: 0.9375 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0582 - accuracy: 0.9785 - val_loss: 0.1988 - val_accuracy: 0.9375 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 0.9980 - val_loss: 0.1990 - val_accuracy: 0.9375 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0558 - accuracy: 0.9785 - val_loss: 0.1990 - val_accuracy: 0.9375 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "64/64 [==============================] - 1s 9ms/step - loss: 0.0463 - accuracy: 0.9902 - val_loss: 0.1990 - val_accuracy: 0.9375 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "64/64 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9746 - val_loss: 0.1990 - val_accuracy: 0.9375 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0496 - accuracy: 0.9863 - val_loss: 0.1991 - val_accuracy: 0.9375 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0603 - accuracy: 0.9863 - val_loss: 0.1992 - val_accuracy: 0.9375 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "64/64 [==============================] - 1s 8ms/step - loss: 0.0522 - accuracy: 0.9883 - val_loss: 0.1992 - val_accuracy: 0.9375 - lr: 1.0156e-05\n",
            "128/128 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0217007d-6097-48d1-a675-10ff22e85c5d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9375\n",
            "0.9379276637341154\n",
            "0.9242424242424242\n",
            "0.9516129032258065\n",
            "0.8754275592730114\n",
            "0.982421875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('bitter_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/bitter_tensorflow_model.zip /content/bitter_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "b7ced367-df2b-4723-ee87-fa93b3c9a632"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/bitter_tensorflow_model/ (stored 0%)\n",
            "  adding: content/bitter_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/bitter_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/bitter_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 39%)\n",
            "  adding: content/bitter_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/bitter_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/bitter_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LB4VkASsiTG-"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}