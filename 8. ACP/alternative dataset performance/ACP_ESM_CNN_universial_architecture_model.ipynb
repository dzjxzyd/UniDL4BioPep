{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0799ab00-74a1-4a59-dbe2-92789e2610d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (main dataset)"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('main_ACP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    \n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('main_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "56bb5ba5-bc7c-4e53-e81f-f946d8d01ac6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7e1aa1239d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training dataset loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'main_ACP_train.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mna_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take care the NA sequence problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msequence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpeptide_sequence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('main_ACP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    \n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('main_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'main_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'main_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "HubTATKXslKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142fb5c1-2d19-4a1d-d9ef-54c6057471a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1378, 320)\n",
            "(344, 320)\n",
            "(1378,)\n",
            "(344,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (alternative dataset)"
      ],
      "metadata": {
        "id": "7qxqYf-d_dCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LXftqHY1_iEm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('alternative_ACP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "\n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "\n",
        "embeddings_results.to_csv('alternative_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "VYDJ5sxJ_ilc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('alternative_ACP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "embeddings_results = pd.DataFrame()\n",
        "# embedding all the peptide one by one\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list = []\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    one_seq_embeddings = esm_embeddings(peptide_sequence_list)\n",
        "    embeddings_results= pd.concat([embeddings_results,one_seq_embeddings])\n",
        "    \n",
        "embeddings_results.to_csv('alternative_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "dH3XGmWJ_ifc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'alternative_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'alternative_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I_QVh1hA_ib4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "mk831Klh_iXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63c6001-cc3b-425c-d863-7205a4a8ec56"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1552, 320)\n",
            "(388, 320)\n",
            "(1552,)\n",
            "(388,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf539b9d-42e8-441f-a4a6-be8a0667a144"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "175/175 [==============================] - 3s 12ms/step - loss: 0.9024 - accuracy: 0.8338 - val_loss: 0.3111 - val_accuracy: 0.8718 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2342 - accuracy: 0.9062 - val_loss: 0.3234 - val_accuracy: 0.8526 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2017 - accuracy: 0.9090 - val_loss: 0.2312 - val_accuracy: 0.8782 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1839 - accuracy: 0.9277 - val_loss: 0.2688 - val_accuracy: 0.8718 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1700 - accuracy: 0.9298 - val_loss: 0.2265 - val_accuracy: 0.8846 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1449 - accuracy: 0.9427 - val_loss: 0.2526 - val_accuracy: 0.8846 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1366 - accuracy: 0.9413 - val_loss: 0.3323 - val_accuracy: 0.8782 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1271 - accuracy: 0.9420 - val_loss: 0.2826 - val_accuracy: 0.8846 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1214 - accuracy: 0.9527 - val_loss: 0.2882 - val_accuracy: 0.8718 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1173 - accuracy: 0.9534 - val_loss: 0.3050 - val_accuracy: 0.8782 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1061 - accuracy: 0.9527 - val_loss: 0.3149 - val_accuracy: 0.8846 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0982 - accuracy: 0.9570 - val_loss: 0.2561 - val_accuracy: 0.8846 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0956 - accuracy: 0.9613 - val_loss: 0.3355 - val_accuracy: 0.8782 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0924 - accuracy: 0.9628 - val_loss: 0.2933 - val_accuracy: 0.8846 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0932 - accuracy: 0.9656 - val_loss: 0.2631 - val_accuracy: 0.9038 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0824 - accuracy: 0.9642 - val_loss: 0.3027 - val_accuracy: 0.8782 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0818 - accuracy: 0.9670 - val_loss: 0.3096 - val_accuracy: 0.8782 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0856 - accuracy: 0.9706 - val_loss: 0.2869 - val_accuracy: 0.8974 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0817 - accuracy: 0.9692 - val_loss: 0.2926 - val_accuracy: 0.8910 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0779 - accuracy: 0.9620 - val_loss: 0.2852 - val_accuracy: 0.8974 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0756 - accuracy: 0.9735 - val_loss: 0.2778 - val_accuracy: 0.9038 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0760 - accuracy: 0.9764 - val_loss: 0.2946 - val_accuracy: 0.8910 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0814 - accuracy: 0.9670 - val_loss: 0.2932 - val_accuracy: 0.8910 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0744 - accuracy: 0.9756 - val_loss: 0.2907 - val_accuracy: 0.8910 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0750 - accuracy: 0.9749 - val_loss: 0.2985 - val_accuracy: 0.8910 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0766 - accuracy: 0.9685 - val_loss: 0.3010 - val_accuracy: 0.8846 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0691 - accuracy: 0.9785 - val_loss: 0.2963 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0697 - accuracy: 0.9778 - val_loss: 0.2922 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 13ms/step - loss: 0.0734 - accuracy: 0.9735 - val_loss: 0.2900 - val_accuracy: 0.8974 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 4s 21ms/step - loss: 0.0749 - accuracy: 0.9706 - val_loss: 0.2917 - val_accuracy: 0.8974 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 3s 14ms/step - loss: 0.0737 - accuracy: 0.9756 - val_loss: 0.2907 - val_accuracy: 0.8846 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0681 - accuracy: 0.9742 - val_loss: 0.2965 - val_accuracy: 0.8846 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0736 - accuracy: 0.9721 - val_loss: 0.3012 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0771 - accuracy: 0.9735 - val_loss: 0.2991 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 0.2959 - val_accuracy: 0.8846 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0721 - accuracy: 0.9713 - val_loss: 0.2950 - val_accuracy: 0.8910 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0753 - accuracy: 0.9699 - val_loss: 0.2942 - val_accuracy: 0.8910 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0663 - accuracy: 0.9792 - val_loss: 0.2970 - val_accuracy: 0.8910 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0685 - accuracy: 0.9792 - val_loss: 0.2982 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0705 - accuracy: 0.9735 - val_loss: 0.2976 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.3004 - val_accuracy: 0.8846 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0684 - accuracy: 0.9742 - val_loss: 0.3006 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0676 - accuracy: 0.9742 - val_loss: 0.2998 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0660 - accuracy: 0.9771 - val_loss: 0.3017 - val_accuracy: 0.8846 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0747 - accuracy: 0.9706 - val_loss: 0.3003 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0727 - accuracy: 0.9713 - val_loss: 0.3007 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0754 - accuracy: 0.9721 - val_loss: 0.3008 - val_accuracy: 0.8846 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0698 - accuracy: 0.9728 - val_loss: 0.3003 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0738 - accuracy: 0.9685 - val_loss: 0.3002 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0650 - accuracy: 0.9764 - val_loss: 0.3011 - val_accuracy: 0.8846 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0725 - accuracy: 0.9721 - val_loss: 0.3012 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0697 - accuracy: 0.9756 - val_loss: 0.3014 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0655 - accuracy: 0.9771 - val_loss: 0.3014 - val_accuracy: 0.8846 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0728 - accuracy: 0.9713 - val_loss: 0.3007 - val_accuracy: 0.8846 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9742 - val_loss: 0.3012 - val_accuracy: 0.8846 - lr: 1.0156e-05\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.6371 - accuracy: 0.8245 - val_loss: 0.6947 - val_accuracy: 0.4936 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.2576 - accuracy: 0.8918 - val_loss: 0.5170 - val_accuracy: 0.7500 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1934 - accuracy: 0.9126 - val_loss: 0.2144 - val_accuracy: 0.9167 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1683 - accuracy: 0.9198 - val_loss: 0.2307 - val_accuracy: 0.9103 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1613 - accuracy: 0.9291 - val_loss: 0.2203 - val_accuracy: 0.9295 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1537 - accuracy: 0.9420 - val_loss: 0.2283 - val_accuracy: 0.9359 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1289 - accuracy: 0.9520 - val_loss: 0.2389 - val_accuracy: 0.9231 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1379 - accuracy: 0.9456 - val_loss: 0.2289 - val_accuracy: 0.9295 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1028 - accuracy: 0.9585 - val_loss: 0.2396 - val_accuracy: 0.9295 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1037 - accuracy: 0.9585 - val_loss: 0.2655 - val_accuracy: 0.9359 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0961 - accuracy: 0.9656 - val_loss: 0.2494 - val_accuracy: 0.9423 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0947 - accuracy: 0.9628 - val_loss: 0.2426 - val_accuracy: 0.9295 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0847 - accuracy: 0.9649 - val_loss: 0.2250 - val_accuracy: 0.9295 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0775 - accuracy: 0.9721 - val_loss: 0.2250 - val_accuracy: 0.9423 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0738 - accuracy: 0.9764 - val_loss: 0.2348 - val_accuracy: 0.9423 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0725 - accuracy: 0.9728 - val_loss: 0.2387 - val_accuracy: 0.9423 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0655 - accuracy: 0.9742 - val_loss: 0.2372 - val_accuracy: 0.9423 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0610 - accuracy: 0.9764 - val_loss: 0.2388 - val_accuracy: 0.9423 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0629 - accuracy: 0.9771 - val_loss: 0.2356 - val_accuracy: 0.9423 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0579 - accuracy: 0.9799 - val_loss: 0.2432 - val_accuracy: 0.9423 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0650 - accuracy: 0.9742 - val_loss: 0.2461 - val_accuracy: 0.9423 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0602 - accuracy: 0.9778 - val_loss: 0.2522 - val_accuracy: 0.9359 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0540 - accuracy: 0.9828 - val_loss: 0.2529 - val_accuracy: 0.9423 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0649 - accuracy: 0.9749 - val_loss: 0.2490 - val_accuracy: 0.9423 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 7s 41ms/step - loss: 0.0593 - accuracy: 0.9785 - val_loss: 0.2543 - val_accuracy: 0.9423 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 10s 59ms/step - loss: 0.0615 - accuracy: 0.9756 - val_loss: 0.2460 - val_accuracy: 0.9359 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 4s 23ms/step - loss: 0.0583 - accuracy: 0.9799 - val_loss: 0.2484 - val_accuracy: 0.9359 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 0.2452 - val_accuracy: 0.9423 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 0.2441 - val_accuracy: 0.9423 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0534 - accuracy: 0.9799 - val_loss: 0.2469 - val_accuracy: 0.9423 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.2478 - val_accuracy: 0.9423 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0550 - accuracy: 0.9799 - val_loss: 0.2482 - val_accuracy: 0.9423 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0532 - accuracy: 0.9807 - val_loss: 0.2485 - val_accuracy: 0.9423 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0533 - accuracy: 0.9807 - val_loss: 0.2478 - val_accuracy: 0.9423 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0546 - accuracy: 0.9792 - val_loss: 0.2488 - val_accuracy: 0.9423 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0645 - accuracy: 0.9756 - val_loss: 0.2483 - val_accuracy: 0.9423 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0529 - accuracy: 0.9828 - val_loss: 0.2483 - val_accuracy: 0.9423 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.2494 - val_accuracy: 0.9423 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0581 - accuracy: 0.9771 - val_loss: 0.2490 - val_accuracy: 0.9423 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 0.2492 - val_accuracy: 0.9423 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0609 - accuracy: 0.9771 - val_loss: 0.2492 - val_accuracy: 0.9423 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0521 - accuracy: 0.9807 - val_loss: 0.2493 - val_accuracy: 0.9423 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0570 - accuracy: 0.9785 - val_loss: 0.2488 - val_accuracy: 0.9423 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 0.2500 - val_accuracy: 0.9423 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 0.2494 - val_accuracy: 0.9423 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0564 - accuracy: 0.9821 - val_loss: 0.2491 - val_accuracy: 0.9423 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0491 - accuracy: 0.9828 - val_loss: 0.2493 - val_accuracy: 0.9423 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0578 - accuracy: 0.9785 - val_loss: 0.2497 - val_accuracy: 0.9423 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.2497 - val_accuracy: 0.9423 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0477 - accuracy: 0.9857 - val_loss: 0.2496 - val_accuracy: 0.9423 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 0.2495 - val_accuracy: 0.9423 - lr: 1.6927e-05\n",
            "156/156 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 13ms/step - loss: 0.5047 - accuracy: 0.8039 - val_loss: 0.9278 - val_accuracy: 0.5419 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.3018 - accuracy: 0.8762 - val_loss: 0.6437 - val_accuracy: 0.5871 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2575 - accuracy: 0.9019 - val_loss: 0.2047 - val_accuracy: 0.9419 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2172 - accuracy: 0.9112 - val_loss: 0.1333 - val_accuracy: 0.9613 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2049 - accuracy: 0.9127 - val_loss: 0.1905 - val_accuracy: 0.9548 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1787 - accuracy: 0.9313 - val_loss: 0.1508 - val_accuracy: 0.9484 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 3s 19ms/step - loss: 0.1641 - accuracy: 0.9377 - val_loss: 0.1254 - val_accuracy: 0.9548 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1612 - accuracy: 0.9377 - val_loss: 0.1219 - val_accuracy: 0.9484 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1411 - accuracy: 0.9463 - val_loss: 0.1159 - val_accuracy: 0.9484 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1288 - accuracy: 0.9499 - val_loss: 0.1140 - val_accuracy: 0.9613 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1213 - accuracy: 0.9549 - val_loss: 0.1541 - val_accuracy: 0.9419 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1112 - accuracy: 0.9556 - val_loss: 0.1526 - val_accuracy: 0.9419 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1137 - accuracy: 0.9513 - val_loss: 0.1481 - val_accuracy: 0.9484 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1100 - accuracy: 0.9599 - val_loss: 0.1547 - val_accuracy: 0.9484 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1031 - accuracy: 0.9656 - val_loss: 0.1526 - val_accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1171 - accuracy: 0.9535 - val_loss: 0.1391 - val_accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0990 - accuracy: 0.9635 - val_loss: 0.1230 - val_accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0955 - accuracy: 0.9621 - val_loss: 0.1143 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0927 - accuracy: 0.9671 - val_loss: 0.1315 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0955 - accuracy: 0.9671 - val_loss: 0.1434 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0935 - accuracy: 0.9678 - val_loss: 0.1437 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0891 - accuracy: 0.9671 - val_loss: 0.1387 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0833 - accuracy: 0.9699 - val_loss: 0.1502 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0932 - accuracy: 0.9642 - val_loss: 0.1366 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0865 - accuracy: 0.9678 - val_loss: 0.1441 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0895 - accuracy: 0.9678 - val_loss: 0.1520 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0810 - accuracy: 0.9699 - val_loss: 0.1500 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0825 - accuracy: 0.9656 - val_loss: 0.1502 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0840 - accuracy: 0.9685 - val_loss: 0.1437 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0889 - accuracy: 0.9621 - val_loss: 0.1470 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0853 - accuracy: 0.9699 - val_loss: 0.1450 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0821 - accuracy: 0.9721 - val_loss: 0.1407 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0870 - accuracy: 0.9692 - val_loss: 0.1449 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0820 - accuracy: 0.9678 - val_loss: 0.1448 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0879 - accuracy: 0.9678 - val_loss: 0.1409 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0800 - accuracy: 0.9707 - val_loss: 0.1440 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0845 - accuracy: 0.9699 - val_loss: 0.1436 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0793 - accuracy: 0.9721 - val_loss: 0.1459 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0828 - accuracy: 0.9714 - val_loss: 0.1458 - val_accuracy: 0.9548 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0883 - accuracy: 0.9664 - val_loss: 0.1452 - val_accuracy: 0.9548 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0874 - accuracy: 0.9642 - val_loss: 0.1438 - val_accuracy: 0.9548 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.1437 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 0.1437 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0825 - accuracy: 0.9685 - val_loss: 0.1451 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.7212 - accuracy: 0.8690 - val_loss: 0.4514 - val_accuracy: 0.8129 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2234 - accuracy: 0.9177 - val_loss: 0.2976 - val_accuracy: 0.8645 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1787 - accuracy: 0.9284 - val_loss: 0.2817 - val_accuracy: 0.8774 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1614 - accuracy: 0.9384 - val_loss: 0.2743 - val_accuracy: 0.8903 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.1554 - accuracy: 0.9384 - val_loss: 0.2170 - val_accuracy: 0.9032 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1301 - accuracy: 0.9392 - val_loss: 0.2623 - val_accuracy: 0.8968 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1213 - accuracy: 0.9542 - val_loss: 0.2217 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1123 - accuracy: 0.9628 - val_loss: 0.2256 - val_accuracy: 0.9097 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0989 - accuracy: 0.9606 - val_loss: 0.2939 - val_accuracy: 0.8903 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.2251 - val_accuracy: 0.9032 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0866 - accuracy: 0.9656 - val_loss: 0.2510 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0850 - accuracy: 0.9692 - val_loss: 0.2247 - val_accuracy: 0.9161 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.2481 - val_accuracy: 0.9161 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0750 - accuracy: 0.9742 - val_loss: 0.2333 - val_accuracy: 0.9161 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0583 - accuracy: 0.9807 - val_loss: 0.2344 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0707 - accuracy: 0.9735 - val_loss: 0.2119 - val_accuracy: 0.9226 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0667 - accuracy: 0.9771 - val_loss: 0.2270 - val_accuracy: 0.9161 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0669 - accuracy: 0.9785 - val_loss: 0.2339 - val_accuracy: 0.9226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0622 - accuracy: 0.9771 - val_loss: 0.2285 - val_accuracy: 0.9161 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.2351 - val_accuracy: 0.9161 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0607 - accuracy: 0.9792 - val_loss: 0.2311 - val_accuracy: 0.9161 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0578 - accuracy: 0.9792 - val_loss: 0.2282 - val_accuracy: 0.9161 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0560 - accuracy: 0.9807 - val_loss: 0.2273 - val_accuracy: 0.9161 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0533 - accuracy: 0.9800 - val_loss: 0.2283 - val_accuracy: 0.9161 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0608 - accuracy: 0.9785 - val_loss: 0.2274 - val_accuracy: 0.9161 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0564 - accuracy: 0.9757 - val_loss: 0.2261 - val_accuracy: 0.9161 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0608 - accuracy: 0.9764 - val_loss: 0.2304 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0562 - accuracy: 0.9778 - val_loss: 0.2306 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0606 - accuracy: 0.9821 - val_loss: 0.2311 - val_accuracy: 0.9161 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0550 - accuracy: 0.9800 - val_loss: 0.2296 - val_accuracy: 0.9161 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0596 - accuracy: 0.9742 - val_loss: 0.2278 - val_accuracy: 0.9161 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0527 - accuracy: 0.9814 - val_loss: 0.2295 - val_accuracy: 0.9161 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0607 - accuracy: 0.9814 - val_loss: 0.2290 - val_accuracy: 0.9161 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0526 - accuracy: 0.9835 - val_loss: 0.2292 - val_accuracy: 0.9161 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.2285 - val_accuracy: 0.9161 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0566 - accuracy: 0.9814 - val_loss: 0.2275 - val_accuracy: 0.9161 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.2281 - val_accuracy: 0.9161 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0576 - accuracy: 0.9785 - val_loss: 0.2282 - val_accuracy: 0.9161 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0541 - accuracy: 0.9792 - val_loss: 0.2282 - val_accuracy: 0.9161 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0649 - accuracy: 0.9764 - val_loss: 0.2282 - val_accuracy: 0.9161 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0563 - accuracy: 0.9757 - val_loss: 0.2280 - val_accuracy: 0.9161 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0558 - accuracy: 0.9807 - val_loss: 0.2277 - val_accuracy: 0.9161 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0593 - accuracy: 0.9771 - val_loss: 0.2275 - val_accuracy: 0.9161 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0538 - accuracy: 0.9778 - val_loss: 0.2274 - val_accuracy: 0.9161 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0507 - accuracy: 0.9828 - val_loss: 0.2281 - val_accuracy: 0.9161 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0561 - accuracy: 0.9800 - val_loss: 0.2282 - val_accuracy: 0.9161 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0601 - accuracy: 0.9764 - val_loss: 0.2278 - val_accuracy: 0.9161 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0585 - accuracy: 0.9785 - val_loss: 0.2279 - val_accuracy: 0.9161 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0603 - accuracy: 0.9792 - val_loss: 0.2265 - val_accuracy: 0.9161 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 0.9792 - val_loss: 0.2272 - val_accuracy: 0.9161 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0526 - accuracy: 0.9792 - val_loss: 0.2274 - val_accuracy: 0.9161 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0628 - accuracy: 0.9764 - val_loss: 0.2278 - val_accuracy: 0.9161 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0481 - accuracy: 0.9828 - val_loss: 0.2273 - val_accuracy: 0.9161 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 0.2270 - val_accuracy: 0.9161 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0464 - accuracy: 0.9821 - val_loss: 0.2275 - val_accuracy: 0.9161 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0519 - accuracy: 0.9800 - val_loss: 0.2278 - val_accuracy: 0.9161 - lr: 1.0156e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.7430 - accuracy: 0.8139 - val_loss: 0.6376 - val_accuracy: 0.5355 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2438 - accuracy: 0.8919 - val_loss: 0.3218 - val_accuracy: 0.8839 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1940 - accuracy: 0.9141 - val_loss: 0.2452 - val_accuracy: 0.8839 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1857 - accuracy: 0.9241 - val_loss: 0.2011 - val_accuracy: 0.9032 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1766 - accuracy: 0.9256 - val_loss: 0.2604 - val_accuracy: 0.8839 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1476 - accuracy: 0.9406 - val_loss: 0.2024 - val_accuracy: 0.8968 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1301 - accuracy: 0.9499 - val_loss: 0.2213 - val_accuracy: 0.8968 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1319 - accuracy: 0.9470 - val_loss: 0.1672 - val_accuracy: 0.9226 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1171 - accuracy: 0.9542 - val_loss: 0.1812 - val_accuracy: 0.9355 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1039 - accuracy: 0.9628 - val_loss: 0.1564 - val_accuracy: 0.9419 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1123 - accuracy: 0.9585 - val_loss: 0.2461 - val_accuracy: 0.9032 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.1035 - accuracy: 0.9628 - val_loss: 0.1819 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 3s 19ms/step - loss: 0.0954 - accuracy: 0.9592 - val_loss: 0.2134 - val_accuracy: 0.9226 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 13ms/step - loss: 0.0990 - accuracy: 0.9635 - val_loss: 0.1627 - val_accuracy: 0.9484 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0930 - accuracy: 0.9635 - val_loss: 0.1715 - val_accuracy: 0.9419 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0830 - accuracy: 0.9685 - val_loss: 0.1651 - val_accuracy: 0.9484 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0844 - accuracy: 0.9664 - val_loss: 0.1720 - val_accuracy: 0.9419 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0755 - accuracy: 0.9678 - val_loss: 0.1652 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0810 - accuracy: 0.9664 - val_loss: 0.1785 - val_accuracy: 0.9419 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0781 - accuracy: 0.9692 - val_loss: 0.1642 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0740 - accuracy: 0.9714 - val_loss: 0.1669 - val_accuracy: 0.9419 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0816 - accuracy: 0.9699 - val_loss: 0.1617 - val_accuracy: 0.9484 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 0.1746 - val_accuracy: 0.9355 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0789 - accuracy: 0.9685 - val_loss: 0.1744 - val_accuracy: 0.9355 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0725 - accuracy: 0.9728 - val_loss: 0.1740 - val_accuracy: 0.9355 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0802 - accuracy: 0.9649 - val_loss: 0.1752 - val_accuracy: 0.9419 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0736 - accuracy: 0.9714 - val_loss: 0.1712 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0700 - accuracy: 0.9735 - val_loss: 0.1715 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0733 - accuracy: 0.9728 - val_loss: 0.1737 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0699 - accuracy: 0.9735 - val_loss: 0.1733 - val_accuracy: 0.9419 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0704 - accuracy: 0.9757 - val_loss: 0.1717 - val_accuracy: 0.9419 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0686 - accuracy: 0.9685 - val_loss: 0.1724 - val_accuracy: 0.9419 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0647 - accuracy: 0.9757 - val_loss: 0.1719 - val_accuracy: 0.9419 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0711 - accuracy: 0.9757 - val_loss: 0.1745 - val_accuracy: 0.9355 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0669 - accuracy: 0.9742 - val_loss: 0.1758 - val_accuracy: 0.9355 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9728 - val_loss: 0.1755 - val_accuracy: 0.9355 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0714 - accuracy: 0.9728 - val_loss: 0.1749 - val_accuracy: 0.9355 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0680 - accuracy: 0.9742 - val_loss: 0.1744 - val_accuracy: 0.9419 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0692 - accuracy: 0.9699 - val_loss: 0.1739 - val_accuracy: 0.9419 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0664 - accuracy: 0.9735 - val_loss: 0.1733 - val_accuracy: 0.9419 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.1729 - val_accuracy: 0.9419 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0742 - accuracy: 0.9742 - val_loss: 0.1731 - val_accuracy: 0.9419 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0708 - accuracy: 0.9735 - val_loss: 0.1730 - val_accuracy: 0.9419 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0743 - accuracy: 0.9707 - val_loss: 0.1720 - val_accuracy: 0.9419 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0664 - accuracy: 0.9771 - val_loss: 0.1726 - val_accuracy: 0.9419 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0684 - accuracy: 0.9735 - val_loss: 0.1730 - val_accuracy: 0.9419 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0729 - accuracy: 0.9742 - val_loss: 0.1731 - val_accuracy: 0.9419 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9757 - val_loss: 0.1731 - val_accuracy: 0.9419 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0734 - accuracy: 0.9707 - val_loss: 0.1730 - val_accuracy: 0.9419 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0723 - accuracy: 0.9692 - val_loss: 0.1724 - val_accuracy: 0.9419 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0759 - accuracy: 0.9685 - val_loss: 0.1723 - val_accuracy: 0.9419 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0670 - accuracy: 0.9749 - val_loss: 0.1728 - val_accuracy: 0.9419 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0752 - accuracy: 0.9692 - val_loss: 0.1728 - val_accuracy: 0.9419 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.1726 - val_accuracy: 0.9419 - lr: 1.0156e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 13ms/step - loss: 0.6375 - accuracy: 0.8182 - val_loss: 0.6740 - val_accuracy: 0.5677 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2457 - accuracy: 0.8955 - val_loss: 0.4738 - val_accuracy: 0.8323 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1984 - accuracy: 0.9084 - val_loss: 0.3140 - val_accuracy: 0.8968 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1684 - accuracy: 0.9277 - val_loss: 0.2522 - val_accuracy: 0.8710 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1714 - accuracy: 0.9270 - val_loss: 0.3015 - val_accuracy: 0.8839 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1532 - accuracy: 0.9392 - val_loss: 0.2512 - val_accuracy: 0.9032 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1334 - accuracy: 0.9449 - val_loss: 0.2429 - val_accuracy: 0.9032 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1183 - accuracy: 0.9477 - val_loss: 0.2686 - val_accuracy: 0.8839 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1115 - accuracy: 0.9571 - val_loss: 0.2700 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1052 - accuracy: 0.9585 - val_loss: 0.2973 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1010 - accuracy: 0.9613 - val_loss: 0.2760 - val_accuracy: 0.9097 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0846 - accuracy: 0.9721 - val_loss: 0.3243 - val_accuracy: 0.8903 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0865 - accuracy: 0.9664 - val_loss: 0.2667 - val_accuracy: 0.9032 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0803 - accuracy: 0.9685 - val_loss: 0.3063 - val_accuracy: 0.9032 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0790 - accuracy: 0.9692 - val_loss: 0.2795 - val_accuracy: 0.9032 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 0.2947 - val_accuracy: 0.9032 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0740 - accuracy: 0.9721 - val_loss: 0.3033 - val_accuracy: 0.9097 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 0.3027 - val_accuracy: 0.9032 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0683 - accuracy: 0.9785 - val_loss: 0.3014 - val_accuracy: 0.9097 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0653 - accuracy: 0.9749 - val_loss: 0.3277 - val_accuracy: 0.9032 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0669 - accuracy: 0.9742 - val_loss: 0.3166 - val_accuracy: 0.9032 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0664 - accuracy: 0.9735 - val_loss: 0.3123 - val_accuracy: 0.9097 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0634 - accuracy: 0.9771 - val_loss: 0.3081 - val_accuracy: 0.9161 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0616 - accuracy: 0.9785 - val_loss: 0.3137 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.3222 - val_accuracy: 0.9097 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0554 - accuracy: 0.9828 - val_loss: 0.3254 - val_accuracy: 0.9032 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0588 - accuracy: 0.9814 - val_loss: 0.3216 - val_accuracy: 0.9097 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 0.3233 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0523 - accuracy: 0.9821 - val_loss: 0.3306 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0633 - accuracy: 0.9778 - val_loss: 0.3244 - val_accuracy: 0.9032 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.3248 - val_accuracy: 0.9032 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 0.3298 - val_accuracy: 0.9032 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0575 - accuracy: 0.9814 - val_loss: 0.3262 - val_accuracy: 0.9032 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0635 - accuracy: 0.9771 - val_loss: 0.3246 - val_accuracy: 0.9097 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0540 - accuracy: 0.9785 - val_loss: 0.3239 - val_accuracy: 0.9097 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0585 - accuracy: 0.9814 - val_loss: 0.3259 - val_accuracy: 0.9032 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0596 - accuracy: 0.9771 - val_loss: 0.3268 - val_accuracy: 0.9032 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0601 - accuracy: 0.9764 - val_loss: 0.3277 - val_accuracy: 0.9032 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0573 - accuracy: 0.9792 - val_loss: 0.3290 - val_accuracy: 0.9032 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.3281 - val_accuracy: 0.9032 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0542 - accuracy: 0.9828 - val_loss: 0.3280 - val_accuracy: 0.9032 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0624 - accuracy: 0.9749 - val_loss: 0.3281 - val_accuracy: 0.9032 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0557 - accuracy: 0.9807 - val_loss: 0.3283 - val_accuracy: 0.9032 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0580 - accuracy: 0.9792 - val_loss: 0.3288 - val_accuracy: 0.9032 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0612 - accuracy: 0.9764 - val_loss: 0.3285 - val_accuracy: 0.9032 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0598 - accuracy: 0.9749 - val_loss: 0.3275 - val_accuracy: 0.9032 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0558 - accuracy: 0.9771 - val_loss: 0.3274 - val_accuracy: 0.9032 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0528 - accuracy: 0.9828 - val_loss: 0.3277 - val_accuracy: 0.9032 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0664 - accuracy: 0.9721 - val_loss: 0.3278 - val_accuracy: 0.9032 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0587 - accuracy: 0.9778 - val_loss: 0.3272 - val_accuracy: 0.9032 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0558 - accuracy: 0.9814 - val_loss: 0.3275 - val_accuracy: 0.9032 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0625 - accuracy: 0.9771 - val_loss: 0.3273 - val_accuracy: 0.9032 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "175/175 [==============================] - 3s 20ms/step - loss: 0.0596 - accuracy: 0.9785 - val_loss: 0.3274 - val_accuracy: 0.9032 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "175/175 [==============================] - 3s 16ms/step - loss: 0.0592 - accuracy: 0.9764 - val_loss: 0.3274 - val_accuracy: 0.9032 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0660 - accuracy: 0.9764 - val_loss: 0.3271 - val_accuracy: 0.9032 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "175/175 [==============================] - 2s 12ms/step - loss: 0.0597 - accuracy: 0.9749 - val_loss: 0.3275 - val_accuracy: 0.9032 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.3273 - val_accuracy: 0.9032 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0562 - accuracy: 0.9785 - val_loss: 0.3272 - val_accuracy: 0.9032 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0592 - accuracy: 0.9792 - val_loss: 0.3272 - val_accuracy: 0.9032 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0571 - accuracy: 0.9814 - val_loss: 0.3272 - val_accuracy: 0.9032 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0563 - accuracy: 0.9807 - val_loss: 0.3270 - val_accuracy: 0.9032 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0569 - accuracy: 0.9792 - val_loss: 0.3271 - val_accuracy: 0.9032 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0575 - accuracy: 0.9792 - val_loss: 0.3274 - val_accuracy: 0.9032 - lr: 2.1937e-06\n",
            "155/155 [==============================] - 1s 3ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.6859 - accuracy: 0.8397 - val_loss: 0.6817 - val_accuracy: 0.5161 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.2325 - accuracy: 0.9091 - val_loss: 0.3783 - val_accuracy: 0.9161 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1753 - accuracy: 0.9191 - val_loss: 0.1912 - val_accuracy: 0.9484 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1671 - accuracy: 0.9298 - val_loss: 0.2003 - val_accuracy: 0.9355 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1516 - accuracy: 0.9392 - val_loss: 0.2123 - val_accuracy: 0.9290 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1199 - accuracy: 0.9563 - val_loss: 0.2216 - val_accuracy: 0.9613 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1040 - accuracy: 0.9592 - val_loss: 0.2087 - val_accuracy: 0.9419 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0993 - accuracy: 0.9606 - val_loss: 0.2720 - val_accuracy: 0.9355 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0860 - accuracy: 0.9699 - val_loss: 0.2379 - val_accuracy: 0.9613 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0861 - accuracy: 0.9692 - val_loss: 0.2589 - val_accuracy: 0.9548 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0775 - accuracy: 0.9714 - val_loss: 0.2297 - val_accuracy: 0.9548 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0717 - accuracy: 0.9721 - val_loss: 0.2489 - val_accuracy: 0.9613 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0616 - accuracy: 0.9828 - val_loss: 0.2558 - val_accuracy: 0.9548 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0692 - accuracy: 0.9742 - val_loss: 0.2643 - val_accuracy: 0.9548 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0615 - accuracy: 0.9785 - val_loss: 0.2528 - val_accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0539 - accuracy: 0.9785 - val_loss: 0.2751 - val_accuracy: 0.9484 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0578 - accuracy: 0.9807 - val_loss: 0.2674 - val_accuracy: 0.9548 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.2735 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.2710 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0498 - accuracy: 0.9821 - val_loss: 0.2784 - val_accuracy: 0.9548 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.2827 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.2865 - val_accuracy: 0.9484 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0447 - accuracy: 0.9871 - val_loss: 0.2874 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0443 - accuracy: 0.9843 - val_loss: 0.2916 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 0.2854 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0415 - accuracy: 0.9871 - val_loss: 0.2918 - val_accuracy: 0.9548 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0428 - accuracy: 0.9835 - val_loss: 0.2902 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0467 - accuracy: 0.9850 - val_loss: 0.2898 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0396 - accuracy: 0.9857 - val_loss: 0.2901 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0447 - accuracy: 0.9814 - val_loss: 0.2907 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0476 - accuracy: 0.9821 - val_loss: 0.2910 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 0.2900 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0423 - accuracy: 0.9843 - val_loss: 0.2900 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0497 - accuracy: 0.9821 - val_loss: 0.2905 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0453 - accuracy: 0.9857 - val_loss: 0.2909 - val_accuracy: 0.9484 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 0.2929 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0488 - accuracy: 0.9828 - val_loss: 0.2916 - val_accuracy: 0.9484 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0433 - accuracy: 0.9843 - val_loss: 0.2932 - val_accuracy: 0.9484 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0446 - accuracy: 0.9843 - val_loss: 0.2900 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0371 - accuracy: 0.9900 - val_loss: 0.2917 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0433 - accuracy: 0.9864 - val_loss: 0.2922 - val_accuracy: 0.9548 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.2924 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0417 - accuracy: 0.9857 - val_loss: 0.2917 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0415 - accuracy: 0.9878 - val_loss: 0.2908 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0369 - accuracy: 0.9878 - val_loss: 0.2907 - val_accuracy: 0.9548 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0516 - accuracy: 0.9814 - val_loss: 0.2909 - val_accuracy: 0.9548 - lr: 4.7018e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.5851 - accuracy: 0.8268 - val_loss: 0.8161 - val_accuracy: 0.4581 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.2547 - accuracy: 0.8991 - val_loss: 0.7292 - val_accuracy: 0.4581 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.2066 - accuracy: 0.9141 - val_loss: 0.2589 - val_accuracy: 0.9226 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1974 - accuracy: 0.9127 - val_loss: 0.1701 - val_accuracy: 0.9484 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1817 - accuracy: 0.9241 - val_loss: 0.1489 - val_accuracy: 0.9355 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1559 - accuracy: 0.9313 - val_loss: 0.1381 - val_accuracy: 0.9484 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1518 - accuracy: 0.9320 - val_loss: 0.1718 - val_accuracy: 0.9419 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1346 - accuracy: 0.9420 - val_loss: 0.1472 - val_accuracy: 0.9290 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1170 - accuracy: 0.9528 - val_loss: 0.1581 - val_accuracy: 0.9419 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1088 - accuracy: 0.9563 - val_loss: 0.1515 - val_accuracy: 0.9419 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1088 - accuracy: 0.9571 - val_loss: 0.1428 - val_accuracy: 0.9419 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1006 - accuracy: 0.9592 - val_loss: 0.1501 - val_accuracy: 0.9290 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0927 - accuracy: 0.9599 - val_loss: 0.1627 - val_accuracy: 0.9419 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0888 - accuracy: 0.9613 - val_loss: 0.1630 - val_accuracy: 0.9419 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0827 - accuracy: 0.9671 - val_loss: 0.1524 - val_accuracy: 0.9419 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0775 - accuracy: 0.9656 - val_loss: 0.1580 - val_accuracy: 0.9355 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0787 - accuracy: 0.9692 - val_loss: 0.1558 - val_accuracy: 0.9484 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0726 - accuracy: 0.9714 - val_loss: 0.1540 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0745 - accuracy: 0.9728 - val_loss: 0.1555 - val_accuracy: 0.9419 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0769 - accuracy: 0.9707 - val_loss: 0.1498 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0712 - accuracy: 0.9749 - val_loss: 0.1453 - val_accuracy: 0.9419 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0690 - accuracy: 0.9714 - val_loss: 0.1533 - val_accuracy: 0.9484 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0717 - accuracy: 0.9757 - val_loss: 0.1528 - val_accuracy: 0.9355 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0591 - accuracy: 0.9764 - val_loss: 0.1496 - val_accuracy: 0.9419 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0673 - accuracy: 0.9749 - val_loss: 0.1552 - val_accuracy: 0.9484 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0650 - accuracy: 0.9771 - val_loss: 0.1555 - val_accuracy: 0.9484 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0676 - accuracy: 0.9728 - val_loss: 0.1528 - val_accuracy: 0.9419 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0636 - accuracy: 0.9792 - val_loss: 0.1536 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0710 - accuracy: 0.9735 - val_loss: 0.1569 - val_accuracy: 0.9548 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0616 - accuracy: 0.9771 - val_loss: 0.1545 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0621 - accuracy: 0.9771 - val_loss: 0.1544 - val_accuracy: 0.9548 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9749 - val_loss: 0.1563 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0599 - accuracy: 0.9764 - val_loss: 0.1558 - val_accuracy: 0.9484 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0591 - accuracy: 0.9800 - val_loss: 0.1576 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.1572 - val_accuracy: 0.9548 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0691 - accuracy: 0.9721 - val_loss: 0.1562 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0682 - accuracy: 0.9721 - val_loss: 0.1569 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9778 - val_loss: 0.1562 - val_accuracy: 0.9548 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0605 - accuracy: 0.9771 - val_loss: 0.1567 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0641 - accuracy: 0.9778 - val_loss: 0.1564 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0604 - accuracy: 0.9792 - val_loss: 0.1565 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0597 - accuracy: 0.9764 - val_loss: 0.1563 - val_accuracy: 0.9484 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0632 - accuracy: 0.9764 - val_loss: 0.1561 - val_accuracy: 0.9484 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0582 - accuracy: 0.9814 - val_loss: 0.1565 - val_accuracy: 0.9548 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0643 - accuracy: 0.9721 - val_loss: 0.1569 - val_accuracy: 0.9548 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 0.9764 - val_loss: 0.1568 - val_accuracy: 0.9548 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0626 - accuracy: 0.9792 - val_loss: 0.1564 - val_accuracy: 0.9548 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0689 - accuracy: 0.9742 - val_loss: 0.1565 - val_accuracy: 0.9548 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 0.1570 - val_accuracy: 0.9548 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9721 - val_loss: 0.1570 - val_accuracy: 0.9548 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "175/175 [==============================] - 3s 14ms/step - loss: 0.0580 - accuracy: 0.9778 - val_loss: 0.1567 - val_accuracy: 0.9548 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "175/175 [==============================] - 3s 18ms/step - loss: 0.0609 - accuracy: 0.9742 - val_loss: 0.1562 - val_accuracy: 0.9548 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "175/175 [==============================] - 2s 14ms/step - loss: 0.0618 - accuracy: 0.9757 - val_loss: 0.1572 - val_accuracy: 0.9484 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0687 - accuracy: 0.9721 - val_loss: 0.1561 - val_accuracy: 0.9548 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0656 - accuracy: 0.9735 - val_loss: 0.1560 - val_accuracy: 0.9548 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0599 - accuracy: 0.9785 - val_loss: 0.1567 - val_accuracy: 0.9548 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0653 - accuracy: 0.9749 - val_loss: 0.1570 - val_accuracy: 0.9548 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0644 - accuracy: 0.9757 - val_loss: 0.1567 - val_accuracy: 0.9548 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0670 - accuracy: 0.9778 - val_loss: 0.1566 - val_accuracy: 0.9548 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0673 - accuracy: 0.9742 - val_loss: 0.1565 - val_accuracy: 0.9548 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0644 - accuracy: 0.9771 - val_loss: 0.1569 - val_accuracy: 0.9548 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0586 - accuracy: 0.9792 - val_loss: 0.1561 - val_accuracy: 0.9548 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0616 - accuracy: 0.9757 - val_loss: 0.1559 - val_accuracy: 0.9548 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0617 - accuracy: 0.9771 - val_loss: 0.1567 - val_accuracy: 0.9548 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0644 - accuracy: 0.9721 - val_loss: 0.1559 - val_accuracy: 0.9548 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0630 - accuracy: 0.9757 - val_loss: 0.1564 - val_accuracy: 0.9548 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0626 - accuracy: 0.9800 - val_loss: 0.1564 - val_accuracy: 0.9548 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0608 - accuracy: 0.9800 - val_loss: 0.1562 - val_accuracy: 0.9548 - lr: 1.3162e-06\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.8562 - accuracy: 0.8468 - val_loss: 0.6656 - val_accuracy: 0.6387 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2396 - accuracy: 0.9019 - val_loss: 0.2875 - val_accuracy: 0.8516 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1866 - accuracy: 0.9284 - val_loss: 0.2188 - val_accuracy: 0.8968 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1756 - accuracy: 0.9298 - val_loss: 0.2261 - val_accuracy: 0.8839 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1631 - accuracy: 0.9406 - val_loss: 0.2419 - val_accuracy: 0.8839 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1301 - accuracy: 0.9485 - val_loss: 0.2451 - val_accuracy: 0.8968 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1281 - accuracy: 0.9520 - val_loss: 0.2738 - val_accuracy: 0.8903 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1194 - accuracy: 0.9578 - val_loss: 0.2604 - val_accuracy: 0.8903 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1044 - accuracy: 0.9621 - val_loss: 0.2778 - val_accuracy: 0.8968 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1001 - accuracy: 0.9628 - val_loss: 0.2416 - val_accuracy: 0.9032 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0952 - accuracy: 0.9628 - val_loss: 0.2626 - val_accuracy: 0.8968 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0951 - accuracy: 0.9649 - val_loss: 0.2761 - val_accuracy: 0.8968 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0884 - accuracy: 0.9642 - val_loss: 0.2653 - val_accuracy: 0.8968 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0831 - accuracy: 0.9714 - val_loss: 0.2670 - val_accuracy: 0.9032 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0726 - accuracy: 0.9742 - val_loss: 0.2737 - val_accuracy: 0.9032 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0747 - accuracy: 0.9728 - val_loss: 0.2833 - val_accuracy: 0.9032 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0743 - accuracy: 0.9714 - val_loss: 0.2772 - val_accuracy: 0.8903 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9821 - val_loss: 0.2815 - val_accuracy: 0.8968 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0697 - accuracy: 0.9771 - val_loss: 0.2776 - val_accuracy: 0.8968 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0563 - accuracy: 0.9807 - val_loss: 0.2990 - val_accuracy: 0.8968 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0683 - accuracy: 0.9735 - val_loss: 0.2966 - val_accuracy: 0.8968 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0647 - accuracy: 0.9792 - val_loss: 0.2969 - val_accuracy: 0.8968 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0605 - accuracy: 0.9807 - val_loss: 0.2885 - val_accuracy: 0.8968 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0614 - accuracy: 0.9814 - val_loss: 0.2913 - val_accuracy: 0.8968 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0672 - accuracy: 0.9757 - val_loss: 0.2881 - val_accuracy: 0.8968 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0621 - accuracy: 0.9785 - val_loss: 0.2859 - val_accuracy: 0.8968 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0638 - accuracy: 0.9814 - val_loss: 0.2868 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.2912 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0607 - accuracy: 0.9821 - val_loss: 0.2951 - val_accuracy: 0.8968 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 0.2950 - val_accuracy: 0.8968 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0639 - accuracy: 0.9742 - val_loss: 0.2928 - val_accuracy: 0.8968 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0622 - accuracy: 0.9778 - val_loss: 0.2957 - val_accuracy: 0.8968 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0594 - accuracy: 0.9792 - val_loss: 0.2974 - val_accuracy: 0.8968 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0619 - accuracy: 0.9771 - val_loss: 0.2965 - val_accuracy: 0.8968 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.2976 - val_accuracy: 0.8968 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.2981 - val_accuracy: 0.8968 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0655 - accuracy: 0.9785 - val_loss: 0.2986 - val_accuracy: 0.8968 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 0.2984 - val_accuracy: 0.8968 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0597 - accuracy: 0.9792 - val_loss: 0.2978 - val_accuracy: 0.8968 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0666 - accuracy: 0.9778 - val_loss: 0.2980 - val_accuracy: 0.8968 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0660 - accuracy: 0.9742 - val_loss: 0.2977 - val_accuracy: 0.8968 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0637 - accuracy: 0.9785 - val_loss: 0.2980 - val_accuracy: 0.8968 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0636 - accuracy: 0.9764 - val_loss: 0.2981 - val_accuracy: 0.8968 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0603 - accuracy: 0.9764 - val_loss: 0.2986 - val_accuracy: 0.8968 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.2985 - val_accuracy: 0.8968 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0654 - accuracy: 0.9757 - val_loss: 0.2982 - val_accuracy: 0.8968 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0607 - accuracy: 0.9828 - val_loss: 0.2982 - val_accuracy: 0.8968 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9807 - val_loss: 0.2982 - val_accuracy: 0.8968 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0549 - accuracy: 0.9807 - val_loss: 0.2983 - val_accuracy: 0.8968 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0576 - accuracy: 0.9821 - val_loss: 0.2991 - val_accuracy: 0.8968 - lr: 2.8211e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 3s 12ms/step - loss: 0.6640 - accuracy: 0.8533 - val_loss: 0.5151 - val_accuracy: 0.8323 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.2396 - accuracy: 0.8984 - val_loss: 0.2927 - val_accuracy: 0.9484 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1906 - accuracy: 0.9184 - val_loss: 0.1566 - val_accuracy: 0.9613 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1700 - accuracy: 0.9227 - val_loss: 0.1249 - val_accuracy: 0.9548 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1664 - accuracy: 0.9284 - val_loss: 0.1338 - val_accuracy: 0.9742 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1339 - accuracy: 0.9435 - val_loss: 0.1262 - val_accuracy: 0.9548 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1165 - accuracy: 0.9506 - val_loss: 0.1207 - val_accuracy: 0.9548 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.1168 - accuracy: 0.9528 - val_loss: 0.1293 - val_accuracy: 0.9484 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0981 - accuracy: 0.9621 - val_loss: 0.1402 - val_accuracy: 0.9484 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.1010 - accuracy: 0.9613 - val_loss: 0.1305 - val_accuracy: 0.9484 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0884 - accuracy: 0.9664 - val_loss: 0.1344 - val_accuracy: 0.9548 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0876 - accuracy: 0.9678 - val_loss: 0.1383 - val_accuracy: 0.9613 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0752 - accuracy: 0.9742 - val_loss: 0.1376 - val_accuracy: 0.9419 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0730 - accuracy: 0.9707 - val_loss: 0.1459 - val_accuracy: 0.9484 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0684 - accuracy: 0.9721 - val_loss: 0.1437 - val_accuracy: 0.9419 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0683 - accuracy: 0.9764 - val_loss: 0.1399 - val_accuracy: 0.9484 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0679 - accuracy: 0.9749 - val_loss: 0.1446 - val_accuracy: 0.9484 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0588 - accuracy: 0.9814 - val_loss: 0.1516 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0633 - accuracy: 0.9785 - val_loss: 0.1498 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0694 - accuracy: 0.9749 - val_loss: 0.1462 - val_accuracy: 0.9484 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.1515 - val_accuracy: 0.9419 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0594 - accuracy: 0.9800 - val_loss: 0.1453 - val_accuracy: 0.9548 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0557 - accuracy: 0.9843 - val_loss: 0.1536 - val_accuracy: 0.9355 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0519 - accuracy: 0.9850 - val_loss: 0.1462 - val_accuracy: 0.9419 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 0.1476 - val_accuracy: 0.9419 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0564 - accuracy: 0.9828 - val_loss: 0.1474 - val_accuracy: 0.9419 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0548 - accuracy: 0.9835 - val_loss: 0.1462 - val_accuracy: 0.9484 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0477 - accuracy: 0.9850 - val_loss: 0.1478 - val_accuracy: 0.9484 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.1477 - val_accuracy: 0.9484 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.1464 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0576 - accuracy: 0.9835 - val_loss: 0.1463 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0537 - accuracy: 0.9821 - val_loss: 0.1466 - val_accuracy: 0.9484 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0531 - accuracy: 0.9843 - val_loss: 0.1470 - val_accuracy: 0.9484 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.1461 - val_accuracy: 0.9484 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0542 - accuracy: 0.9814 - val_loss: 0.1463 - val_accuracy: 0.9484 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0639 - accuracy: 0.9771 - val_loss: 0.1466 - val_accuracy: 0.9484 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.1468 - val_accuracy: 0.9484 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0531 - accuracy: 0.9800 - val_loss: 0.1475 - val_accuracy: 0.9484 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0527 - accuracy: 0.9807 - val_loss: 0.1476 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "175/175 [==============================] - 2s 10ms/step - loss: 0.0534 - accuracy: 0.9764 - val_loss: 0.1479 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.1480 - val_accuracy: 0.9484 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.1480 - val_accuracy: 0.9484 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.1478 - val_accuracy: 0.9484 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0502 - accuracy: 0.9835 - val_loss: 0.1477 - val_accuracy: 0.9484 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "175/175 [==============================] - 2s 11ms/step - loss: 0.0495 - accuracy: 0.9843 - val_loss: 0.1480 - val_accuracy: 0.9484 - lr: 4.7018e-05\n",
            "155/155 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "5891ffbe-6c13-479c-aa79-6405c2ea57f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9388089330024814 ± 0.025582379101230845\n",
            "0.9392731834423343 ± 0.02534071549921132\n",
            "0.9566038191176267 ± 0.031859440685139635\n",
            "0.9219425477670421 ± 0.036047696862981544\n",
            "0.8787425634853295 ± 0.05032148341313998\n",
            "0.9777547644735536 ± 0.008808004531147924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5375ea6-0961-48bf-cd9b-9fdd90e67277"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194/194 [==============================] - 3s 13ms/step - loss: 0.6182 - accuracy: 0.8666 - val_loss: 0.6701 - val_accuracy: 0.7294 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "194/194 [==============================] - 4s 19ms/step - loss: 0.2327 - accuracy: 0.9085 - val_loss: 0.3029 - val_accuracy: 0.9124 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "194/194 [==============================] - 2s 12ms/step - loss: 0.1864 - accuracy: 0.9220 - val_loss: 0.2002 - val_accuracy: 0.9407 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1754 - accuracy: 0.9253 - val_loss: 0.1929 - val_accuracy: 0.9459 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1660 - accuracy: 0.9227 - val_loss: 0.2082 - val_accuracy: 0.9304 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1427 - accuracy: 0.9465 - val_loss: 0.2023 - val_accuracy: 0.9330 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1316 - accuracy: 0.9439 - val_loss: 0.2004 - val_accuracy: 0.9330 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1321 - accuracy: 0.9446 - val_loss: 0.1989 - val_accuracy: 0.9381 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1028 - accuracy: 0.9665 - val_loss: 0.2175 - val_accuracy: 0.9304 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.1045 - accuracy: 0.9601 - val_loss: 0.2151 - val_accuracy: 0.9330 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0906 - accuracy: 0.9646 - val_loss: 0.2171 - val_accuracy: 0.9381 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0888 - accuracy: 0.9581 - val_loss: 0.2305 - val_accuracy: 0.9278 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0869 - accuracy: 0.9646 - val_loss: 0.2119 - val_accuracy: 0.9356 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0824 - accuracy: 0.9723 - val_loss: 0.2264 - val_accuracy: 0.9407 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.2314 - val_accuracy: 0.9407 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0713 - accuracy: 0.9723 - val_loss: 0.2299 - val_accuracy: 0.9356 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "194/194 [==============================] - 2s 11ms/step - loss: 0.0720 - accuracy: 0.9742 - val_loss: 0.2206 - val_accuracy: 0.9381 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0762 - accuracy: 0.9684 - val_loss: 0.2243 - val_accuracy: 0.9356 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0706 - accuracy: 0.9742 - val_loss: 0.2301 - val_accuracy: 0.9407 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.2362 - val_accuracy: 0.9330 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0653 - accuracy: 0.9742 - val_loss: 0.2356 - val_accuracy: 0.9407 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0676 - accuracy: 0.9755 - val_loss: 0.2363 - val_accuracy: 0.9330 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0521 - accuracy: 0.9845 - val_loss: 0.2461 - val_accuracy: 0.9407 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0626 - accuracy: 0.9781 - val_loss: 0.2429 - val_accuracy: 0.9381 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0601 - accuracy: 0.9768 - val_loss: 0.2390 - val_accuracy: 0.9407 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0606 - accuracy: 0.9787 - val_loss: 0.2407 - val_accuracy: 0.9381 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "194/194 [==============================] - 2s 11ms/step - loss: 0.0615 - accuracy: 0.9787 - val_loss: 0.2420 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "194/194 [==============================] - 2s 11ms/step - loss: 0.0618 - accuracy: 0.9781 - val_loss: 0.2432 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0604 - accuracy: 0.9742 - val_loss: 0.2443 - val_accuracy: 0.9381 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0584 - accuracy: 0.9742 - val_loss: 0.2432 - val_accuracy: 0.9381 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0622 - accuracy: 0.9749 - val_loss: 0.2445 - val_accuracy: 0.9381 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0646 - accuracy: 0.9742 - val_loss: 0.2425 - val_accuracy: 0.9356 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0587 - accuracy: 0.9794 - val_loss: 0.2436 - val_accuracy: 0.9381 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0559 - accuracy: 0.9807 - val_loss: 0.2446 - val_accuracy: 0.9381 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0584 - accuracy: 0.9749 - val_loss: 0.2454 - val_accuracy: 0.9381 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0575 - accuracy: 0.9781 - val_loss: 0.2456 - val_accuracy: 0.9381 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0555 - accuracy: 0.9807 - val_loss: 0.2454 - val_accuracy: 0.9381 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0611 - accuracy: 0.9787 - val_loss: 0.2449 - val_accuracy: 0.9381 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0562 - accuracy: 0.9787 - val_loss: 0.2452 - val_accuracy: 0.9407 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0556 - accuracy: 0.9820 - val_loss: 0.2450 - val_accuracy: 0.9381 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0588 - accuracy: 0.9762 - val_loss: 0.2456 - val_accuracy: 0.9381 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0607 - accuracy: 0.9762 - val_loss: 0.2452 - val_accuracy: 0.9381 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0574 - accuracy: 0.9794 - val_loss: 0.2455 - val_accuracy: 0.9381 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "194/194 [==============================] - 2s 10ms/step - loss: 0.0560 - accuracy: 0.9774 - val_loss: 0.2450 - val_accuracy: 0.9381 - lr: 7.8364e-05\n",
            "388/388 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0a8de0-15b2-4f4b-a748-57e82f64c579"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9458762886597938\n",
            "0.9478874743107267\n",
            "0.9779005524861878\n",
            "0.9178743961352657\n",
            "0.8937615001394401\n",
            "0.9710915081305133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ACP_alternative_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/ACP_alternative_tensorflow_model.zip /content/ACP_alternative_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "fd237dc8-fd80-4602-edd9-6171e5a1bbb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ACP_alternative_tensorflow_model/ (stored 0%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/variables/ (stored 0%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 37%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/assets/ (stored 0%)\n",
            "  adding: content/ACP_alternative_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fURDBSCz6q6u"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}