{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### requirements for the following codings\n"
      ],
      "metadata": {
        "id": "95NTckuFZZzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### packages required \n",
        "!pip install fair-esm \n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install sklearn"
      ],
      "metadata": {
        "id": "UO71IBS6ZgZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0799ab00-74a1-4a59-dbe2-92789e2610d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[K     |████████████████████████████████| 93 kB 1.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### peptide embeddings with esm2_t6_8M_UR50D pretrained models\n",
        "6 layers, 8M parameters, dataset: UR50/D 2021_04, embedding dimension: 320\n",
        "mode download URL: https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt"
      ],
      "metadata": {
        "id": "m91cA0H5w_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def esm_embeddings(peptide_sequence_list):\n",
        "  # NOTICE: ESM for embeddings is quite RAM usage, if your sequence is too long, \n",
        "  #         or you have too many sequences for transformation in a single converting, \n",
        "  #         you conputer might automatically kill the job.\n",
        "  import torch\n",
        "  import esm\n",
        "  import collections\n",
        "  # load the model\n",
        "  # NOTICE: if the model was not downloaded in your local environment, it will automatically download it.\n",
        "  model, alphabet = esm.pretrained.esm2_t6_8M_UR50D()\n",
        "  batch_converter = alphabet.get_batch_converter()\n",
        "  model.eval()  # disables dropout for deterministic results\n",
        "\n",
        "  # load the peptide sequence list into the bach_converter\n",
        "  batch_labels, batch_strs, batch_tokens = batch_converter(peptide_sequence_list)\n",
        "  batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
        "  ## batch tokens are the embedding results of the whole data set\n",
        "\n",
        "  # Extract per-residue representations (on CPU)\n",
        "  with torch.no_grad():\n",
        "      # Here we export the last layer of the EMS model output as the representation of the peptides\n",
        "      # model'esm2_t6_8M_UR50D' only has 6 layers, and therefore repr_layers parameters is equal to 6\n",
        "      results = model(batch_tokens, repr_layers=[6], return_contacts=True)  \n",
        "  token_representations = results[\"representations\"][6]\n",
        "\n",
        "  # Generate per-sequence representations via averaging\n",
        "  # NOTE: token 0 is always a beginning-of-sequence token, so the first residue is token 1.\n",
        "  sequence_representations = []\n",
        "  for i, tokens_len in enumerate(batch_lens):\n",
        "      sequence_representations.append(token_representations[i, 1 : tokens_len - 1].mean(0))\n",
        "  # save dataset\n",
        "  # sequence_representations is a list and each element is a tensor\n",
        "  embeddings_results = collections.defaultdict(list)\n",
        "  for i in range(len(sequence_representations)):\n",
        "      # tensor can be transformed as numpy sequence_representations[0].numpy() or sequence_representations[0].to_list\n",
        "      each_seq_rep = sequence_representations[i].tolist()\n",
        "      for each_element in each_seq_rep:\n",
        "          embeddings_results[i].append(each_element)\n",
        "  embeddings_results = pd.DataFrame(embeddings_results).T\n",
        "  return embeddings_results"
      ],
      "metadata": {
        "id": "pl7XVx5HZsHf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (main dataset)"
      ],
      "metadata": {
        "id": "RddxugbsdR1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "n6NOFoREw-40"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('main_ACP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    \n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('main_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "LNlD8pvizH84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30cf5ce-da94-47cb-8913-49e051d82a49"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t6_8M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t6_8M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t6_8M_UR50D-contact-regression.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('main_ACP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "    # employ ESM model for converting and save the converted data in csv format\n",
        "    \n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('main_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "U7jxoIsCw8dW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'main_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'main_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "Xk13-JbBXAph"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "HubTATKXslKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142fb5c1-2d19-4a1d-d9ef-54c6057471a4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1378, 320)\n",
            "(344, 320)\n",
            "(1378,)\n",
            "(344,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data loading and embeddings (alternative dataset)"
      ],
      "metadata": {
        "id": "7qxqYf-d_dCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "LXftqHY1_iEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training dataset loading\n",
        "dataset = pd.read_excel('alternative_ACP_train.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "\n",
        "# employ ESM model for converting and save the converted data in csv format\n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('alternative_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_train = dataset['label']\n",
        "y_train = np.array(y_train) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "VYDJ5sxJ_ilc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test dataset loading\n",
        "dataset = pd.read_excel('alternative_ACP_test.xlsx',na_filter = False) # take care the NA sequence problem\n",
        "sequence_list = dataset['sequence'] \n",
        "peptide_sequence_list = []\n",
        "for seq in sequence_list:\n",
        "    format_seq = [seq,seq] # the setting is just following the input format setting in ESM model, [name,sequence]\n",
        "    tuple_sequence = tuple(format_seq)\n",
        "    peptide_sequence_list.append(tuple_sequence) # build a summarize list variable including all the sequence information\n",
        "\n",
        "# employ ESM model for converting and save the converted data in csv format\n",
        "embeddings_results = esm_embeddings(peptide_sequence_list)\n",
        "embeddings_results.to_csv('alternative_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv')\n",
        "\n",
        "# loading the y dataset for model development \n",
        "y_test = dataset['label']\n",
        "y_test = np.array(y_test) # transformed as np.array for CNN model"
      ],
      "metadata": {
        "id": "dH3XGmWJ_ifc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the dataset \n",
        "X_train_data_name = 'alternative_ACP_train_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_train_data = pd.read_csv(X_train_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_test_data_name = 'alternative_ACP_test_esm2_t6_8M_UR50D_unified_320_dimension.csv'\n",
        "X_test_data = pd.read_csv(X_test_data_name,header=0, index_col = 0,delimiter=',')\n",
        "\n",
        "X_train = np.array(X_train_data)\n",
        "X_test = np.array(X_test_data)\n",
        "\n",
        "# normalize the X data range\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train) # normalize X to 0-1 range \n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "I_QVh1hA_ib4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the dimension of the dataset before model development\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "mk831Klh_iXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model architecture"
      ],
      "metadata": {
        "id": "U3Fagh9Iw83q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ESM_CNN(X_train, y_train, X_test, y_test):\n",
        "  from keras.layers import Input,InputLayer, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D,Conv1D\n",
        "  from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, AveragePooling1D, MaxPooling1D\n",
        "  from keras.models import Sequential,Model\n",
        "  from keras.optimizers import SGD\n",
        "  from keras.callbacks import ModelCheckpoint,LearningRateScheduler, EarlyStopping\n",
        "  import keras\n",
        "  from keras import backend as K\n",
        "  inputShape=(320,1)\n",
        "  input = Input(inputShape)\n",
        "  x = Conv1D(128,(3),strides = (1),name='layer_conv1',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool1',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Conv1D(32,(3),strides = (1),name='layer_conv2',padding='same')(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = MaxPooling1D((2), name='MaxPool2',padding=\"same\")(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(64,activation = 'relu',name='fc1')(x)\n",
        "  x = Dropout(0.15)(x)\n",
        "  x = Dense(2,activation = 'softmax',name='fc2')(x)\n",
        "  model = Model(inputs = input,outputs = x,name='Predict')\n",
        "  # define SGD optimizer\n",
        "  momentum = 0.5\n",
        "  sgd = SGD(lr=0.01, momentum=momentum, decay=0.0, nesterov=False)\n",
        "  # compile the model\n",
        "  model.compile(loss='sparse_categorical_crossentropy',optimizer=sgd, metrics=['accuracy'])\n",
        "  # learning deccay setting\n",
        "  import math\n",
        "  def step_decay(epoch): # gradually decrease the learning rate \n",
        "      initial_lrate=0.1\n",
        "      drop=0.6\n",
        "      epochs_drop = 3.0\n",
        "      lrate= initial_lrate * math.pow(drop,    # math.pow base raised to a power\n",
        "            math.floor((1+epoch)/epochs_drop)) # math.floor Round numbers down to the nearest integer\n",
        "      return lrate\n",
        "  lrate = LearningRateScheduler(step_decay)\n",
        "\n",
        "  # early stop setting\n",
        "  early_stop = EarlyStopping(monitor='val_accuracy', patience = 40,restore_best_weights = True)\n",
        "\n",
        "  # summary the callbacks_list\n",
        "  callbacks_list = [ lrate , early_stop]\n",
        "\n",
        "  model_history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                            epochs=200,callbacks=callbacks_list,batch_size = 8, verbose=1)\n",
        "  return model, model_history"
      ],
      "metadata": {
        "id": "b0QeK6-Cg_cv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10-fold cross validation"
      ],
      "metadata": {
        "id": "sws_G8h08tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing 10-fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "k = 10 \n",
        "kf = KFold(n_splits=k, shuffle = True, random_state=1)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "\n",
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "\n",
        "for train_index , test_index in kf.split(y_train):\n",
        "    X_train_CV , X_valid_CV = X_train.iloc[train_index,:],X_train.iloc[test_index,:]\n",
        "    y_train_CV , y_valid_CV = y_train.iloc[train_index] , y_train.iloc[test_index]\n",
        "    model, model_history = ESM_CNN(X_train_CV, y_train_CV, X_valid_CV, y_valid_CV)\n",
        "    # confusion matrix \n",
        "    predicted_class= []\n",
        "    predicted_protability = model.predict(X_valid_CV,batch_size=1)\n",
        "    for i in range(predicted_protability.shape[0]):\n",
        "      index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "      predicted_class.append(index)\n",
        "    predicted_class = np.array(predicted_class)\n",
        "    y_true = y_valid_CV    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import math\n",
        "    # np.ravel() return a flatten 1D array\n",
        "    TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "    ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "    ACC_collecton.append(ACC)\n",
        "    Sn_collecton.append(TP/(TP+FN))\n",
        "    Sp_collecton.append(TN/(TN+FP))\n",
        "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "    MCC_collecton.append(MCC)\n",
        "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    AUC = roc_auc_score(y_valid_CV, predicted_protability[:,1])\n",
        "    AUC_collecton.append(AUC)\n"
      ],
      "metadata": {
        "id": "iFGZ88goj6u4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6cfd6b-960a-4c41-8cf0-336ff4ca04b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "155/155 [==============================] - 5s 15ms/step - loss: 0.8826 - accuracy: 0.5863 - val_loss: 0.6985 - val_accuracy: 0.5435 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.6280 - accuracy: 0.6395 - val_loss: 0.6952 - val_accuracy: 0.5435 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.5803 - accuracy: 0.6855 - val_loss: 0.6364 - val_accuracy: 0.6449 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5495 - accuracy: 0.7161 - val_loss: 0.5821 - val_accuracy: 0.6667 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5297 - accuracy: 0.7129 - val_loss: 0.6030 - val_accuracy: 0.6232 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5002 - accuracy: 0.7306 - val_loss: 0.6234 - val_accuracy: 0.6522 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4817 - accuracy: 0.7613 - val_loss: 0.6123 - val_accuracy: 0.6739 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.4703 - accuracy: 0.7581 - val_loss: 0.5827 - val_accuracy: 0.7174 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4370 - accuracy: 0.7782 - val_loss: 0.5970 - val_accuracy: 0.6957 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.4172 - accuracy: 0.7968 - val_loss: 0.6565 - val_accuracy: 0.6739 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.3966 - accuracy: 0.8040 - val_loss: 0.7054 - val_accuracy: 0.6957 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.3752 - accuracy: 0.8194 - val_loss: 0.6248 - val_accuracy: 0.6812 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3739 - accuracy: 0.8306 - val_loss: 0.6416 - val_accuracy: 0.6594 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.3655 - accuracy: 0.8185 - val_loss: 0.6503 - val_accuracy: 0.6739 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3382 - accuracy: 0.8444 - val_loss: 0.6841 - val_accuracy: 0.6739 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3239 - accuracy: 0.8492 - val_loss: 0.7491 - val_accuracy: 0.7029 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3323 - accuracy: 0.8419 - val_loss: 0.6999 - val_accuracy: 0.6594 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3103 - accuracy: 0.8573 - val_loss: 0.7059 - val_accuracy: 0.6667 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3046 - accuracy: 0.8597 - val_loss: 0.7154 - val_accuracy: 0.7029 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3064 - accuracy: 0.8581 - val_loss: 0.7283 - val_accuracy: 0.6812 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2880 - accuracy: 0.8766 - val_loss: 0.7227 - val_accuracy: 0.6522 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.2974 - accuracy: 0.8669 - val_loss: 0.7342 - val_accuracy: 0.6594 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.2961 - accuracy: 0.8669 - val_loss: 0.7425 - val_accuracy: 0.6522 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2837 - accuracy: 0.8734 - val_loss: 0.7397 - val_accuracy: 0.6667 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2966 - accuracy: 0.8758 - val_loss: 0.7317 - val_accuracy: 0.6667 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2816 - accuracy: 0.8734 - val_loss: 0.7415 - val_accuracy: 0.6594 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.2838 - accuracy: 0.8774 - val_loss: 0.7552 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2773 - accuracy: 0.8774 - val_loss: 0.7564 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2746 - accuracy: 0.8742 - val_loss: 0.7491 - val_accuracy: 0.6739 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2740 - accuracy: 0.8734 - val_loss: 0.7494 - val_accuracy: 0.6739 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2768 - accuracy: 0.8855 - val_loss: 0.7567 - val_accuracy: 0.6739 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2805 - accuracy: 0.8685 - val_loss: 0.7554 - val_accuracy: 0.6667 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2527 - accuracy: 0.8903 - val_loss: 0.7624 - val_accuracy: 0.6739 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2714 - accuracy: 0.8790 - val_loss: 0.7558 - val_accuracy: 0.6739 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2683 - accuracy: 0.8839 - val_loss: 0.7561 - val_accuracy: 0.6739 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2719 - accuracy: 0.8790 - val_loss: 0.7610 - val_accuracy: 0.6739 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2699 - accuracy: 0.8863 - val_loss: 0.7627 - val_accuracy: 0.6739 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2739 - accuracy: 0.8863 - val_loss: 0.7588 - val_accuracy: 0.6739 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2727 - accuracy: 0.8718 - val_loss: 0.7600 - val_accuracy: 0.6739 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2713 - accuracy: 0.8871 - val_loss: 0.7604 - val_accuracy: 0.6739 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2637 - accuracy: 0.8887 - val_loss: 0.7597 - val_accuracy: 0.6739 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2706 - accuracy: 0.8774 - val_loss: 0.7592 - val_accuracy: 0.6739 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2754 - accuracy: 0.8742 - val_loss: 0.7599 - val_accuracy: 0.6739 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2672 - accuracy: 0.8871 - val_loss: 0.7583 - val_accuracy: 0.6739 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2738 - accuracy: 0.8887 - val_loss: 0.7607 - val_accuracy: 0.6739 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2677 - accuracy: 0.8863 - val_loss: 0.7598 - val_accuracy: 0.6739 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2667 - accuracy: 0.8903 - val_loss: 0.7587 - val_accuracy: 0.6739 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.2676 - accuracy: 0.8903 - val_loss: 0.7608 - val_accuracy: 0.6739 - lr: 2.8211e-05\n",
            "138/138 [==============================] - 1s 3ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 4s 20ms/step - loss: 1.6469 - accuracy: 0.5016 - val_loss: 0.7585 - val_accuracy: 0.5362 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6996 - accuracy: 0.4815 - val_loss: 0.7006 - val_accuracy: 0.4638 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.6836 - accuracy: 0.5242 - val_loss: 0.6480 - val_accuracy: 0.6159 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6643 - accuracy: 0.5815 - val_loss: 0.5993 - val_accuracy: 0.6304 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6482 - accuracy: 0.6000 - val_loss: 0.6050 - val_accuracy: 0.6739 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6203 - accuracy: 0.6339 - val_loss: 0.6166 - val_accuracy: 0.6667 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6225 - accuracy: 0.6282 - val_loss: 0.5878 - val_accuracy: 0.6667 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6159 - accuracy: 0.6339 - val_loss: 0.5974 - val_accuracy: 0.6522 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5976 - accuracy: 0.6411 - val_loss: 0.5777 - val_accuracy: 0.6739 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.5819 - accuracy: 0.6460 - val_loss: 0.5838 - val_accuracy: 0.6812 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5694 - accuracy: 0.6605 - val_loss: 0.5777 - val_accuracy: 0.6884 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5700 - accuracy: 0.6476 - val_loss: 0.5696 - val_accuracy: 0.6957 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5557 - accuracy: 0.6597 - val_loss: 0.5711 - val_accuracy: 0.6667 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5653 - accuracy: 0.6315 - val_loss: 0.5593 - val_accuracy: 0.6884 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5405 - accuracy: 0.6831 - val_loss: 0.5606 - val_accuracy: 0.6957 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5523 - accuracy: 0.6782 - val_loss: 0.5641 - val_accuracy: 0.6667 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5476 - accuracy: 0.6734 - val_loss: 0.5606 - val_accuracy: 0.6812 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5352 - accuracy: 0.6758 - val_loss: 0.5688 - val_accuracy: 0.6594 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5304 - accuracy: 0.6976 - val_loss: 0.5603 - val_accuracy: 0.7029 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5327 - accuracy: 0.6919 - val_loss: 0.5746 - val_accuracy: 0.6377 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.5234 - accuracy: 0.6968 - val_loss: 0.5714 - val_accuracy: 0.6522 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5354 - accuracy: 0.6774 - val_loss: 0.5649 - val_accuracy: 0.6594 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5271 - accuracy: 0.6952 - val_loss: 0.5642 - val_accuracy: 0.6812 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5289 - accuracy: 0.6935 - val_loss: 0.5639 - val_accuracy: 0.6667 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5199 - accuracy: 0.6911 - val_loss: 0.5623 - val_accuracy: 0.6884 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5272 - accuracy: 0.6863 - val_loss: 0.5612 - val_accuracy: 0.6884 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5159 - accuracy: 0.6927 - val_loss: 0.5633 - val_accuracy: 0.6957 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5133 - accuracy: 0.7040 - val_loss: 0.5643 - val_accuracy: 0.6957 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5231 - accuracy: 0.6863 - val_loss: 0.5646 - val_accuracy: 0.6739 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5046 - accuracy: 0.7048 - val_loss: 0.5656 - val_accuracy: 0.6739 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5157 - accuracy: 0.6919 - val_loss: 0.5654 - val_accuracy: 0.6739 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5089 - accuracy: 0.6968 - val_loss: 0.5666 - val_accuracy: 0.6739 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5088 - accuracy: 0.7032 - val_loss: 0.5660 - val_accuracy: 0.6667 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5061 - accuracy: 0.7073 - val_loss: 0.5653 - val_accuracy: 0.6812 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5121 - accuracy: 0.6976 - val_loss: 0.5647 - val_accuracy: 0.6739 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5175 - accuracy: 0.6952 - val_loss: 0.5644 - val_accuracy: 0.6739 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5109 - accuracy: 0.7016 - val_loss: 0.5634 - val_accuracy: 0.6739 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5085 - accuracy: 0.7065 - val_loss: 0.5632 - val_accuracy: 0.6812 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5031 - accuracy: 0.7169 - val_loss: 0.5631 - val_accuracy: 0.6812 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5141 - accuracy: 0.6992 - val_loss: 0.5628 - val_accuracy: 0.6884 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5085 - accuracy: 0.7105 - val_loss: 0.5629 - val_accuracy: 0.6884 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5092 - accuracy: 0.7000 - val_loss: 0.5633 - val_accuracy: 0.6812 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5048 - accuracy: 0.7081 - val_loss: 0.5639 - val_accuracy: 0.6812 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5046 - accuracy: 0.7048 - val_loss: 0.5633 - val_accuracy: 0.6884 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.5104 - accuracy: 0.6976 - val_loss: 0.5642 - val_accuracy: 0.6812 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.5088 - accuracy: 0.6919 - val_loss: 0.5640 - val_accuracy: 0.6739 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5107 - accuracy: 0.7073 - val_loss: 0.5644 - val_accuracy: 0.6739 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5095 - accuracy: 0.7065 - val_loss: 0.5642 - val_accuracy: 0.6739 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5191 - accuracy: 0.6863 - val_loss: 0.5643 - val_accuracy: 0.6739 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 3s 21ms/step - loss: 0.5034 - accuracy: 0.7089 - val_loss: 0.5645 - val_accuracy: 0.6739 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5144 - accuracy: 0.6992 - val_loss: 0.5640 - val_accuracy: 0.6739 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5142 - accuracy: 0.6968 - val_loss: 0.5640 - val_accuracy: 0.6739 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 3s 18ms/step - loss: 0.5074 - accuracy: 0.7000 - val_loss: 0.5641 - val_accuracy: 0.6739 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5122 - accuracy: 0.7032 - val_loss: 0.5644 - val_accuracy: 0.6739 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5082 - accuracy: 0.7000 - val_loss: 0.5644 - val_accuracy: 0.6739 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5088 - accuracy: 0.7040 - val_loss: 0.5643 - val_accuracy: 0.6739 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5186 - accuracy: 0.6839 - val_loss: 0.5640 - val_accuracy: 0.6739 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5121 - accuracy: 0.6855 - val_loss: 0.5639 - val_accuracy: 0.6739 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5185 - accuracy: 0.6935 - val_loss: 0.5643 - val_accuracy: 0.6739 - lr: 6.0936e-06\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 14ms/step - loss: 1.3387 - accuracy: 0.6065 - val_loss: 0.6909 - val_accuracy: 0.5362 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5993 - accuracy: 0.6702 - val_loss: 0.6327 - val_accuracy: 0.6522 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5697 - accuracy: 0.6766 - val_loss: 0.6086 - val_accuracy: 0.6304 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5472 - accuracy: 0.7089 - val_loss: 0.5665 - val_accuracy: 0.6812 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5319 - accuracy: 0.7226 - val_loss: 0.5589 - val_accuracy: 0.7101 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5150 - accuracy: 0.7339 - val_loss: 0.5964 - val_accuracy: 0.6957 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5018 - accuracy: 0.7548 - val_loss: 0.6323 - val_accuracy: 0.6304 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4784 - accuracy: 0.7500 - val_loss: 0.6750 - val_accuracy: 0.6377 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4664 - accuracy: 0.7710 - val_loss: 0.6136 - val_accuracy: 0.6667 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4524 - accuracy: 0.7790 - val_loss: 0.5786 - val_accuracy: 0.7029 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4508 - accuracy: 0.7710 - val_loss: 0.5610 - val_accuracy: 0.6812 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4328 - accuracy: 0.7871 - val_loss: 0.5328 - val_accuracy: 0.7246 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4286 - accuracy: 0.7935 - val_loss: 0.5394 - val_accuracy: 0.7319 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4245 - accuracy: 0.7927 - val_loss: 0.5488 - val_accuracy: 0.7029 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4100 - accuracy: 0.8065 - val_loss: 0.5764 - val_accuracy: 0.6884 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3999 - accuracy: 0.8137 - val_loss: 0.5546 - val_accuracy: 0.7246 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3927 - accuracy: 0.8073 - val_loss: 0.5571 - val_accuracy: 0.7246 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3856 - accuracy: 0.8234 - val_loss: 0.5723 - val_accuracy: 0.7101 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3877 - accuracy: 0.8234 - val_loss: 0.5680 - val_accuracy: 0.7246 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3717 - accuracy: 0.8331 - val_loss: 0.5651 - val_accuracy: 0.7319 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3810 - accuracy: 0.8185 - val_loss: 0.5601 - val_accuracy: 0.7319 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3788 - accuracy: 0.8218 - val_loss: 0.5457 - val_accuracy: 0.7319 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3752 - accuracy: 0.8315 - val_loss: 0.5616 - val_accuracy: 0.7391 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3761 - accuracy: 0.8298 - val_loss: 0.5618 - val_accuracy: 0.7319 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3682 - accuracy: 0.8298 - val_loss: 0.5611 - val_accuracy: 0.7391 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3864 - accuracy: 0.8177 - val_loss: 0.5625 - val_accuracy: 0.7464 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3769 - accuracy: 0.8363 - val_loss: 0.5552 - val_accuracy: 0.7391 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3587 - accuracy: 0.8347 - val_loss: 0.5597 - val_accuracy: 0.7391 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3654 - accuracy: 0.8492 - val_loss: 0.5662 - val_accuracy: 0.7246 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3666 - accuracy: 0.8347 - val_loss: 0.5590 - val_accuracy: 0.7319 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3558 - accuracy: 0.8379 - val_loss: 0.5589 - val_accuracy: 0.7246 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3720 - accuracy: 0.8282 - val_loss: 0.5613 - val_accuracy: 0.7319 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3666 - accuracy: 0.8282 - val_loss: 0.5620 - val_accuracy: 0.7391 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3495 - accuracy: 0.8444 - val_loss: 0.5619 - val_accuracy: 0.7319 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3587 - accuracy: 0.8419 - val_loss: 0.5634 - val_accuracy: 0.7391 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3556 - accuracy: 0.8363 - val_loss: 0.5625 - val_accuracy: 0.7391 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3594 - accuracy: 0.8347 - val_loss: 0.5632 - val_accuracy: 0.7464 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3568 - accuracy: 0.8347 - val_loss: 0.5627 - val_accuracy: 0.7464 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3650 - accuracy: 0.8379 - val_loss: 0.5632 - val_accuracy: 0.7464 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3520 - accuracy: 0.8444 - val_loss: 0.5641 - val_accuracy: 0.7464 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3630 - accuracy: 0.8363 - val_loss: 0.5634 - val_accuracy: 0.7464 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3595 - accuracy: 0.8274 - val_loss: 0.5641 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3565 - accuracy: 0.8331 - val_loss: 0.5635 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3621 - accuracy: 0.8347 - val_loss: 0.5632 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3653 - accuracy: 0.8315 - val_loss: 0.5647 - val_accuracy: 0.7464 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3622 - accuracy: 0.8282 - val_loss: 0.5646 - val_accuracy: 0.7464 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3522 - accuracy: 0.8315 - val_loss: 0.5641 - val_accuracy: 0.7464 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3708 - accuracy: 0.8298 - val_loss: 0.5636 - val_accuracy: 0.7464 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3521 - accuracy: 0.8387 - val_loss: 0.5649 - val_accuracy: 0.7464 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3664 - accuracy: 0.8339 - val_loss: 0.5650 - val_accuracy: 0.7464 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3577 - accuracy: 0.8444 - val_loss: 0.5655 - val_accuracy: 0.7464 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3397 - accuracy: 0.8468 - val_loss: 0.5654 - val_accuracy: 0.7464 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.3566 - accuracy: 0.8435 - val_loss: 0.5642 - val_accuracy: 0.7464 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3654 - accuracy: 0.8274 - val_loss: 0.5647 - val_accuracy: 0.7464 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3542 - accuracy: 0.8355 - val_loss: 0.5652 - val_accuracy: 0.7464 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3574 - accuracy: 0.8371 - val_loss: 0.5649 - val_accuracy: 0.7464 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "155/155 [==============================] - 3s 19ms/step - loss: 0.3526 - accuracy: 0.8435 - val_loss: 0.5652 - val_accuracy: 0.7464 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.3649 - accuracy: 0.8452 - val_loss: 0.5654 - val_accuracy: 0.7464 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3536 - accuracy: 0.8379 - val_loss: 0.5651 - val_accuracy: 0.7464 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3480 - accuracy: 0.8613 - val_loss: 0.5650 - val_accuracy: 0.7464 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3421 - accuracy: 0.8468 - val_loss: 0.5646 - val_accuracy: 0.7464 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3599 - accuracy: 0.8298 - val_loss: 0.5649 - val_accuracy: 0.7464 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3610 - accuracy: 0.8290 - val_loss: 0.5645 - val_accuracy: 0.7464 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3449 - accuracy: 0.8403 - val_loss: 0.5644 - val_accuracy: 0.7464 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3536 - accuracy: 0.8460 - val_loss: 0.5651 - val_accuracy: 0.7464 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3503 - accuracy: 0.8492 - val_loss: 0.5648 - val_accuracy: 0.7464 - lr: 1.3162e-06\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 14ms/step - loss: 0.9535 - accuracy: 0.5339 - val_loss: 0.6800 - val_accuracy: 0.5870 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6534 - accuracy: 0.5806 - val_loss: 0.7061 - val_accuracy: 0.5725 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6302 - accuracy: 0.6234 - val_loss: 0.5677 - val_accuracy: 0.6739 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6109 - accuracy: 0.6347 - val_loss: 0.5416 - val_accuracy: 0.6812 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5865 - accuracy: 0.6516 - val_loss: 0.5382 - val_accuracy: 0.6667 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5459 - accuracy: 0.6984 - val_loss: 0.5260 - val_accuracy: 0.6957 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5326 - accuracy: 0.7065 - val_loss: 0.5148 - val_accuracy: 0.7246 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5233 - accuracy: 0.7161 - val_loss: 0.5101 - val_accuracy: 0.7101 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5012 - accuracy: 0.7210 - val_loss: 0.5023 - val_accuracy: 0.7246 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4908 - accuracy: 0.7403 - val_loss: 0.4970 - val_accuracy: 0.7319 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4809 - accuracy: 0.7395 - val_loss: 0.4976 - val_accuracy: 0.7391 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4554 - accuracy: 0.7476 - val_loss: 0.4881 - val_accuracy: 0.7319 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4724 - accuracy: 0.7290 - val_loss: 0.5057 - val_accuracy: 0.7319 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4549 - accuracy: 0.7492 - val_loss: 0.4947 - val_accuracy: 0.7609 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4478 - accuracy: 0.7452 - val_loss: 0.5001 - val_accuracy: 0.7391 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4198 - accuracy: 0.7645 - val_loss: 0.5262 - val_accuracy: 0.7246 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4274 - accuracy: 0.7661 - val_loss: 0.5053 - val_accuracy: 0.7464 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4077 - accuracy: 0.7645 - val_loss: 0.4997 - val_accuracy: 0.7681 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4034 - accuracy: 0.7855 - val_loss: 0.4968 - val_accuracy: 0.7681 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4207 - accuracy: 0.7589 - val_loss: 0.4971 - val_accuracy: 0.7609 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4053 - accuracy: 0.7863 - val_loss: 0.4966 - val_accuracy: 0.7609 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3999 - accuracy: 0.7895 - val_loss: 0.4956 - val_accuracy: 0.7754 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3955 - accuracy: 0.7831 - val_loss: 0.5006 - val_accuracy: 0.7464 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3968 - accuracy: 0.7831 - val_loss: 0.5057 - val_accuracy: 0.7536 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3761 - accuracy: 0.8008 - val_loss: 0.5100 - val_accuracy: 0.7464 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3820 - accuracy: 0.7855 - val_loss: 0.5001 - val_accuracy: 0.7464 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3872 - accuracy: 0.8016 - val_loss: 0.5069 - val_accuracy: 0.7536 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3833 - accuracy: 0.7984 - val_loss: 0.5030 - val_accuracy: 0.7536 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3821 - accuracy: 0.7952 - val_loss: 0.5044 - val_accuracy: 0.7536 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3879 - accuracy: 0.7984 - val_loss: 0.5023 - val_accuracy: 0.7536 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3746 - accuracy: 0.7992 - val_loss: 0.4978 - val_accuracy: 0.7464 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3777 - accuracy: 0.8097 - val_loss: 0.5003 - val_accuracy: 0.7391 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3828 - accuracy: 0.8048 - val_loss: 0.5004 - val_accuracy: 0.7391 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3777 - accuracy: 0.8081 - val_loss: 0.5024 - val_accuracy: 0.7464 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3840 - accuracy: 0.8016 - val_loss: 0.5029 - val_accuracy: 0.7609 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3651 - accuracy: 0.8202 - val_loss: 0.5025 - val_accuracy: 0.7609 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3782 - accuracy: 0.8016 - val_loss: 0.5016 - val_accuracy: 0.7609 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3816 - accuracy: 0.7976 - val_loss: 0.5002 - val_accuracy: 0.7536 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3663 - accuracy: 0.8065 - val_loss: 0.5015 - val_accuracy: 0.7536 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3664 - accuracy: 0.8226 - val_loss: 0.5016 - val_accuracy: 0.7609 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3663 - accuracy: 0.8113 - val_loss: 0.5022 - val_accuracy: 0.7609 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3756 - accuracy: 0.8056 - val_loss: 0.5024 - val_accuracy: 0.7609 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3725 - accuracy: 0.8040 - val_loss: 0.5021 - val_accuracy: 0.7609 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3762 - accuracy: 0.8056 - val_loss: 0.5018 - val_accuracy: 0.7609 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3770 - accuracy: 0.8056 - val_loss: 0.5021 - val_accuracy: 0.7609 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3709 - accuracy: 0.8145 - val_loss: 0.5013 - val_accuracy: 0.7609 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3712 - accuracy: 0.8032 - val_loss: 0.5015 - val_accuracy: 0.7609 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3774 - accuracy: 0.8032 - val_loss: 0.5011 - val_accuracy: 0.7609 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3639 - accuracy: 0.8113 - val_loss: 0.5012 - val_accuracy: 0.7609 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3722 - accuracy: 0.8065 - val_loss: 0.5012 - val_accuracy: 0.7609 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3772 - accuracy: 0.8113 - val_loss: 0.5013 - val_accuracy: 0.7609 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3739 - accuracy: 0.8073 - val_loss: 0.5012 - val_accuracy: 0.7609 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3664 - accuracy: 0.8113 - val_loss: 0.5016 - val_accuracy: 0.7609 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3853 - accuracy: 0.7992 - val_loss: 0.5014 - val_accuracy: 0.7609 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3667 - accuracy: 0.8153 - val_loss: 0.5015 - val_accuracy: 0.7609 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3885 - accuracy: 0.8000 - val_loss: 0.5013 - val_accuracy: 0.7609 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3652 - accuracy: 0.8185 - val_loss: 0.5009 - val_accuracy: 0.7609 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3691 - accuracy: 0.8137 - val_loss: 0.5015 - val_accuracy: 0.7609 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3729 - accuracy: 0.7992 - val_loss: 0.5012 - val_accuracy: 0.7609 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3755 - accuracy: 0.8016 - val_loss: 0.5011 - val_accuracy: 0.7609 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.3584 - accuracy: 0.8161 - val_loss: 0.5016 - val_accuracy: 0.7609 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3755 - accuracy: 0.8105 - val_loss: 0.5017 - val_accuracy: 0.7609 - lr: 3.6562e-06\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 4s 18ms/step - loss: 0.8123 - accuracy: 0.5097 - val_loss: 0.6949 - val_accuracy: 0.5000 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.6812 - accuracy: 0.5379 - val_loss: 0.6957 - val_accuracy: 0.5000 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6962 - accuracy: 0.4710 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6958 - accuracy: 0.5016 - val_loss: 0.6944 - val_accuracy: 0.5000 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6961 - accuracy: 0.4927 - val_loss: 0.6964 - val_accuracy: 0.5000 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 3s 20ms/step - loss: 0.6940 - accuracy: 0.5177 - val_loss: 0.6939 - val_accuracy: 0.5000 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.6926 - accuracy: 0.5274 - val_loss: 0.6953 - val_accuracy: 0.5000 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6948 - accuracy: 0.4952 - val_loss: 0.6933 - val_accuracy: 0.5000 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6824 - accuracy: 0.5589 - val_loss: 0.6616 - val_accuracy: 0.6304 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6525 - accuracy: 0.6379 - val_loss: 0.6212 - val_accuracy: 0.6522 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6302 - accuracy: 0.6492 - val_loss: 0.6768 - val_accuracy: 0.5507 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6119 - accuracy: 0.6782 - val_loss: 0.6030 - val_accuracy: 0.6957 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6051 - accuracy: 0.6903 - val_loss: 0.5909 - val_accuracy: 0.7029 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.6073 - accuracy: 0.6855 - val_loss: 0.5973 - val_accuracy: 0.6957 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5930 - accuracy: 0.6968 - val_loss: 0.5973 - val_accuracy: 0.7319 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5764 - accuracy: 0.7081 - val_loss: 0.5948 - val_accuracy: 0.6957 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5792 - accuracy: 0.7153 - val_loss: 0.6184 - val_accuracy: 0.6304 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5449 - accuracy: 0.7298 - val_loss: 0.5903 - val_accuracy: 0.7101 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5657 - accuracy: 0.7177 - val_loss: 0.5883 - val_accuracy: 0.7174 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5676 - accuracy: 0.7137 - val_loss: 0.5759 - val_accuracy: 0.7101 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5566 - accuracy: 0.7371 - val_loss: 0.5870 - val_accuracy: 0.6884 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5494 - accuracy: 0.7419 - val_loss: 0.5942 - val_accuracy: 0.6739 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5451 - accuracy: 0.7282 - val_loss: 0.5747 - val_accuracy: 0.7029 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5475 - accuracy: 0.7339 - val_loss: 0.5841 - val_accuracy: 0.6957 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5501 - accuracy: 0.7331 - val_loss: 0.5802 - val_accuracy: 0.7029 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5505 - accuracy: 0.7331 - val_loss: 0.5842 - val_accuracy: 0.6884 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5256 - accuracy: 0.7508 - val_loss: 0.5825 - val_accuracy: 0.6884 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5441 - accuracy: 0.7395 - val_loss: 0.5857 - val_accuracy: 0.6884 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5388 - accuracy: 0.7452 - val_loss: 0.5795 - val_accuracy: 0.6957 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5363 - accuracy: 0.7435 - val_loss: 0.5818 - val_accuracy: 0.6957 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5220 - accuracy: 0.7573 - val_loss: 0.5842 - val_accuracy: 0.6957 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5285 - accuracy: 0.7540 - val_loss: 0.5811 - val_accuracy: 0.6957 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5234 - accuracy: 0.7500 - val_loss: 0.5816 - val_accuracy: 0.6812 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5105 - accuracy: 0.7661 - val_loss: 0.5798 - val_accuracy: 0.6884 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5347 - accuracy: 0.7524 - val_loss: 0.5867 - val_accuracy: 0.6812 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5233 - accuracy: 0.7565 - val_loss: 0.5811 - val_accuracy: 0.6884 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5409 - accuracy: 0.7468 - val_loss: 0.5812 - val_accuracy: 0.6884 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5356 - accuracy: 0.7395 - val_loss: 0.5808 - val_accuracy: 0.6884 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5088 - accuracy: 0.7685 - val_loss: 0.5810 - val_accuracy: 0.6884 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5246 - accuracy: 0.7540 - val_loss: 0.5820 - val_accuracy: 0.6884 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5165 - accuracy: 0.7556 - val_loss: 0.5802 - val_accuracy: 0.6812 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5102 - accuracy: 0.7677 - val_loss: 0.5805 - val_accuracy: 0.6884 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5308 - accuracy: 0.7427 - val_loss: 0.5808 - val_accuracy: 0.6884 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5228 - accuracy: 0.7556 - val_loss: 0.5812 - val_accuracy: 0.6884 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5108 - accuracy: 0.7637 - val_loss: 0.5807 - val_accuracy: 0.6884 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5392 - accuracy: 0.7460 - val_loss: 0.5814 - val_accuracy: 0.6884 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5257 - accuracy: 0.7492 - val_loss: 0.5808 - val_accuracy: 0.6884 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.5144 - accuracy: 0.7613 - val_loss: 0.5803 - val_accuracy: 0.6884 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5273 - accuracy: 0.7565 - val_loss: 0.5803 - val_accuracy: 0.6884 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5245 - accuracy: 0.7524 - val_loss: 0.5805 - val_accuracy: 0.6884 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5205 - accuracy: 0.7581 - val_loss: 0.5807 - val_accuracy: 0.6884 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5303 - accuracy: 0.7508 - val_loss: 0.5808 - val_accuracy: 0.6884 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5191 - accuracy: 0.7556 - val_loss: 0.5806 - val_accuracy: 0.6884 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5225 - accuracy: 0.7516 - val_loss: 0.5806 - val_accuracy: 0.6884 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5267 - accuracy: 0.7395 - val_loss: 0.5807 - val_accuracy: 0.6884 - lr: 1.0156e-05\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 13ms/step - loss: 0.9864 - accuracy: 0.5597 - val_loss: 0.6724 - val_accuracy: 0.6522 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.6182 - accuracy: 0.6298 - val_loss: 0.6664 - val_accuracy: 0.6667 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5743 - accuracy: 0.6750 - val_loss: 0.6050 - val_accuracy: 0.6957 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5365 - accuracy: 0.7089 - val_loss: 0.5809 - val_accuracy: 0.6449 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5173 - accuracy: 0.7266 - val_loss: 0.5621 - val_accuracy: 0.6884 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4744 - accuracy: 0.7476 - val_loss: 0.5378 - val_accuracy: 0.7681 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4592 - accuracy: 0.7645 - val_loss: 0.5738 - val_accuracy: 0.6594 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4355 - accuracy: 0.7839 - val_loss: 0.5704 - val_accuracy: 0.7029 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4115 - accuracy: 0.8048 - val_loss: 0.5568 - val_accuracy: 0.7464 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3989 - accuracy: 0.8081 - val_loss: 0.5138 - val_accuracy: 0.7246 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3723 - accuracy: 0.8153 - val_loss: 0.5821 - val_accuracy: 0.7319 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3693 - accuracy: 0.8266 - val_loss: 0.5534 - val_accuracy: 0.7391 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3463 - accuracy: 0.8331 - val_loss: 0.6274 - val_accuracy: 0.6957 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3303 - accuracy: 0.8403 - val_loss: 0.5481 - val_accuracy: 0.7681 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3255 - accuracy: 0.8427 - val_loss: 0.5642 - val_accuracy: 0.7319 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3148 - accuracy: 0.8524 - val_loss: 0.5397 - val_accuracy: 0.7319 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3056 - accuracy: 0.8589 - val_loss: 0.5633 - val_accuracy: 0.7319 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2877 - accuracy: 0.8758 - val_loss: 0.5701 - val_accuracy: 0.7246 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2981 - accuracy: 0.8669 - val_loss: 0.5743 - val_accuracy: 0.7464 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2925 - accuracy: 0.8653 - val_loss: 0.5750 - val_accuracy: 0.7174 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2843 - accuracy: 0.8702 - val_loss: 0.5714 - val_accuracy: 0.7391 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2693 - accuracy: 0.8935 - val_loss: 0.5586 - val_accuracy: 0.7681 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2604 - accuracy: 0.8782 - val_loss: 0.5785 - val_accuracy: 0.7246 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.2791 - accuracy: 0.8766 - val_loss: 0.5654 - val_accuracy: 0.7246 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2649 - accuracy: 0.8984 - val_loss: 0.5672 - val_accuracy: 0.7319 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2608 - accuracy: 0.8871 - val_loss: 0.5718 - val_accuracy: 0.7391 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2656 - accuracy: 0.8798 - val_loss: 0.5701 - val_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2544 - accuracy: 0.8879 - val_loss: 0.5699 - val_accuracy: 0.7609 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 14ms/step - loss: 0.2682 - accuracy: 0.8863 - val_loss: 0.5627 - val_accuracy: 0.7536 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.2657 - accuracy: 0.8839 - val_loss: 0.5690 - val_accuracy: 0.7319 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2640 - accuracy: 0.8903 - val_loss: 0.5685 - val_accuracy: 0.7609 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2657 - accuracy: 0.8798 - val_loss: 0.5706 - val_accuracy: 0.7536 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2500 - accuracy: 0.8960 - val_loss: 0.5736 - val_accuracy: 0.7536 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2474 - accuracy: 0.8976 - val_loss: 0.5718 - val_accuracy: 0.7609 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2493 - accuracy: 0.8927 - val_loss: 0.5735 - val_accuracy: 0.7609 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2561 - accuracy: 0.8855 - val_loss: 0.5745 - val_accuracy: 0.7536 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2565 - accuracy: 0.8831 - val_loss: 0.5748 - val_accuracy: 0.7536 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2486 - accuracy: 0.8863 - val_loss: 0.5746 - val_accuracy: 0.7609 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2543 - accuracy: 0.8911 - val_loss: 0.5749 - val_accuracy: 0.7609 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2555 - accuracy: 0.8863 - val_loss: 0.5753 - val_accuracy: 0.7464 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2533 - accuracy: 0.8960 - val_loss: 0.5767 - val_accuracy: 0.7464 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2536 - accuracy: 0.8847 - val_loss: 0.5763 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2613 - accuracy: 0.8831 - val_loss: 0.5755 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2645 - accuracy: 0.8774 - val_loss: 0.5754 - val_accuracy: 0.7464 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2519 - accuracy: 0.8887 - val_loss: 0.5749 - val_accuracy: 0.7464 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2553 - accuracy: 0.8903 - val_loss: 0.5747 - val_accuracy: 0.7464 - lr: 4.7018e-05\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 12ms/step - loss: 0.8339 - accuracy: 0.5226 - val_loss: 0.7072 - val_accuracy: 0.4565 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.6963 - accuracy: 0.5065 - val_loss: 0.6907 - val_accuracy: 0.5435 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.6929 - accuracy: 0.5073 - val_loss: 0.7015 - val_accuracy: 0.4565 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.6574 - accuracy: 0.5944 - val_loss: 0.6782 - val_accuracy: 0.5507 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.6191 - accuracy: 0.6323 - val_loss: 0.6397 - val_accuracy: 0.6087 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5964 - accuracy: 0.6508 - val_loss: 0.6593 - val_accuracy: 0.5725 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5781 - accuracy: 0.6702 - val_loss: 0.6201 - val_accuracy: 0.6377 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5547 - accuracy: 0.6685 - val_loss: 0.5799 - val_accuracy: 0.6449 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5391 - accuracy: 0.6879 - val_loss: 0.6200 - val_accuracy: 0.6667 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5392 - accuracy: 0.6815 - val_loss: 0.6043 - val_accuracy: 0.6159 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5182 - accuracy: 0.7016 - val_loss: 0.6024 - val_accuracy: 0.6522 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5040 - accuracy: 0.7008 - val_loss: 0.6079 - val_accuracy: 0.6377 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4963 - accuracy: 0.7000 - val_loss: 0.6238 - val_accuracy: 0.6594 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4833 - accuracy: 0.7153 - val_loss: 0.6405 - val_accuracy: 0.6594 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4857 - accuracy: 0.7089 - val_loss: 0.6383 - val_accuracy: 0.6739 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4766 - accuracy: 0.7185 - val_loss: 0.6192 - val_accuracy: 0.6812 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4731 - accuracy: 0.7145 - val_loss: 0.6456 - val_accuracy: 0.6522 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4606 - accuracy: 0.7226 - val_loss: 0.6412 - val_accuracy: 0.6522 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4630 - accuracy: 0.7234 - val_loss: 0.6257 - val_accuracy: 0.6522 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4617 - accuracy: 0.7250 - val_loss: 0.6387 - val_accuracy: 0.6667 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4521 - accuracy: 0.7258 - val_loss: 0.6548 - val_accuracy: 0.6739 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4561 - accuracy: 0.7234 - val_loss: 0.6651 - val_accuracy: 0.6594 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4592 - accuracy: 0.7315 - val_loss: 0.6473 - val_accuracy: 0.6667 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4459 - accuracy: 0.7315 - val_loss: 0.6338 - val_accuracy: 0.6739 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4521 - accuracy: 0.7177 - val_loss: 0.6403 - val_accuracy: 0.6739 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4393 - accuracy: 0.7435 - val_loss: 0.6311 - val_accuracy: 0.6739 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4376 - accuracy: 0.7403 - val_loss: 0.6510 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.4484 - accuracy: 0.7282 - val_loss: 0.6469 - val_accuracy: 0.6594 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.4429 - accuracy: 0.7298 - val_loss: 0.6520 - val_accuracy: 0.6667 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4477 - accuracy: 0.7210 - val_loss: 0.6552 - val_accuracy: 0.6594 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4436 - accuracy: 0.7274 - val_loss: 0.6500 - val_accuracy: 0.6594 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4414 - accuracy: 0.7323 - val_loss: 0.6542 - val_accuracy: 0.6594 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 3s 17ms/step - loss: 0.4343 - accuracy: 0.7379 - val_loss: 0.6611 - val_accuracy: 0.6594 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4304 - accuracy: 0.7427 - val_loss: 0.6622 - val_accuracy: 0.6594 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4347 - accuracy: 0.7419 - val_loss: 0.6657 - val_accuracy: 0.6594 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4230 - accuracy: 0.7403 - val_loss: 0.6635 - val_accuracy: 0.6667 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4352 - accuracy: 0.7323 - val_loss: 0.6565 - val_accuracy: 0.6667 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4400 - accuracy: 0.7266 - val_loss: 0.6566 - val_accuracy: 0.6667 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4359 - accuracy: 0.7266 - val_loss: 0.6587 - val_accuracy: 0.6667 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4321 - accuracy: 0.7323 - val_loss: 0.6577 - val_accuracy: 0.6667 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4415 - accuracy: 0.7306 - val_loss: 0.6546 - val_accuracy: 0.6667 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4344 - accuracy: 0.7379 - val_loss: 0.6571 - val_accuracy: 0.6667 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4277 - accuracy: 0.7258 - val_loss: 0.6551 - val_accuracy: 0.6667 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4348 - accuracy: 0.7258 - val_loss: 0.6534 - val_accuracy: 0.6667 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4311 - accuracy: 0.7379 - val_loss: 0.6535 - val_accuracy: 0.6667 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4339 - accuracy: 0.7355 - val_loss: 0.6549 - val_accuracy: 0.6667 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4317 - accuracy: 0.7266 - val_loss: 0.6550 - val_accuracy: 0.6667 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4327 - accuracy: 0.7379 - val_loss: 0.6561 - val_accuracy: 0.6667 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4357 - accuracy: 0.7379 - val_loss: 0.6568 - val_accuracy: 0.6667 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4338 - accuracy: 0.7290 - val_loss: 0.6568 - val_accuracy: 0.6667 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4409 - accuracy: 0.7347 - val_loss: 0.6562 - val_accuracy: 0.6667 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4296 - accuracy: 0.7323 - val_loss: 0.6564 - val_accuracy: 0.6667 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4253 - accuracy: 0.7444 - val_loss: 0.6563 - val_accuracy: 0.6667 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4295 - accuracy: 0.7331 - val_loss: 0.6568 - val_accuracy: 0.6667 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.4344 - accuracy: 0.7266 - val_loss: 0.6565 - val_accuracy: 0.6667 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4351 - accuracy: 0.7331 - val_loss: 0.6562 - val_accuracy: 0.6667 - lr: 1.0156e-05\n",
            "138/138 [==============================] - 0s 3ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 3s 13ms/step - loss: 1.1691 - accuracy: 0.6177 - val_loss: 0.7089 - val_accuracy: 0.4855 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5785 - accuracy: 0.6742 - val_loss: 0.6560 - val_accuracy: 0.5652 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.5208 - accuracy: 0.7290 - val_loss: 0.6198 - val_accuracy: 0.6304 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.5113 - accuracy: 0.7484 - val_loss: 0.6277 - val_accuracy: 0.5870 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4839 - accuracy: 0.7605 - val_loss: 0.6328 - val_accuracy: 0.6594 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4571 - accuracy: 0.7726 - val_loss: 0.6438 - val_accuracy: 0.6884 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4242 - accuracy: 0.7855 - val_loss: 0.6051 - val_accuracy: 0.6812 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.4155 - accuracy: 0.7960 - val_loss: 0.5705 - val_accuracy: 0.7101 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3902 - accuracy: 0.8202 - val_loss: 0.6142 - val_accuracy: 0.7029 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3794 - accuracy: 0.8202 - val_loss: 0.5888 - val_accuracy: 0.7174 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3719 - accuracy: 0.8210 - val_loss: 0.5986 - val_accuracy: 0.7101 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3473 - accuracy: 0.8427 - val_loss: 0.6243 - val_accuracy: 0.7174 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3364 - accuracy: 0.8581 - val_loss: 0.6216 - val_accuracy: 0.7101 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3267 - accuracy: 0.8516 - val_loss: 0.6746 - val_accuracy: 0.6884 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3083 - accuracy: 0.8589 - val_loss: 0.6346 - val_accuracy: 0.7536 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.3056 - accuracy: 0.8677 - val_loss: 0.6378 - val_accuracy: 0.7319 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.3074 - accuracy: 0.8629 - val_loss: 0.6249 - val_accuracy: 0.7174 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2893 - accuracy: 0.8790 - val_loss: 0.6443 - val_accuracy: 0.7246 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2783 - accuracy: 0.8734 - val_loss: 0.6437 - val_accuracy: 0.7391 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2869 - accuracy: 0.8766 - val_loss: 0.6369 - val_accuracy: 0.7174 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2680 - accuracy: 0.8823 - val_loss: 0.6465 - val_accuracy: 0.7174 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2701 - accuracy: 0.8806 - val_loss: 0.6458 - val_accuracy: 0.7174 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2572 - accuracy: 0.8895 - val_loss: 0.6458 - val_accuracy: 0.7246 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2593 - accuracy: 0.8960 - val_loss: 0.6593 - val_accuracy: 0.7319 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2513 - accuracy: 0.8952 - val_loss: 0.6679 - val_accuracy: 0.7174 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2577 - accuracy: 0.8790 - val_loss: 0.6638 - val_accuracy: 0.7391 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2603 - accuracy: 0.8911 - val_loss: 0.6683 - val_accuracy: 0.7319 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2426 - accuracy: 0.8927 - val_loss: 0.6688 - val_accuracy: 0.7174 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2580 - accuracy: 0.8887 - val_loss: 0.6628 - val_accuracy: 0.7319 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2602 - accuracy: 0.8855 - val_loss: 0.6643 - val_accuracy: 0.7246 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "155/155 [==============================] - 2s 10ms/step - loss: 0.2450 - accuracy: 0.8871 - val_loss: 0.6629 - val_accuracy: 0.7319 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2595 - accuracy: 0.8976 - val_loss: 0.6642 - val_accuracy: 0.7319 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "155/155 [==============================] - 2s 16ms/step - loss: 0.2617 - accuracy: 0.8831 - val_loss: 0.6631 - val_accuracy: 0.7319 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2571 - accuracy: 0.8927 - val_loss: 0.6617 - val_accuracy: 0.7319 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2460 - accuracy: 0.8895 - val_loss: 0.6626 - val_accuracy: 0.7319 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "155/155 [==============================] - 2s 12ms/step - loss: 0.2444 - accuracy: 0.8984 - val_loss: 0.6646 - val_accuracy: 0.7319 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "155/155 [==============================] - 3s 16ms/step - loss: 0.2451 - accuracy: 0.8960 - val_loss: 0.6617 - val_accuracy: 0.7319 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2541 - accuracy: 0.8935 - val_loss: 0.6624 - val_accuracy: 0.7319 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2574 - accuracy: 0.8887 - val_loss: 0.6620 - val_accuracy: 0.7319 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2485 - accuracy: 0.8984 - val_loss: 0.6626 - val_accuracy: 0.7319 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2447 - accuracy: 0.8984 - val_loss: 0.6623 - val_accuracy: 0.7319 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2465 - accuracy: 0.8879 - val_loss: 0.6623 - val_accuracy: 0.7319 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2634 - accuracy: 0.8879 - val_loss: 0.6617 - val_accuracy: 0.7319 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2533 - accuracy: 0.8903 - val_loss: 0.6613 - val_accuracy: 0.7319 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2490 - accuracy: 0.8960 - val_loss: 0.6612 - val_accuracy: 0.7319 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2518 - accuracy: 0.8952 - val_loss: 0.6616 - val_accuracy: 0.7319 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2405 - accuracy: 0.9073 - val_loss: 0.6618 - val_accuracy: 0.7319 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2432 - accuracy: 0.8960 - val_loss: 0.6616 - val_accuracy: 0.7319 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2464 - accuracy: 0.8944 - val_loss: 0.6624 - val_accuracy: 0.7319 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2404 - accuracy: 0.9024 - val_loss: 0.6629 - val_accuracy: 0.7319 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "155/155 [==============================] - 2s 15ms/step - loss: 0.2421 - accuracy: 0.8911 - val_loss: 0.6617 - val_accuracy: 0.7319 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "155/155 [==============================] - 2s 13ms/step - loss: 0.2479 - accuracy: 0.8992 - val_loss: 0.6627 - val_accuracy: 0.7319 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2547 - accuracy: 0.8935 - val_loss: 0.6626 - val_accuracy: 0.7319 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2487 - accuracy: 0.8944 - val_loss: 0.6627 - val_accuracy: 0.7319 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "155/155 [==============================] - 2s 11ms/step - loss: 0.2420 - accuracy: 0.9097 - val_loss: 0.6632 - val_accuracy: 0.7319 - lr: 1.0156e-05\n",
            "138/138 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 3s 13ms/step - loss: 0.9254 - accuracy: 0.5254 - val_loss: 0.6949 - val_accuracy: 0.5401 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.7008 - accuracy: 0.4859 - val_loss: 0.6970 - val_accuracy: 0.4672 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6945 - accuracy: 0.5085 - val_loss: 0.7217 - val_accuracy: 0.4599 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6957 - accuracy: 0.5165 - val_loss: 0.6927 - val_accuracy: 0.5401 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6928 - accuracy: 0.5028 - val_loss: 0.6904 - val_accuracy: 0.5401 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.6952 - accuracy: 0.4859 - val_loss: 0.6912 - val_accuracy: 0.5401 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6954 - accuracy: 0.4738 - val_loss: 0.6922 - val_accuracy: 0.5401 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6948 - accuracy: 0.4932 - val_loss: 0.6964 - val_accuracy: 0.4599 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6942 - accuracy: 0.4883 - val_loss: 0.6919 - val_accuracy: 0.4599 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6753 - accuracy: 0.5745 - val_loss: 0.6165 - val_accuracy: 0.7080 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6257 - accuracy: 0.6205 - val_loss: 0.6085 - val_accuracy: 0.6788 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.6066 - accuracy: 0.6446 - val_loss: 0.6039 - val_accuracy: 0.6861 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5922 - accuracy: 0.6640 - val_loss: 0.6487 - val_accuracy: 0.6277 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.6015 - accuracy: 0.6616 - val_loss: 0.5844 - val_accuracy: 0.7153 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5745 - accuracy: 0.6841 - val_loss: 0.5739 - val_accuracy: 0.7445 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5782 - accuracy: 0.6801 - val_loss: 0.5629 - val_accuracy: 0.7299 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5645 - accuracy: 0.6954 - val_loss: 0.5674 - val_accuracy: 0.7226 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5561 - accuracy: 0.7035 - val_loss: 0.5654 - val_accuracy: 0.7226 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5551 - accuracy: 0.7010 - val_loss: 0.5546 - val_accuracy: 0.7226 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5551 - accuracy: 0.7035 - val_loss: 0.5604 - val_accuracy: 0.7080 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5450 - accuracy: 0.7059 - val_loss: 0.5629 - val_accuracy: 0.7153 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5477 - accuracy: 0.7027 - val_loss: 0.5552 - val_accuracy: 0.7299 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5438 - accuracy: 0.7083 - val_loss: 0.5657 - val_accuracy: 0.7080 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5331 - accuracy: 0.7172 - val_loss: 0.5625 - val_accuracy: 0.7080 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5384 - accuracy: 0.7115 - val_loss: 0.5587 - val_accuracy: 0.7226 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5339 - accuracy: 0.7123 - val_loss: 0.5609 - val_accuracy: 0.7226 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5266 - accuracy: 0.7244 - val_loss: 0.5576 - val_accuracy: 0.7153 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5254 - accuracy: 0.7228 - val_loss: 0.5650 - val_accuracy: 0.7080 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5276 - accuracy: 0.7220 - val_loss: 0.5629 - val_accuracy: 0.7153 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5380 - accuracy: 0.7115 - val_loss: 0.5703 - val_accuracy: 0.7153 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5244 - accuracy: 0.7228 - val_loss: 0.5667 - val_accuracy: 0.7153 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5194 - accuracy: 0.7284 - val_loss: 0.5664 - val_accuracy: 0.7080 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5395 - accuracy: 0.7067 - val_loss: 0.5610 - val_accuracy: 0.7153 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5232 - accuracy: 0.7284 - val_loss: 0.5605 - val_accuracy: 0.7153 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5208 - accuracy: 0.7333 - val_loss: 0.5672 - val_accuracy: 0.7080 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5271 - accuracy: 0.7164 - val_loss: 0.5647 - val_accuracy: 0.7226 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "156/156 [==============================] - 2s 13ms/step - loss: 0.5358 - accuracy: 0.7172 - val_loss: 0.5596 - val_accuracy: 0.7080 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "156/156 [==============================] - 3s 16ms/step - loss: 0.5207 - accuracy: 0.7301 - val_loss: 0.5625 - val_accuracy: 0.7226 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5237 - accuracy: 0.7252 - val_loss: 0.5646 - val_accuracy: 0.7226 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "156/156 [==============================] - 2s 14ms/step - loss: 0.5322 - accuracy: 0.7188 - val_loss: 0.5616 - val_accuracy: 0.7153 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "156/156 [==============================] - 3s 16ms/step - loss: 0.5279 - accuracy: 0.7204 - val_loss: 0.5645 - val_accuracy: 0.7226 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5229 - accuracy: 0.7212 - val_loss: 0.5647 - val_accuracy: 0.7226 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5149 - accuracy: 0.7293 - val_loss: 0.5645 - val_accuracy: 0.7226 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5228 - accuracy: 0.7276 - val_loss: 0.5644 - val_accuracy: 0.7226 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5102 - accuracy: 0.7357 - val_loss: 0.5648 - val_accuracy: 0.7226 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5259 - accuracy: 0.7276 - val_loss: 0.5640 - val_accuracy: 0.7226 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5244 - accuracy: 0.7196 - val_loss: 0.5636 - val_accuracy: 0.7226 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5267 - accuracy: 0.7252 - val_loss: 0.5638 - val_accuracy: 0.7226 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5301 - accuracy: 0.7196 - val_loss: 0.5634 - val_accuracy: 0.7153 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5196 - accuracy: 0.7252 - val_loss: 0.5638 - val_accuracy: 0.7226 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5198 - accuracy: 0.7284 - val_loss: 0.5641 - val_accuracy: 0.7226 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5207 - accuracy: 0.7220 - val_loss: 0.5642 - val_accuracy: 0.7226 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5170 - accuracy: 0.7341 - val_loss: 0.5645 - val_accuracy: 0.7226 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5195 - accuracy: 0.7301 - val_loss: 0.5644 - val_accuracy: 0.7226 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5325 - accuracy: 0.7131 - val_loss: 0.5639 - val_accuracy: 0.7153 - lr: 1.0156e-05\n",
            "137/137 [==============================] - 0s 2ms/step\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 3s 13ms/step - loss: 0.8293 - accuracy: 0.5761 - val_loss: 0.6957 - val_accuracy: 0.4818 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6407 - accuracy: 0.6092 - val_loss: 0.6919 - val_accuracy: 0.5036 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.6099 - accuracy: 0.6398 - val_loss: 0.5926 - val_accuracy: 0.7080 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.6088 - accuracy: 0.6471 - val_loss: 0.5819 - val_accuracy: 0.7226 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5890 - accuracy: 0.6720 - val_loss: 0.5440 - val_accuracy: 0.7226 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.5404 - accuracy: 0.6954 - val_loss: 0.5471 - val_accuracy: 0.6934 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5387 - accuracy: 0.7019 - val_loss: 0.4839 - val_accuracy: 0.7518 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.5080 - accuracy: 0.7236 - val_loss: 0.4549 - val_accuracy: 0.7883 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.4843 - accuracy: 0.7518 - val_loss: 0.4687 - val_accuracy: 0.7372 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.4730 - accuracy: 0.7542 - val_loss: 0.4471 - val_accuracy: 0.8102 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.4646 - accuracy: 0.7607 - val_loss: 0.4305 - val_accuracy: 0.8321 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.4309 - accuracy: 0.7816 - val_loss: 0.4244 - val_accuracy: 0.8321 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.4185 - accuracy: 0.7832 - val_loss: 0.4452 - val_accuracy: 0.8175 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.4191 - accuracy: 0.7881 - val_loss: 0.4710 - val_accuracy: 0.7810 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.4027 - accuracy: 0.7994 - val_loss: 0.4519 - val_accuracy: 0.8175 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3906 - accuracy: 0.8050 - val_loss: 0.4296 - val_accuracy: 0.8321 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3817 - accuracy: 0.8211 - val_loss: 0.4484 - val_accuracy: 0.8248 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3672 - accuracy: 0.8147 - val_loss: 0.4281 - val_accuracy: 0.8248 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3651 - accuracy: 0.8219 - val_loss: 0.4408 - val_accuracy: 0.8029 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3742 - accuracy: 0.8195 - val_loss: 0.4385 - val_accuracy: 0.8321 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.3502 - accuracy: 0.8332 - val_loss: 0.4296 - val_accuracy: 0.8102 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3434 - accuracy: 0.8405 - val_loss: 0.4243 - val_accuracy: 0.8321 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3483 - accuracy: 0.8380 - val_loss: 0.4313 - val_accuracy: 0.8175 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3441 - accuracy: 0.8324 - val_loss: 0.4341 - val_accuracy: 0.8175 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3311 - accuracy: 0.8469 - val_loss: 0.4288 - val_accuracy: 0.8321 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3312 - accuracy: 0.8356 - val_loss: 0.4351 - val_accuracy: 0.8248 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3249 - accuracy: 0.8501 - val_loss: 0.4380 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3254 - accuracy: 0.8574 - val_loss: 0.4328 - val_accuracy: 0.8175 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3255 - accuracy: 0.8413 - val_loss: 0.4353 - val_accuracy: 0.8394 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3272 - accuracy: 0.8485 - val_loss: 0.4326 - val_accuracy: 0.8248 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3365 - accuracy: 0.8356 - val_loss: 0.4316 - val_accuracy: 0.8248 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3215 - accuracy: 0.8485 - val_loss: 0.4353 - val_accuracy: 0.8102 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3244 - accuracy: 0.8501 - val_loss: 0.4346 - val_accuracy: 0.8102 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3185 - accuracy: 0.8437 - val_loss: 0.4323 - val_accuracy: 0.8175 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3214 - accuracy: 0.8372 - val_loss: 0.4331 - val_accuracy: 0.8175 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3198 - accuracy: 0.8550 - val_loss: 0.4338 - val_accuracy: 0.8175 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3132 - accuracy: 0.8517 - val_loss: 0.4339 - val_accuracy: 0.8248 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3228 - accuracy: 0.8485 - val_loss: 0.4334 - val_accuracy: 0.8175 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3243 - accuracy: 0.8541 - val_loss: 0.4329 - val_accuracy: 0.8175 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3151 - accuracy: 0.8558 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3137 - accuracy: 0.8541 - val_loss: 0.4336 - val_accuracy: 0.8175 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3191 - accuracy: 0.8429 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3184 - accuracy: 0.8517 - val_loss: 0.4328 - val_accuracy: 0.8175 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "156/156 [==============================] - 2s 13ms/step - loss: 0.3186 - accuracy: 0.8533 - val_loss: 0.4327 - val_accuracy: 0.8175 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3162 - accuracy: 0.8574 - val_loss: 0.4327 - val_accuracy: 0.8175 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3144 - accuracy: 0.8541 - val_loss: 0.4329 - val_accuracy: 0.8175 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3155 - accuracy: 0.8485 - val_loss: 0.4331 - val_accuracy: 0.8175 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3077 - accuracy: 0.8582 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3249 - accuracy: 0.8614 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "156/156 [==============================] - 2s 11ms/step - loss: 0.3172 - accuracy: 0.8421 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3214 - accuracy: 0.8453 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3202 - accuracy: 0.8525 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3130 - accuracy: 0.8630 - val_loss: 0.4331 - val_accuracy: 0.8175 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3125 - accuracy: 0.8550 - val_loss: 0.4331 - val_accuracy: 0.8175 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3200 - accuracy: 0.8550 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3166 - accuracy: 0.8566 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3165 - accuracy: 0.8614 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3058 - accuracy: 0.8622 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3111 - accuracy: 0.8654 - val_loss: 0.4330 - val_accuracy: 0.8175 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3217 - accuracy: 0.8541 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3191 - accuracy: 0.8590 - val_loss: 0.4331 - val_accuracy: 0.8175 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3257 - accuracy: 0.8485 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3141 - accuracy: 0.8566 - val_loss: 0.4334 - val_accuracy: 0.8175 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3059 - accuracy: 0.8606 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "156/156 [==============================] - 3s 17ms/step - loss: 0.3092 - accuracy: 0.8614 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "156/156 [==============================] - 2s 13ms/step - loss: 0.3203 - accuracy: 0.8493 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "156/156 [==============================] - 2s 15ms/step - loss: 0.3171 - accuracy: 0.8558 - val_loss: 0.4333 - val_accuracy: 0.8175 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "156/156 [==============================] - 2s 15ms/step - loss: 0.3147 - accuracy: 0.8533 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 1.3162e-06\n",
            "Epoch 69/200\n",
            "156/156 [==============================] - 2s 12ms/step - loss: 0.3180 - accuracy: 0.8541 - val_loss: 0.4332 - val_accuracy: 0.8175 - lr: 7.8973e-07\n",
            "137/137 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statistics import mean, stdev\n",
        "print(mean(ACC_collecton),'±',stdev(ACC_collecton))\n",
        "print(mean(BACC_collecton),'±',stdev(BACC_collecton))\n",
        "print(mean(Sn_collecton),'±',stdev(Sn_collecton))\n",
        "print(mean(Sp_collecton),'±',stdev(Sp_collecton))\n",
        "print(mean(MCC_collecton),'±',stdev(MCC_collecton))\n",
        "print(mean(AUC_collecton),'±',stdev(AUC_collecton))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTi2x37MzsIY",
        "outputId": "fcb47224-102f-455d-a2a0-b77d8d6fd75c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7460753200042315 ± 0.043739056899664536\n",
            "0.7593259096849925 ± 0.03948824282465656\n",
            "0.8044658584580148 ± 0.06221850836486582\n",
            "0.7141859609119703 ± 0.05584179725576553\n",
            "0.5027567383386884 ± 0.08229734761153824\n",
            "0.7917416007238911 ± 0.04810856071346626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model evaluation in test dataset"
      ],
      "metadata": {
        "id": "5JBlTA9shnQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# result collection list\n",
        "ACC_collecton = []\n",
        "BACC_collecton = []\n",
        "Sn_collecton = []\n",
        "Sp_collecton = []\n",
        "MCC_collecton = []\n",
        "AUC_collecton = []\n",
        "model, model_history = ESM_CNN(X_train, y_train, X_test , y_test)\n",
        "# confusion matrix \n",
        "predicted_class= []\n",
        "predicted_protability = model.predict(X_test,batch_size=1)\n",
        "for i in range(predicted_protability.shape[0]):\n",
        "  index = np.where(predicted_protability[i] == np.amax(predicted_protability[i]))[0][0]\n",
        "  predicted_class.append(index)\n",
        "predicted_class = np.array(predicted_class)\n",
        "y_true = y_test    \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import math\n",
        "# np.ravel() return a flatten 1D array\n",
        "TP, FP, FN, TN = confusion_matrix(y_true, predicted_class).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
        "ACC = (TP+TN)/(TP+TN+FP+FN)\n",
        "ACC_collecton.append(ACC)\n",
        "Sn_collecton.append(TP/(TP+FN))\n",
        "Sp_collecton.append(TN/(TN+FP))\n",
        "MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
        "MCC_collecton.append(MCC)\n",
        "BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
        "from sklearn.metrics import roc_auc_score\n",
        "AUC = roc_auc_score(y_test, predicted_protability[:,1])\n",
        "AUC_collecton.append(AUC)"
      ],
      "metadata": {
        "id": "KPwEv_WsnH6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f376088-b93c-4b53-8bd7-6ab76cfe23bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 3s 12ms/step - loss: 1.2733 - accuracy: 0.5958 - val_loss: 0.6583 - val_accuracy: 0.6366 - lr: 0.1000\n",
            "Epoch 2/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.5902 - accuracy: 0.6589 - val_loss: 0.6660 - val_accuracy: 0.6221 - lr: 0.1000\n",
            "Epoch 3/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.5379 - accuracy: 0.7163 - val_loss: 0.5802 - val_accuracy: 0.6657 - lr: 0.0600\n",
            "Epoch 4/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.5049 - accuracy: 0.7170 - val_loss: 0.5746 - val_accuracy: 0.6831 - lr: 0.0600\n",
            "Epoch 5/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.5020 - accuracy: 0.7380 - val_loss: 0.5609 - val_accuracy: 0.6919 - lr: 0.0600\n",
            "Epoch 6/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.4607 - accuracy: 0.7583 - val_loss: 0.5553 - val_accuracy: 0.7122 - lr: 0.0360\n",
            "Epoch 7/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.4528 - accuracy: 0.7540 - val_loss: 0.5841 - val_accuracy: 0.7180 - lr: 0.0360\n",
            "Epoch 8/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.4359 - accuracy: 0.7627 - val_loss: 0.6088 - val_accuracy: 0.7267 - lr: 0.0360\n",
            "Epoch 9/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.4177 - accuracy: 0.7656 - val_loss: 0.5918 - val_accuracy: 0.7151 - lr: 0.0216\n",
            "Epoch 10/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3966 - accuracy: 0.7954 - val_loss: 0.5908 - val_accuracy: 0.7151 - lr: 0.0216\n",
            "Epoch 11/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.3868 - accuracy: 0.7990 - val_loss: 0.6112 - val_accuracy: 0.7238 - lr: 0.0216\n",
            "Epoch 12/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.3662 - accuracy: 0.8164 - val_loss: 0.6333 - val_accuracy: 0.7180 - lr: 0.0130\n",
            "Epoch 13/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3563 - accuracy: 0.8179 - val_loss: 0.6109 - val_accuracy: 0.7297 - lr: 0.0130\n",
            "Epoch 14/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3577 - accuracy: 0.8244 - val_loss: 0.6462 - val_accuracy: 0.7035 - lr: 0.0130\n",
            "Epoch 15/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3321 - accuracy: 0.8331 - val_loss: 0.6232 - val_accuracy: 0.7326 - lr: 0.0078\n",
            "Epoch 16/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3442 - accuracy: 0.8229 - val_loss: 0.5993 - val_accuracy: 0.7326 - lr: 0.0078\n",
            "Epoch 17/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3332 - accuracy: 0.8287 - val_loss: 0.6695 - val_accuracy: 0.7267 - lr: 0.0078\n",
            "Epoch 18/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3269 - accuracy: 0.8447 - val_loss: 0.6384 - val_accuracy: 0.7209 - lr: 0.0047\n",
            "Epoch 19/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3265 - accuracy: 0.8331 - val_loss: 0.6434 - val_accuracy: 0.7326 - lr: 0.0047\n",
            "Epoch 20/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.3268 - accuracy: 0.8403 - val_loss: 0.6444 - val_accuracy: 0.7238 - lr: 0.0047\n",
            "Epoch 21/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2999 - accuracy: 0.8563 - val_loss: 0.6575 - val_accuracy: 0.7297 - lr: 0.0028\n",
            "Epoch 22/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3081 - accuracy: 0.8505 - val_loss: 0.6545 - val_accuracy: 0.7297 - lr: 0.0028\n",
            "Epoch 23/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2965 - accuracy: 0.8628 - val_loss: 0.6547 - val_accuracy: 0.7238 - lr: 0.0028\n",
            "Epoch 24/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.3043 - accuracy: 0.8578 - val_loss: 0.6571 - val_accuracy: 0.7297 - lr: 0.0017\n",
            "Epoch 25/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3072 - accuracy: 0.8599 - val_loss: 0.6508 - val_accuracy: 0.7326 - lr: 0.0017\n",
            "Epoch 26/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2997 - accuracy: 0.8563 - val_loss: 0.6489 - val_accuracy: 0.7267 - lr: 0.0017\n",
            "Epoch 27/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2963 - accuracy: 0.8520 - val_loss: 0.6483 - val_accuracy: 0.7267 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3037 - accuracy: 0.8599 - val_loss: 0.6482 - val_accuracy: 0.7297 - lr: 0.0010\n",
            "Epoch 29/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2910 - accuracy: 0.8556 - val_loss: 0.6466 - val_accuracy: 0.7326 - lr: 0.0010\n",
            "Epoch 30/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2876 - accuracy: 0.8592 - val_loss: 0.6456 - val_accuracy: 0.7297 - lr: 6.0466e-04\n",
            "Epoch 31/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2894 - accuracy: 0.8665 - val_loss: 0.6522 - val_accuracy: 0.7326 - lr: 6.0466e-04\n",
            "Epoch 32/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2875 - accuracy: 0.8607 - val_loss: 0.6557 - val_accuracy: 0.7326 - lr: 6.0466e-04\n",
            "Epoch 33/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2895 - accuracy: 0.8549 - val_loss: 0.6583 - val_accuracy: 0.7355 - lr: 3.6280e-04\n",
            "Epoch 34/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2864 - accuracy: 0.8614 - val_loss: 0.6608 - val_accuracy: 0.7355 - lr: 3.6280e-04\n",
            "Epoch 35/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2978 - accuracy: 0.8549 - val_loss: 0.6583 - val_accuracy: 0.7355 - lr: 3.6280e-04\n",
            "Epoch 36/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2789 - accuracy: 0.8679 - val_loss: 0.6583 - val_accuracy: 0.7355 - lr: 2.1768e-04\n",
            "Epoch 37/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2887 - accuracy: 0.8766 - val_loss: 0.6581 - val_accuracy: 0.7326 - lr: 2.1768e-04\n",
            "Epoch 38/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2892 - accuracy: 0.8498 - val_loss: 0.6582 - val_accuracy: 0.7297 - lr: 2.1768e-04\n",
            "Epoch 39/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2888 - accuracy: 0.8614 - val_loss: 0.6570 - val_accuracy: 0.7297 - lr: 1.3061e-04\n",
            "Epoch 40/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2913 - accuracy: 0.8498 - val_loss: 0.6569 - val_accuracy: 0.7326 - lr: 1.3061e-04\n",
            "Epoch 41/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2867 - accuracy: 0.8636 - val_loss: 0.6593 - val_accuracy: 0.7355 - lr: 1.3061e-04\n",
            "Epoch 42/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2790 - accuracy: 0.8759 - val_loss: 0.6582 - val_accuracy: 0.7297 - lr: 7.8364e-05\n",
            "Epoch 43/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2841 - accuracy: 0.8694 - val_loss: 0.6602 - val_accuracy: 0.7326 - lr: 7.8364e-05\n",
            "Epoch 44/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2844 - accuracy: 0.8672 - val_loss: 0.6594 - val_accuracy: 0.7297 - lr: 7.8364e-05\n",
            "Epoch 45/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2725 - accuracy: 0.8708 - val_loss: 0.6615 - val_accuracy: 0.7326 - lr: 4.7018e-05\n",
            "Epoch 46/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2803 - accuracy: 0.8737 - val_loss: 0.6609 - val_accuracy: 0.7326 - lr: 4.7018e-05\n",
            "Epoch 47/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.3035 - accuracy: 0.8556 - val_loss: 0.6621 - val_accuracy: 0.7326 - lr: 4.7018e-05\n",
            "Epoch 48/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2808 - accuracy: 0.8679 - val_loss: 0.6598 - val_accuracy: 0.7297 - lr: 2.8211e-05\n",
            "Epoch 49/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2800 - accuracy: 0.8694 - val_loss: 0.6603 - val_accuracy: 0.7297 - lr: 2.8211e-05\n",
            "Epoch 50/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2871 - accuracy: 0.8628 - val_loss: 0.6606 - val_accuracy: 0.7297 - lr: 2.8211e-05\n",
            "Epoch 51/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2846 - accuracy: 0.8657 - val_loss: 0.6606 - val_accuracy: 0.7326 - lr: 1.6927e-05\n",
            "Epoch 52/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2768 - accuracy: 0.8636 - val_loss: 0.6611 - val_accuracy: 0.7326 - lr: 1.6927e-05\n",
            "Epoch 53/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2796 - accuracy: 0.8665 - val_loss: 0.6608 - val_accuracy: 0.7297 - lr: 1.6927e-05\n",
            "Epoch 54/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2765 - accuracy: 0.8607 - val_loss: 0.6610 - val_accuracy: 0.7297 - lr: 1.0156e-05\n",
            "Epoch 55/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2967 - accuracy: 0.8607 - val_loss: 0.6599 - val_accuracy: 0.7297 - lr: 1.0156e-05\n",
            "Epoch 56/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2831 - accuracy: 0.8657 - val_loss: 0.6606 - val_accuracy: 0.7297 - lr: 1.0156e-05\n",
            "Epoch 57/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2835 - accuracy: 0.8650 - val_loss: 0.6612 - val_accuracy: 0.7297 - lr: 6.0936e-06\n",
            "Epoch 58/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2874 - accuracy: 0.8607 - val_loss: 0.6606 - val_accuracy: 0.7297 - lr: 6.0936e-06\n",
            "Epoch 59/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2847 - accuracy: 0.8672 - val_loss: 0.6612 - val_accuracy: 0.7297 - lr: 6.0936e-06\n",
            "Epoch 60/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2870 - accuracy: 0.8643 - val_loss: 0.6603 - val_accuracy: 0.7297 - lr: 3.6562e-06\n",
            "Epoch 61/200\n",
            "173/173 [==============================] - 2s 11ms/step - loss: 0.2744 - accuracy: 0.8687 - val_loss: 0.6614 - val_accuracy: 0.7297 - lr: 3.6562e-06\n",
            "Epoch 62/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2849 - accuracy: 0.8679 - val_loss: 0.6610 - val_accuracy: 0.7297 - lr: 3.6562e-06\n",
            "Epoch 63/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2714 - accuracy: 0.8752 - val_loss: 0.6614 - val_accuracy: 0.7297 - lr: 2.1937e-06\n",
            "Epoch 64/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2889 - accuracy: 0.8541 - val_loss: 0.6600 - val_accuracy: 0.7297 - lr: 2.1937e-06\n",
            "Epoch 65/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2789 - accuracy: 0.8694 - val_loss: 0.6614 - val_accuracy: 0.7297 - lr: 2.1937e-06\n",
            "Epoch 66/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2893 - accuracy: 0.8687 - val_loss: 0.6626 - val_accuracy: 0.7297 - lr: 1.3162e-06\n",
            "Epoch 67/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2859 - accuracy: 0.8672 - val_loss: 0.6621 - val_accuracy: 0.7297 - lr: 1.3162e-06\n",
            "Epoch 68/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2941 - accuracy: 0.8621 - val_loss: 0.6602 - val_accuracy: 0.7297 - lr: 1.3162e-06\n",
            "Epoch 69/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2904 - accuracy: 0.8614 - val_loss: 0.6610 - val_accuracy: 0.7297 - lr: 7.8973e-07\n",
            "Epoch 70/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2840 - accuracy: 0.8694 - val_loss: 0.6619 - val_accuracy: 0.7297 - lr: 7.8973e-07\n",
            "Epoch 71/200\n",
            "173/173 [==============================] - 3s 17ms/step - loss: 0.2805 - accuracy: 0.8737 - val_loss: 0.6631 - val_accuracy: 0.7297 - lr: 7.8973e-07\n",
            "Epoch 72/200\n",
            "173/173 [==============================] - 3s 18ms/step - loss: 0.2743 - accuracy: 0.8716 - val_loss: 0.6605 - val_accuracy: 0.7297 - lr: 4.7384e-07\n",
            "Epoch 73/200\n",
            "173/173 [==============================] - 2s 12ms/step - loss: 0.2810 - accuracy: 0.8694 - val_loss: 0.6602 - val_accuracy: 0.7297 - lr: 4.7384e-07\n",
            "344/344 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ACC_collecton[0])\n",
        "print(BACC_collecton[0])\n",
        "print(Sn_collecton[0])\n",
        "print(Sp_collecton[0])\n",
        "print(MCC_collecton[0])\n",
        "print(AUC_collecton[0])"
      ],
      "metadata": {
        "id": "nOkHijttl10O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb16278-dbf8-42aa-add6-b08c4c065183"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7354651162790697\n",
            "0.7354730757529662\n",
            "0.7341040462427746\n",
            "0.7368421052631579\n",
            "0.4709381919647732\n",
            "0.8054015684153597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('ACP_main_tensorflow_model',save_format = 'tf') \n",
        "!zip -r /content/ACP_main_tensorflow_model.zip /content/ACP_main_tensorflow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDNAw5DCUDHT",
        "outputId": "bd85c8ac-5536-4cb5-f0b7-29824aacd0db"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/ACP_main_tensorflow_model/ (stored 0%)\n",
            "updating: content/ACP_main_tensorflow_model/variables/ (stored 0%)\n",
            "updating: content/ACP_main_tensorflow_model/variables/variables.index (deflated 64%)\n",
            "updating: content/ACP_main_tensorflow_model/variables/variables.data-00000-of-00001 (deflated 43%)\n",
            "updating: content/ACP_main_tensorflow_model/saved_model.pb (deflated 88%)\n",
            "updating: content/ACP_main_tensorflow_model/assets/ (stored 0%)\n",
            "updating: content/ACP_main_tensorflow_model/keras_metadata.pb (deflated 89%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fURDBSCz6q6u"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}